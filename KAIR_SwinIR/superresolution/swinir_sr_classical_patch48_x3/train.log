22-01-12 00:47:14.886 :   task: swinir_sr_classical_patch48_x3
  model: plain
  gpu_ids: [0]
  dist: False
  scale: 3
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution/swinir_sr_classical_patch48_x3
    log: superresolution/swinir_sr_classical_patch48_x3
    options: superresolution/swinir_sr_classical_patch48_x3/options
    models: superresolution/swinir_sr_classical_patch48_x3/models
    images: superresolution/swinir_sr_classical_patch48_x3/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: dataset/training_hr_images
      dataroot_L: None
      H_size: 144
      dataloader_shuffle: True
      dataloader_num_workers: 16
      dataloader_batch_size: 32
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: dataset/val_hr_images
      dataroot_L: None
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 3
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
    init_type: default
    scale: 3
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
  ]
  opt_path: options/swinir/train_swinir_sr_classical.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  num_gpu: 1
  rank: 0
  world_size: 1

22-01-12 00:47:14.888 : Number of train images: 283, iters: 9
22-01-12 00:47:16.922 : 
Networks name: SwinIR
Params number: 11937127
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (3): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (4): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (5): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=3)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

22-01-12 00:47:16.979 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.002 | -0.192 |  0.192 |  0.111 | torch.Size([180, 3, 3, 3]) || conv_first.weight
 |  0.002 | -0.190 |  0.192 |  0.117 | torch.Size([180]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.000 | -0.063 |  0.062 |  0.019 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.085 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.076 |  0.096 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.083 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.084 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.bias
 |  0.000 | -0.058 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.080 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 |  0.000 | -0.092 |  0.088 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.095 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.088 |  0.074 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.067 |  0.056 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.087 |  0.102 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.080 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.086 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.101 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.bias
 |  0.001 | -0.063 |  0.079 |  0.021 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.087 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.082 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.102 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.086 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.082 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 | -0.000 | -0.087 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.091 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.084 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.080 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.065 |  0.073 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.102 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.000 | -0.076 |  0.090 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.085 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.086 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.0.conv.weight
 |  0.000 | -0.024 |  0.024 |  0.014 | torch.Size([180]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.063 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.091 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.085 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.096 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.098 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.089 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.095 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.083 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.086 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.094 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.073 |  0.058 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.085 |  0.092 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.081 |  0.092 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.076 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.089 |  0.092 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.068 |  0.052 |  0.019 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.095 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.080 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.083 |  0.092 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.080 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.063 |  0.073 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 | -0.000 | -0.078 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.079 |  0.077 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.090 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.092 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.068 |  0.059 |  0.021 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.090 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.079 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.088 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.077 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.1.conv.weight
 |  0.002 | -0.025 |  0.025 |  0.015 | torch.Size([180]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.bias
 | -0.001 | -0.074 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.084 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.082 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.078 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.095 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.bias
 |  0.002 | -0.057 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.092 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.088 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.086 |  0.079 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.081 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.072 |  0.063 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.087 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.086 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.089 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.091 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.061 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.094 |  0.081 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.087 |  0.077 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.099 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.082 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.063 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.098 |  0.093 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.4.attn.qkv.bias
 |  0.000 | -0.077 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.085 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.093 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.070 |  0.056 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.086 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.5.attn.qkv.bias
 | -0.000 | -0.083 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.079 |  0.077 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.091 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.2.conv.weight
 | -0.001 | -0.025 |  0.025 |  0.013 | torch.Size([180]) || layers.2.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.bias
 | -0.001 | -0.055 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.082 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.077 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.081 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.090 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.069 |  0.058 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.079 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.080 |  0.082 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.086 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.086 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.060 |  0.071 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.088 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.090 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.089 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.083 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.069 |  0.059 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.089 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.078 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.090 |  0.075 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.084 |  0.093 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.062 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.080 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.079 |  0.086 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.080 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.060 |  0.066 |  0.021 | torch.Size([225, 6]) || layers.3.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.5.attn.relative_position_index
 |  0.000 | -0.080 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.078 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.083 |  0.074 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.076 |  0.094 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.3.conv.weight
 | -0.001 | -0.025 |  0.024 |  0.014 | torch.Size([180]) || layers.3.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.065 |  0.071 |  0.021 | torch.Size([225, 6]) || layers.4.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.082 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.075 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.085 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.082 |  0.096 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.069 |  0.059 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.086 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.088 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.090 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.090 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.066 |  0.064 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.091 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.081 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.083 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.083 |  0.079 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.061 |  0.067 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.087 |  0.080 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.088 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.083 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.090 |  0.089 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.062 |  0.069 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.081 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.079 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.087 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.081 |  0.100 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.063 |  0.067 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.099 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.087 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.bias
 | -0.000 | -2.000 |  0.082 |  0.021 | torch.Size([360, 180]) || layers.4.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.084 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.4.conv.weight
 |  0.001 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.4.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.063 |  0.075 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.0.attn.relative_position_index
 |  0.000 | -0.096 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.090 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.098 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.089 |  0.078 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.bias
 | -0.001 | -0.067 |  0.056 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.088 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.082 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.082 |  0.097 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.088 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.066 |  0.067 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.086 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.082 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.106 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.083 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.bias
 |  0.001 | -0.059 |  0.080 |  0.021 | torch.Size([225, 6]) || layers.5.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.081 |  0.098 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.082 |  0.082 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.100 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.083 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.071 |  0.072 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.093 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.4.attn.qkv.bias
 |  0.000 | -0.086 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.089 |  0.079 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.085 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.bias
 | -0.001 | -0.068 |  0.061 |  0.021 | torch.Size([225, 6]) || layers.5.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.090 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.077 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.081 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.5.conv.weight
 |  0.000 | -0.024 |  0.024 |  0.014 | torch.Size([180]) || layers.5.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || norm.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || conv_after_body.weight
 |  0.000 | -0.024 |  0.025 |  0.014 | torch.Size([180]) || conv_after_body.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([64, 180, 3, 3]) || conv_before_upsample.0.weight
 | -0.000 | -0.025 |  0.024 |  0.014 | torch.Size([64]) || conv_before_upsample.0.bias
 | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([576, 64, 3, 3]) || upsample.0.weight
 |  0.003 | -0.042 |  0.042 |  0.024 | torch.Size([576]) || upsample.0.bias
 | -0.001 | -0.042 |  0.042 |  0.024 | torch.Size([3, 64, 3, 3]) || conv_last.weight
 |  0.006 |  0.003 |  0.008 |  0.002 | torch.Size([3]) || conv_last.bias

22-01-12 00:48:01.801 :   task: swinir_sr_classical_patch48_x3
  model: plain
  gpu_ids: [0]
  dist: False
  scale: 3
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution/swinir_sr_classical_patch48_x3
    log: superresolution/swinir_sr_classical_patch48_x3
    options: superresolution/swinir_sr_classical_patch48_x3/options
    models: superresolution/swinir_sr_classical_patch48_x3/models
    images: superresolution/swinir_sr_classical_patch48_x3/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: dataset/training_hr_images
      dataroot_L: None
      H_size: 144
      dataloader_shuffle: True
      dataloader_num_workers: 16
      dataloader_batch_size: 1
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: dataset/val_hr_images
      dataroot_L: None
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 3
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
    init_type: default
    scale: 3
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
  ]
  opt_path: options/swinir/train_swinir_sr_classical.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  num_gpu: 1
  rank: 0
  world_size: 1

22-01-12 00:48:01.803 : Number of train images: 283, iters: 283
22-01-12 00:48:03.746 : 
Networks name: SwinIR
Params number: 11937127
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (3): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (4): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (5): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=3)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

22-01-12 00:48:03.804 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.002 | -0.192 |  0.192 |  0.112 | torch.Size([180, 3, 3, 3]) || conv_first.weight
 | -0.011 | -0.190 |  0.192 |  0.111 | torch.Size([180]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.061 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.000 | -0.090 |  0.101 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.084 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.089 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.083 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.001 | -0.065 |  0.063 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.085 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 |  0.000 | -0.084 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.081 |  0.078 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.058 |  0.063 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.084 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.084 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.086 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.078 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.059 |  0.070 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.086 |  0.095 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.079 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.084 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.091 |  0.098 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.065 |  0.057 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 | -0.000 | -0.087 |  0.099 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.094 |  0.098 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.087 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.083 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.067 |  0.057 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.089 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.000 | -0.080 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.082 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.095 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.0.conv.weight
 |  0.002 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.001 | -0.061 |  0.065 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.094 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.087 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.078 |  0.077 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.088 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.060 |  0.070 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.084 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.091 |  0.074 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.084 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.087 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.076 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.086 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.085 |  0.099 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.078 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.086 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.059 |  0.060 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.082 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.084 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.088 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.082 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.061 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.087 |  0.080 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.096 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.087 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.094 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.075 |  0.081 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -2.000 |  0.087 |  0.021 | torch.Size([540, 180]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.093 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.088 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.098 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.1.conv.weight
 | -0.001 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.bias
 | -0.000 | -0.065 |  0.060 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.085 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.087 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.082 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.095 |  0.092 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.bias
 |  0.001 | -0.069 |  0.064 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.084 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.079 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.102 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.078 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.bias
 |  0.000 | -0.072 |  0.070 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.083 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.082 |  0.082 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.084 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.083 |  0.089 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.073 |  0.063 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.094 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.076 |  0.088 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.083 |  0.099 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.100 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.067 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.090 |  0.092 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.083 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.083 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.080 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.2.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.063 |  0.075 |  0.020 | torch.Size([225, 6]) || layers.2.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.2.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.083 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.080 |  0.074 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.076 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.2.conv.weight
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.2.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.079 |  0.069 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.090 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.081 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.086 |  0.086 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.089 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.bias
 |  0.001 | -0.059 |  0.078 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.088 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.083 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.092 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.085 |  0.077 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.bias
 |  0.000 | -0.060 |  0.075 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.088 |  0.081 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.084 |  0.082 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.079 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.085 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.075 |  0.076 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.099 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.078 |  0.074 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.084 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -2.000 |  0.085 |  0.021 | torch.Size([180, 360]) || layers.3.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.076 |  0.063 |  0.021 | torch.Size([225, 6]) || layers.3.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.092 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.083 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.082 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.084 |  0.093 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.3.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.062 |  0.057 |  0.020 | torch.Size([225, 6]) || layers.3.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.3.residual_group.blocks.5.attn.relative_position_index
 |  0.000 | -0.084 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.086 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.bias
 |  0.000 | -0.086 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.088 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.3.conv.weight
 | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.3.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.074 |  0.061 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.0.attn.relative_position_index
 |  0.000 | -0.097 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.080 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.bias
 | -0.000 | -0.082 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.079 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.074 |  0.072 |  0.021 | torch.Size([225, 6]) || layers.4.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.092 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.1.attn.qkv.bias
 |  0.000 | -0.076 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.087 |  0.088 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.078 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.071 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.080 |  0.096 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.074 |  0.079 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.085 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.085 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.067 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.090 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.088 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.097 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.088 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.072 |  0.065 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.081 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.079 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.090 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.075 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.4.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.bias
 | -0.001 | -0.073 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.4.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.4.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.091 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.076 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.087 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.077 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.4.conv.weight
 |  0.000 | -0.025 |  0.024 |  0.015 | torch.Size([180]) || layers.4.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.bias
 | -0.000 | -0.066 |  0.065 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.088 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.091 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.082 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.bias
 | -0.001 | -0.069 |  0.064 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.085 |  0.093 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.086 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.bias
 | -0.000 | -0.096 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.074 |  0.081 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.061 |  0.072 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.077 |  0.094 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.077 |  0.087 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.084 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.091 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.054 |  0.073 |  0.020 | torch.Size([225, 6]) || layers.5.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.092 |  0.095 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.075 |  0.079 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.079 |  0.094 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.086 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.067 |  0.063 |  0.019 | torch.Size([225, 6]) || layers.5.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.087 |  0.077 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.076 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.084 |  0.080 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.mlp.fc2.bias
 | -15.972 | -100.000 |  0.000 | 36.635 | torch.Size([36, 64, 64]) || layers.5.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.bias
 |  0.001 | -0.056 |  0.065 |  0.021 | torch.Size([225, 6]) || layers.5.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.5.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.094 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.082 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.103 |  0.091 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.096 |  0.098 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.5.conv.weight
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.5.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || norm.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || conv_after_body.weight
 |  0.001 | -0.025 |  0.024 |  0.015 | torch.Size([180]) || conv_after_body.bias
 |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([64, 180, 3, 3]) || conv_before_upsample.0.weight
 |  0.000 | -0.025 |  0.024 |  0.014 | torch.Size([64]) || conv_before_upsample.0.bias
 |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([576, 64, 3, 3]) || upsample.0.weight
 | -0.001 | -0.041 |  0.042 |  0.023 | torch.Size([576]) || upsample.0.bias
 |  0.001 | -0.042 |  0.042 |  0.024 | torch.Size([3, 64, 3, 3]) || conv_last.weight
 | -0.011 | -0.023 |  0.006 |  0.015 | torch.Size([3]) || conv_last.bias

22-01-12 00:48:30.050 : <epoch:  0, iter:     200, lr:2.000e-04> G_loss: 1.079e-01 
22-01-12 00:48:56.540 : <epoch:  1, iter:     400, lr:2.000e-04> G_loss: 6.312e-02 
22-01-12 00:49:23.197 : <epoch:  2, iter:     600, lr:2.000e-04> G_loss: 8.524e-02 
22-01-12 00:49:49.256 : <epoch:  2, iter:     800, lr:2.000e-04> G_loss: 5.577e-02 
22-01-12 00:50:15.786 : <epoch:  3, iter:   1,000, lr:2.000e-04> G_loss: 5.018e-02 
22-01-12 00:50:42.348 : <epoch:  4, iter:   1,200, lr:2.000e-04> G_loss: 3.776e-02 
22-01-12 00:51:08.396 : <epoch:  4, iter:   1,400, lr:2.000e-04> G_loss: 5.513e-02 
22-01-12 00:51:35.037 : <epoch:  5, iter:   1,600, lr:2.000e-04> G_loss: 8.521e-02 
22-01-12 00:52:01.668 : <epoch:  6, iter:   1,800, lr:2.000e-04> G_loss: 4.482e-02 
22-01-12 00:52:28.325 : <epoch:  7, iter:   2,000, lr:2.000e-04> G_loss: 3.602e-02 
22-01-12 00:52:54.372 : <epoch:  7, iter:   2,200, lr:2.000e-04> G_loss: 6.459e-02 
22-01-12 00:53:21.025 : <epoch:  8, iter:   2,400, lr:2.000e-04> G_loss: 1.887e-02 
22-01-12 00:53:47.598 : <epoch:  9, iter:   2,600, lr:2.000e-04> G_loss: 4.350e-02 
22-01-12 00:54:13.757 : <epoch:  9, iter:   2,800, lr:2.000e-04> G_loss: 4.372e-02 
22-01-12 00:54:40.367 : <epoch: 10, iter:   3,000, lr:2.000e-04> G_loss: 3.660e-02 
22-01-12 00:55:07.025 : <epoch: 11, iter:   3,200, lr:2.000e-04> G_loss: 2.918e-02 
22-01-12 00:55:33.627 : <epoch: 12, iter:   3,400, lr:2.000e-04> G_loss: 2.725e-02 
22-01-12 00:55:59.686 : <epoch: 12, iter:   3,600, lr:2.000e-04> G_loss: 2.938e-02 
22-01-12 00:56:26.328 : <epoch: 13, iter:   3,800, lr:2.000e-04> G_loss: 2.700e-02 
22-01-12 00:56:52.937 : <epoch: 14, iter:   4,000, lr:2.000e-04> G_loss: 7.815e-02 
22-01-12 00:57:19.017 : <epoch: 14, iter:   4,200, lr:2.000e-04> G_loss: 5.505e-02 
22-01-12 00:57:45.613 : <epoch: 15, iter:   4,400, lr:2.000e-04> G_loss: 7.192e-02 
22-01-12 00:58:12.236 : <epoch: 16, iter:   4,600, lr:2.000e-04> G_loss: 4.474e-02 
22-01-12 00:58:38.299 : <epoch: 16, iter:   4,800, lr:2.000e-04> G_loss: 1.578e-02 
22-01-12 00:59:04.933 : <epoch: 17, iter:   5,000, lr:2.000e-04> G_loss: 2.671e-02 
22-01-12 00:59:04.933 : Saving the model.
22-01-12 00:59:05.586 : ---1-->  12003.png | 26.97dB
22-01-12 00:59:05.908 : ---2-->  12074.png | 28.46dB
22-01-12 00:59:06.198 : ---3-->  15004.png | 23.92dB
22-01-12 00:59:06.526 : ---4-->  15088.png | 24.41dB
22-01-12 00:59:06.844 : ---5-->  16052.png | 32.26dB
22-01-12 00:59:07.160 : ---6-->   2092.png | 27.00dB
22-01-12 00:59:07.441 : ---7-->   8049.png | 25.46dB
22-01-12 00:59:07.733 : ---8-->   8143.png | 19.71dB
22-01-12 00:59:07.764 : <epoch: 17, iter:   5,000, Average PSNR : 26.02dB

22-01-12 00:59:34.322 : <epoch: 18, iter:   5,200, lr:2.000e-04> G_loss: 2.533e-02 
22-01-12 01:00:00.937 : <epoch: 19, iter:   5,400, lr:2.000e-04> G_loss: 2.428e-02 
22-01-12 01:00:27.156 : <epoch: 19, iter:   5,600, lr:2.000e-04> G_loss: 2.248e-02 
22-01-12 01:00:53.758 : <epoch: 20, iter:   5,800, lr:2.000e-04> G_loss: 4.053e-02 
22-01-12 01:01:20.369 : <epoch: 21, iter:   6,000, lr:2.000e-04> G_loss: 4.308e-02 
22-01-12 01:01:46.435 : <epoch: 21, iter:   6,200, lr:2.000e-04> G_loss: 1.683e-02 
22-01-12 01:02:13.243 : <epoch: 22, iter:   6,400, lr:2.000e-04> G_loss: 2.026e-02 
22-01-12 01:02:39.842 : <epoch: 23, iter:   6,600, lr:2.000e-04> G_loss: 2.363e-02 
22-01-12 01:03:06.492 : <epoch: 24, iter:   6,800, lr:2.000e-04> G_loss: 3.245e-02 
22-01-12 01:03:32.538 : <epoch: 24, iter:   7,000, lr:2.000e-04> G_loss: 2.218e-02 
22-01-12 01:03:59.204 : <epoch: 25, iter:   7,200, lr:2.000e-04> G_loss: 5.536e-02 
22-01-12 01:04:25.780 : <epoch: 26, iter:   7,400, lr:2.000e-04> G_loss: 6.956e-02 
22-01-12 01:04:51.824 : <epoch: 26, iter:   7,600, lr:2.000e-04> G_loss: 4.610e-02 
22-01-12 01:05:18.645 : <epoch: 27, iter:   7,800, lr:2.000e-04> G_loss: 2.774e-02 
22-01-12 01:05:45.271 : <epoch: 28, iter:   8,000, lr:2.000e-04> G_loss: 1.247e-02 
22-01-12 01:06:11.388 : <epoch: 28, iter:   8,200, lr:2.000e-04> G_loss: 1.042e-02 
22-01-12 01:06:38.121 : <epoch: 29, iter:   8,400, lr:2.000e-04> G_loss: 2.869e-02 
22-01-12 01:07:04.779 : <epoch: 30, iter:   8,600, lr:2.000e-04> G_loss: 2.902e-02 
22-01-12 01:07:31.468 : <epoch: 31, iter:   8,800, lr:2.000e-04> G_loss: 3.920e-02 
22-01-12 01:07:57.672 : <epoch: 31, iter:   9,000, lr:2.000e-04> G_loss: 4.159e-02 
22-01-12 01:08:24.463 : <epoch: 32, iter:   9,200, lr:2.000e-04> G_loss: 3.886e-02 
22-01-12 01:08:51.073 : <epoch: 33, iter:   9,400, lr:2.000e-04> G_loss: 2.987e-02 
22-01-12 01:09:17.173 : <epoch: 33, iter:   9,600, lr:2.000e-04> G_loss: 2.449e-02 
22-01-12 01:09:43.803 : <epoch: 34, iter:   9,800, lr:2.000e-04> G_loss: 5.507e-02 
22-01-12 01:10:10.456 : <epoch: 35, iter:  10,000, lr:2.000e-04> G_loss: 3.535e-02 
22-01-12 01:10:10.456 : Saving the model.
22-01-12 01:10:11.130 : ---1-->  12003.png | 25.74dB
22-01-12 01:10:11.412 : ---2-->  12074.png | 29.02dB
22-01-12 01:10:11.707 : ---3-->  15004.png | 23.60dB
22-01-12 01:10:12.003 : ---4-->  15088.png | 24.47dB
22-01-12 01:10:12.310 : ---5-->  16052.png | 31.55dB
22-01-12 01:10:12.628 : ---6-->   2092.png | 28.73dB
22-01-12 01:10:12.898 : ---7-->   8049.png | 26.62dB
22-01-12 01:10:13.188 : ---8-->   8143.png | 19.74dB
22-01-12 01:10:13.229 : <epoch: 35, iter:  10,000, Average PSNR : 26.18dB

22-01-12 01:10:39.869 : <epoch: 36, iter:  10,200, lr:2.000e-04> G_loss: 1.869e-02 
22-01-12 01:11:05.900 : <epoch: 36, iter:  10,400, lr:2.000e-04> G_loss: 4.633e-02 
22-01-12 01:11:32.554 : <epoch: 37, iter:  10,600, lr:2.000e-04> G_loss: 3.098e-02 
22-01-12 01:11:59.329 : <epoch: 38, iter:  10,800, lr:2.000e-04> G_loss: 2.662e-02 
22-01-12 01:12:25.378 : <epoch: 38, iter:  11,000, lr:2.000e-04> G_loss: 7.506e-02 
22-01-12 01:12:52.026 : <epoch: 39, iter:  11,200, lr:2.000e-04> G_loss: 3.106e-02 
22-01-12 01:13:18.779 : <epoch: 40, iter:  11,400, lr:2.000e-04> G_loss: 3.645e-02 
22-01-12 01:13:44.829 : <epoch: 40, iter:  11,600, lr:2.000e-04> G_loss: 3.339e-02 
22-01-12 01:14:11.648 : <epoch: 41, iter:  11,800, lr:2.000e-04> G_loss: 4.956e-02 
22-01-12 01:14:38.295 : <epoch: 42, iter:  12,000, lr:2.000e-04> G_loss: 2.807e-02 
22-01-12 01:15:04.956 : <epoch: 43, iter:  12,200, lr:2.000e-04> G_loss: 2.026e-02 
22-01-12 01:15:30.986 : <epoch: 43, iter:  12,400, lr:2.000e-04> G_loss: 3.090e-02 
22-01-12 01:15:57.616 : <epoch: 44, iter:  12,600, lr:2.000e-04> G_loss: 7.306e-02 
22-01-12 01:16:24.255 : <epoch: 45, iter:  12,800, lr:2.000e-04> G_loss: 3.968e-02 
22-01-12 01:16:50.313 : <epoch: 45, iter:  13,000, lr:2.000e-04> G_loss: 3.450e-02 
22-01-12 01:17:16.957 : <epoch: 46, iter:  13,200, lr:2.000e-04> G_loss: 2.344e-02 
22-01-12 01:17:43.579 : <epoch: 47, iter:  13,400, lr:2.000e-04> G_loss: 1.676e-02 
22-01-12 01:18:10.199 : <epoch: 48, iter:  13,600, lr:2.000e-04> G_loss: 2.584e-02 
22-01-12 01:18:36.297 : <epoch: 48, iter:  13,800, lr:2.000e-04> G_loss: 4.446e-02 
22-01-12 01:19:02.945 : <epoch: 49, iter:  14,000, lr:2.000e-04> G_loss: 2.647e-02 
22-01-12 01:19:29.662 : <epoch: 50, iter:  14,200, lr:2.000e-04> G_loss: 4.922e-02 
22-01-12 01:19:55.739 : <epoch: 50, iter:  14,400, lr:2.000e-04> G_loss: 3.283e-02 
22-01-12 01:20:22.482 : <epoch: 51, iter:  14,600, lr:2.000e-04> G_loss: 1.678e-02 
22-01-12 01:20:49.039 : <epoch: 52, iter:  14,800, lr:2.000e-04> G_loss: 1.016e-02 
22-01-12 01:21:15.833 : <epoch: 53, iter:  15,000, lr:2.000e-04> G_loss: 1.936e-02 
22-01-12 01:21:15.833 : Saving the model.
22-01-12 01:21:16.554 : ---1-->  12003.png | 27.81dB
22-01-12 01:21:16.882 : ---2-->  12074.png | 30.54dB
22-01-12 01:21:17.201 : ---3-->  15004.png | 24.34dB
22-01-12 01:21:17.498 : ---4-->  15088.png | 24.94dB
22-01-12 01:21:17.799 : ---5-->  16052.png | 33.15dB
22-01-12 01:21:18.203 : ---6-->   2092.png | 28.75dB
22-01-12 01:21:18.492 : ---7-->   8049.png | 27.04dB
22-01-12 01:21:18.785 : ---8-->   8143.png | 19.91dB
22-01-12 01:21:18.822 : <epoch: 53, iter:  15,000, Average PSNR : 27.06dB

22-01-12 01:21:44.894 : <epoch: 53, iter:  15,200, lr:2.000e-04> G_loss: 3.827e-02 
22-01-12 01:22:11.501 : <epoch: 54, iter:  15,400, lr:2.000e-04> G_loss: 2.512e-02 
22-01-12 01:22:38.246 : <epoch: 55, iter:  15,600, lr:2.000e-04> G_loss: 5.058e-02 
22-01-12 01:23:04.222 : <epoch: 55, iter:  15,800, lr:2.000e-04> G_loss: 4.010e-02 
22-01-12 01:23:30.961 : <epoch: 56, iter:  16,000, lr:2.000e-04> G_loss: 2.338e-02 
22-01-12 01:23:57.558 : <epoch: 57, iter:  16,200, lr:2.000e-04> G_loss: 2.444e-02 
22-01-12 01:24:23.608 : <epoch: 57, iter:  16,400, lr:2.000e-04> G_loss: 2.376e-02 
22-01-12 01:24:50.392 : <epoch: 58, iter:  16,600, lr:2.000e-04> G_loss: 3.376e-02 
22-01-12 01:25:17.060 : <epoch: 59, iter:  16,800, lr:2.000e-04> G_loss: 2.031e-02 
22-01-12 01:25:43.664 : <epoch: 60, iter:  17,000, lr:2.000e-04> G_loss: 1.979e-02 
22-01-12 01:26:09.775 : <epoch: 60, iter:  17,200, lr:2.000e-04> G_loss: 4.144e-02 
22-01-12 01:26:36.410 : <epoch: 61, iter:  17,400, lr:2.000e-04> G_loss: 5.761e-02 
22-01-12 01:27:03.036 : <epoch: 62, iter:  17,600, lr:2.000e-04> G_loss: 1.020e-02 
22-01-12 01:27:29.127 : <epoch: 62, iter:  17,800, lr:2.000e-04> G_loss: 1.741e-02 
22-01-12 01:27:55.765 : <epoch: 63, iter:  18,000, lr:2.000e-04> G_loss: 2.179e-02 
22-01-12 01:28:22.581 : <epoch: 64, iter:  18,200, lr:2.000e-04> G_loss: 2.306e-02 
22-01-12 01:28:49.207 : <epoch: 65, iter:  18,400, lr:2.000e-04> G_loss: 1.525e-02 
22-01-12 01:29:15.232 : <epoch: 65, iter:  18,600, lr:2.000e-04> G_loss: 2.771e-02 
22-01-12 01:29:41.849 : <epoch: 66, iter:  18,800, lr:2.000e-04> G_loss: 7.938e-03 
22-01-12 01:30:08.498 : <epoch: 67, iter:  19,000, lr:2.000e-04> G_loss: 5.166e-02 
22-01-12 01:30:34.571 : <epoch: 67, iter:  19,200, lr:2.000e-04> G_loss: 4.859e-02 
22-01-12 01:31:01.193 : <epoch: 68, iter:  19,400, lr:2.000e-04> G_loss: 3.955e-02 
22-01-12 01:31:27.911 : <epoch: 69, iter:  19,600, lr:2.000e-04> G_loss: 1.759e-02 
22-01-12 01:31:53.977 : <epoch: 69, iter:  19,800, lr:2.000e-04> G_loss: 3.587e-02 
22-01-12 01:32:20.581 : <epoch: 70, iter:  20,000, lr:2.000e-04> G_loss: 6.361e-02 
22-01-12 01:32:20.582 : Saving the model.
22-01-12 01:32:21.223 : ---1-->  12003.png | 27.95dB
22-01-12 01:32:21.540 : ---2-->  12074.png | 30.02dB
22-01-12 01:32:21.828 : ---3-->  15004.png | 24.40dB
22-01-12 01:32:22.106 : ---4-->  15088.png | 24.88dB
22-01-12 01:32:22.406 : ---5-->  16052.png | 33.18dB
22-01-12 01:32:22.712 : ---6-->   2092.png | 28.90dB
22-01-12 01:32:22.999 : ---7-->   8049.png | 27.01dB
22-01-12 01:32:23.319 : ---8-->   8143.png | 20.01dB
22-01-12 01:32:23.351 : <epoch: 70, iter:  20,000, Average PSNR : 27.04dB

22-01-12 01:32:50.075 : <epoch: 71, iter:  20,200, lr:2.000e-04> G_loss: 5.742e-02 
22-01-12 01:33:16.862 : <epoch: 72, iter:  20,400, lr:2.000e-04> G_loss: 3.719e-02 
22-01-12 01:33:42.948 : <epoch: 72, iter:  20,600, lr:2.000e-04> G_loss: 1.404e-02 
22-01-12 01:34:09.724 : <epoch: 73, iter:  20,800, lr:2.000e-04> G_loss: 3.156e-02 
22-01-12 01:34:36.406 : <epoch: 74, iter:  21,000, lr:2.000e-04> G_loss: 1.797e-02 
22-01-12 01:35:02.555 : <epoch: 74, iter:  21,200, lr:2.000e-04> G_loss: 2.717e-02 
22-01-12 01:35:29.258 : <epoch: 75, iter:  21,400, lr:2.000e-04> G_loss: 3.885e-02 
22-01-12 01:35:55.947 : <epoch: 76, iter:  21,600, lr:2.000e-04> G_loss: 6.045e-02 
22-01-12 01:36:22.536 : <epoch: 77, iter:  21,800, lr:2.000e-04> G_loss: 2.369e-02 
22-01-12 01:36:48.602 : <epoch: 77, iter:  22,000, lr:2.000e-04> G_loss: 1.018e-02 
22-01-12 01:37:15.376 : <epoch: 78, iter:  22,200, lr:2.000e-04> G_loss: 3.922e-02 
22-01-12 01:37:42.132 : <epoch: 79, iter:  22,400, lr:2.000e-04> G_loss: 3.216e-02 
22-01-12 01:38:08.206 : <epoch: 79, iter:  22,600, lr:2.000e-04> G_loss: 3.374e-02 
22-01-12 01:38:34.851 : <epoch: 80, iter:  22,800, lr:2.000e-04> G_loss: 2.191e-02 
22-01-12 01:39:01.481 : <epoch: 81, iter:  23,000, lr:2.000e-04> G_loss: 2.183e-02 
22-01-12 01:39:27.579 : <epoch: 81, iter:  23,200, lr:2.000e-04> G_loss: 6.065e-03 
22-01-12 01:39:54.308 : <epoch: 82, iter:  23,400, lr:2.000e-04> G_loss: 1.922e-02 
22-01-12 01:40:20.950 : <epoch: 83, iter:  23,600, lr:2.000e-04> G_loss: 6.962e-03 
22-01-12 01:40:47.623 : <epoch: 84, iter:  23,800, lr:2.000e-04> G_loss: 1.278e-02 
22-01-12 01:41:13.823 : <epoch: 84, iter:  24,000, lr:2.000e-04> G_loss: 1.725e-02 
22-01-12 01:41:40.529 : <epoch: 85, iter:  24,200, lr:2.000e-04> G_loss: 2.747e-02 
22-01-12 01:42:07.200 : <epoch: 86, iter:  24,400, lr:2.000e-04> G_loss: 2.952e-02 
22-01-12 01:42:33.218 : <epoch: 86, iter:  24,600, lr:2.000e-04> G_loss: 2.549e-02 
22-01-12 01:42:59.843 : <epoch: 87, iter:  24,800, lr:2.000e-04> G_loss: 1.389e-02 
22-01-12 01:43:26.495 : <epoch: 88, iter:  25,000, lr:2.000e-04> G_loss: 3.459e-02 
22-01-12 01:43:26.495 : Saving the model.
22-01-12 01:43:27.158 : ---1-->  12003.png | 27.76dB
22-01-12 01:43:27.432 : ---2-->  12074.png | 30.21dB
22-01-12 01:43:27.739 : ---3-->  15004.png | 24.30dB
22-01-12 01:43:28.066 : ---4-->  15088.png | 24.87dB
22-01-12 01:43:28.363 : ---5-->  16052.png | 33.17dB
22-01-12 01:43:28.671 : ---6-->   2092.png | 28.83dB
22-01-12 01:43:28.929 : ---7-->   8049.png | 27.05dB
22-01-12 01:43:29.200 : ---8-->   8143.png | 19.91dB
22-01-12 01:43:29.232 : <epoch: 88, iter:  25,000, Average PSNR : 27.01dB

22-01-12 01:43:55.847 : <epoch: 89, iter:  25,200, lr:2.000e-04> G_loss: 1.713e-02 
22-01-12 01:44:22.081 : <epoch: 89, iter:  25,400, lr:2.000e-04> G_loss: 2.037e-02 
22-01-12 01:44:48.715 : <epoch: 90, iter:  25,600, lr:2.000e-04> G_loss: 1.130e-02 
22-01-12 01:45:15.380 : <epoch: 91, iter:  25,800, lr:2.000e-04> G_loss: 5.993e-02 
22-01-12 01:45:41.468 : <epoch: 91, iter:  26,000, lr:2.000e-04> G_loss: 2.258e-02 
22-01-12 01:46:08.093 : <epoch: 92, iter:  26,200, lr:2.000e-04> G_loss: 2.791e-02 
22-01-12 01:46:34.727 : <epoch: 93, iter:  26,400, lr:2.000e-04> G_loss: 1.554e-02 
22-01-12 01:47:00.782 : <epoch: 93, iter:  26,600, lr:2.000e-04> G_loss: 3.808e-02 
22-01-12 01:47:27.452 : <epoch: 94, iter:  26,800, lr:2.000e-04> G_loss: 5.285e-02 
22-01-12 01:47:54.068 : <epoch: 95, iter:  27,000, lr:2.000e-04> G_loss: 4.381e-02 
22-01-12 01:48:20.739 : <epoch: 96, iter:  27,200, lr:2.000e-04> G_loss: 1.981e-02 
22-01-12 01:48:46.853 : <epoch: 96, iter:  27,400, lr:2.000e-04> G_loss: 1.281e-02 
22-01-12 01:49:13.416 : <epoch: 97, iter:  27,600, lr:2.000e-04> G_loss: 2.113e-02 
22-01-12 01:49:40.059 : <epoch: 98, iter:  27,800, lr:2.000e-04> G_loss: 2.462e-02 
22-01-12 01:50:06.096 : <epoch: 98, iter:  28,000, lr:2.000e-04> G_loss: 2.002e-02 
22-01-12 01:50:32.731 : <epoch: 99, iter:  28,200, lr:2.000e-04> G_loss: 1.948e-02 
22-01-12 01:50:59.462 : <epoch:100, iter:  28,400, lr:2.000e-04> G_loss: 2.120e-02 
22-01-12 01:51:26.179 : <epoch:101, iter:  28,600, lr:2.000e-04> G_loss: 2.393e-02 
22-01-12 01:51:52.268 : <epoch:101, iter:  28,800, lr:2.000e-04> G_loss: 2.427e-02 
22-01-12 01:52:18.948 : <epoch:102, iter:  29,000, lr:2.000e-04> G_loss: 1.212e-02 
22-01-12 01:52:45.618 : <epoch:103, iter:  29,200, lr:2.000e-04> G_loss: 2.670e-02 
22-01-12 01:53:11.733 : <epoch:103, iter:  29,400, lr:2.000e-04> G_loss: 5.645e-02 
22-01-12 01:53:38.486 : <epoch:104, iter:  29,600, lr:2.000e-04> G_loss: 2.406e-02 
22-01-12 01:54:05.267 : <epoch:105, iter:  29,800, lr:2.000e-04> G_loss: 2.507e-02 
22-01-12 01:54:31.849 : <epoch:106, iter:  30,000, lr:2.000e-04> G_loss: 5.511e-02 
22-01-12 01:54:31.850 : Saving the model.
22-01-12 01:54:32.494 : ---1-->  12003.png | 27.36dB
22-01-12 01:54:32.806 : ---2-->  12074.png | 29.45dB
22-01-12 01:54:33.115 : ---3-->  15004.png | 24.08dB
22-01-12 01:54:33.393 : ---4-->  15088.png | 24.76dB
22-01-12 01:54:33.708 : ---5-->  16052.png | 32.97dB
22-01-12 01:54:34.022 : ---6-->   2092.png | 28.75dB
22-01-12 01:54:34.317 : ---7-->   8049.png | 26.79dB
22-01-12 01:54:34.602 : ---8-->   8143.png | 19.82dB
22-01-12 01:54:34.635 : <epoch:106, iter:  30,000, Average PSNR : 26.75dB

22-01-12 01:55:00.733 : <epoch:106, iter:  30,200, lr:2.000e-04> G_loss: 6.160e-02 
22-01-12 01:55:27.342 : <epoch:107, iter:  30,400, lr:2.000e-04> G_loss: 2.333e-02 
22-01-12 01:55:53.969 : <epoch:108, iter:  30,600, lr:2.000e-04> G_loss: 4.293e-02 
22-01-12 01:56:20.058 : <epoch:108, iter:  30,800, lr:2.000e-04> G_loss: 2.601e-02 
22-01-12 01:56:46.704 : <epoch:109, iter:  31,000, lr:2.000e-04> G_loss: 3.041e-02 
22-01-12 01:57:13.389 : <epoch:110, iter:  31,200, lr:2.000e-04> G_loss: 5.673e-02 
22-01-12 01:57:39.469 : <epoch:110, iter:  31,400, lr:2.000e-04> G_loss: 3.865e-02 
22-01-12 01:58:06.091 : <epoch:111, iter:  31,600, lr:2.000e-04> G_loss: 1.295e-02 
22-01-12 01:58:32.746 : <epoch:112, iter:  31,800, lr:2.000e-04> G_loss: 4.729e-02 
22-01-12 01:58:59.375 : <epoch:113, iter:  32,000, lr:2.000e-04> G_loss: 3.000e-02 
22-01-12 01:59:25.391 : <epoch:113, iter:  32,200, lr:2.000e-04> G_loss: 3.227e-02 
22-01-12 01:59:51.951 : <epoch:114, iter:  32,400, lr:2.000e-04> G_loss: 5.112e-02 
22-01-12 02:00:18.604 : <epoch:115, iter:  32,600, lr:2.000e-04> G_loss: 5.502e-02 
22-01-12 02:00:44.672 : <epoch:115, iter:  32,800, lr:2.000e-04> G_loss: 1.719e-02 
22-01-12 02:01:11.329 : <epoch:116, iter:  33,000, lr:2.000e-04> G_loss: 1.527e-02 
22-01-12 02:01:37.985 : <epoch:117, iter:  33,200, lr:2.000e-04> G_loss: 1.960e-02 
22-01-12 02:02:04.619 : <epoch:118, iter:  33,400, lr:2.000e-04> G_loss: 4.043e-02 
22-01-12 02:02:30.693 : <epoch:118, iter:  33,600, lr:2.000e-04> G_loss: 3.094e-02 
22-01-12 02:02:57.343 : <epoch:119, iter:  33,800, lr:2.000e-04> G_loss: 4.604e-02 
22-01-12 02:03:24.033 : <epoch:120, iter:  34,000, lr:2.000e-04> G_loss: 2.164e-02 
22-01-12 02:03:50.137 : <epoch:120, iter:  34,200, lr:2.000e-04> G_loss: 1.861e-02 
22-01-12 02:04:16.755 : <epoch:121, iter:  34,400, lr:2.000e-04> G_loss: 3.555e-02 
22-01-12 02:04:43.432 : <epoch:122, iter:  34,600, lr:2.000e-04> G_loss: 4.167e-02 
22-01-12 02:05:09.654 : <epoch:122, iter:  34,800, lr:2.000e-04> G_loss: 3.028e-02 
22-01-12 02:05:36.311 : <epoch:123, iter:  35,000, lr:2.000e-04> G_loss: 2.526e-02 
22-01-12 02:05:36.312 : Saving the model.
22-01-12 02:05:36.958 : ---1-->  12003.png | 28.08dB
22-01-12 02:05:37.267 : ---2-->  12074.png | 30.65dB
22-01-12 02:05:37.587 : ---3-->  15004.png | 24.44dB
22-01-12 02:05:37.902 : ---4-->  15088.png | 24.91dB
22-01-12 02:05:38.216 : ---5-->  16052.png | 33.31dB
22-01-12 02:05:38.562 : ---6-->   2092.png | 28.94dB
22-01-12 02:05:38.847 : ---7-->   8049.png | 27.02dB
22-01-12 02:05:39.131 : ---8-->   8143.png | 20.02dB
22-01-12 02:05:39.163 : <epoch:123, iter:  35,000, Average PSNR : 27.17dB

22-01-12 02:06:05.788 : <epoch:124, iter:  35,200, lr:2.000e-04> G_loss: 1.164e-02 
22-01-12 02:06:32.384 : <epoch:125, iter:  35,400, lr:2.000e-04> G_loss: 4.183e-02 
22-01-12 02:06:58.498 : <epoch:125, iter:  35,600, lr:2.000e-04> G_loss: 6.440e-02 
22-01-12 02:07:25.114 : <epoch:126, iter:  35,800, lr:2.000e-04> G_loss: 7.822e-03 
22-01-12 02:07:51.722 : <epoch:127, iter:  36,000, lr:2.000e-04> G_loss: 3.365e-02 
22-01-12 02:08:17.814 : <epoch:127, iter:  36,200, lr:2.000e-04> G_loss: 2.535e-02 
22-01-12 02:08:44.409 : <epoch:128, iter:  36,400, lr:2.000e-04> G_loss: 1.363e-02 
22-01-12 02:09:10.984 : <epoch:129, iter:  36,600, lr:2.000e-04> G_loss: 7.352e-02 
22-01-12 02:09:37.602 : <epoch:130, iter:  36,800, lr:2.000e-04> G_loss: 1.780e-02 
22-01-12 02:10:03.683 : <epoch:130, iter:  37,000, lr:2.000e-04> G_loss: 1.854e-02 
22-01-12 02:10:30.277 : <epoch:131, iter:  37,200, lr:2.000e-04> G_loss: 3.788e-02 
22-01-12 02:10:56.932 : <epoch:132, iter:  37,400, lr:2.000e-04> G_loss: 2.507e-02 
22-01-12 02:11:22.931 : <epoch:132, iter:  37,600, lr:2.000e-04> G_loss: 3.687e-02 
22-01-12 02:11:49.579 : <epoch:133, iter:  37,800, lr:2.000e-04> G_loss: 3.423e-02 
22-01-12 02:12:16.199 : <epoch:134, iter:  38,000, lr:2.000e-04> G_loss: 3.566e-02 
22-01-12 02:12:42.263 : <epoch:134, iter:  38,200, lr:2.000e-04> G_loss: 2.141e-02 
22-01-12 02:13:08.907 : <epoch:135, iter:  38,400, lr:2.000e-04> G_loss: 6.692e-02 
22-01-12 02:13:35.543 : <epoch:136, iter:  38,600, lr:2.000e-04> G_loss: 2.222e-02 
22-01-12 02:14:02.217 : <epoch:137, iter:  38,800, lr:2.000e-04> G_loss: 8.749e-02 
22-01-12 02:14:28.291 : <epoch:137, iter:  39,000, lr:2.000e-04> G_loss: 4.717e-02 
22-01-12 02:14:54.954 : <epoch:138, iter:  39,200, lr:2.000e-04> G_loss: 4.946e-02 
22-01-12 02:15:21.574 : <epoch:139, iter:  39,400, lr:2.000e-04> G_loss: 3.973e-02 
22-01-12 02:15:47.634 : <epoch:139, iter:  39,600, lr:2.000e-04> G_loss: 8.825e-03 
22-01-12 02:16:14.264 : <epoch:140, iter:  39,800, lr:2.000e-04> G_loss: 3.860e-02 
22-01-12 02:16:41.007 : <epoch:141, iter:  40,000, lr:2.000e-04> G_loss: 4.898e-02 
22-01-12 02:16:41.007 : Saving the model.
22-01-12 02:16:41.638 : ---1-->  12003.png | 28.01dB
22-01-12 02:16:41.933 : ---2-->  12074.png | 30.58dB
22-01-12 02:16:42.258 : ---3-->  15004.png | 24.42dB
22-01-12 02:16:42.540 : ---4-->  15088.png | 24.81dB
22-01-12 02:16:42.831 : ---5-->  16052.png | 33.31dB
22-01-12 02:16:43.111 : ---6-->   2092.png | 28.83dB
22-01-12 02:16:43.424 : ---7-->   8049.png | 27.06dB
22-01-12 02:16:43.714 : ---8-->   8143.png | 20.02dB
22-01-12 02:16:43.745 : <epoch:141, iter:  40,000, Average PSNR : 27.13dB

22-01-12 02:17:10.499 : <epoch:142, iter:  40,200, lr:2.000e-04> G_loss: 9.131e-03 
22-01-12 02:17:36.556 : <epoch:142, iter:  40,400, lr:2.000e-04> G_loss: 2.489e-02 
22-01-12 02:18:03.162 : <epoch:143, iter:  40,600, lr:2.000e-04> G_loss: 3.142e-02 
22-01-12 02:18:29.781 : <epoch:144, iter:  40,800, lr:2.000e-04> G_loss: 1.917e-02 
22-01-12 02:18:55.834 : <epoch:144, iter:  41,000, lr:2.000e-04> G_loss: 1.612e-02 
22-01-12 02:19:22.456 : <epoch:145, iter:  41,200, lr:2.000e-04> G_loss: 4.713e-02 
22-01-12 02:19:49.086 : <epoch:146, iter:  41,400, lr:2.000e-04> G_loss: 3.477e-02 
22-01-12 02:20:15.139 : <epoch:146, iter:  41,600, lr:2.000e-04> G_loss: 1.023e-02 
22-01-12 02:20:41.790 : <epoch:147, iter:  41,800, lr:2.000e-04> G_loss: 8.771e-02 
22-01-12 02:21:08.536 : <epoch:148, iter:  42,000, lr:2.000e-04> G_loss: 1.185e-02 
22-01-12 02:21:35.142 : <epoch:149, iter:  42,200, lr:2.000e-04> G_loss: 2.075e-02 
22-01-12 02:22:01.229 : <epoch:149, iter:  42,400, lr:2.000e-04> G_loss: 6.135e-02 
22-01-12 02:22:27.848 : <epoch:150, iter:  42,600, lr:2.000e-04> G_loss: 1.811e-02 
22-01-12 02:22:54.492 : <epoch:151, iter:  42,800, lr:2.000e-04> G_loss: 1.743e-02 
22-01-12 02:23:20.570 : <epoch:151, iter:  43,000, lr:2.000e-04> G_loss: 2.002e-02 
22-01-12 02:23:47.177 : <epoch:152, iter:  43,200, lr:2.000e-04> G_loss: 3.423e-02 
22-01-12 02:24:13.812 : <epoch:153, iter:  43,400, lr:2.000e-04> G_loss: 5.680e-02 
22-01-12 02:24:40.432 : <epoch:154, iter:  43,600, lr:2.000e-04> G_loss: 6.967e-03 
22-01-12 02:25:06.524 : <epoch:154, iter:  43,800, lr:2.000e-04> G_loss: 2.518e-02 
22-01-12 02:25:33.142 : <epoch:155, iter:  44,000, lr:2.000e-04> G_loss: 1.160e-02 
22-01-12 02:25:59.775 : <epoch:156, iter:  44,200, lr:2.000e-04> G_loss: 1.437e-02 
22-01-12 02:26:25.858 : <epoch:156, iter:  44,400, lr:2.000e-04> G_loss: 1.302e-02 
22-01-12 02:26:52.389 : <epoch:157, iter:  44,600, lr:2.000e-04> G_loss: 4.047e-02 
22-01-12 02:27:19.920 : <epoch:158, iter:  44,800, lr:2.000e-04> G_loss: 1.966e-02 
22-01-12 02:27:46.536 : <epoch:159, iter:  45,000, lr:2.000e-04> G_loss: 1.858e-02 
22-01-12 02:27:46.536 : Saving the model.
22-01-12 02:27:47.205 : ---1-->  12003.png | 28.11dB
22-01-12 02:27:47.516 : ---2-->  12074.png | 30.44dB
22-01-12 02:27:47.842 : ---3-->  15004.png | 24.45dB
22-01-12 02:27:48.143 : ---4-->  15088.png | 24.91dB
22-01-12 02:27:48.445 : ---5-->  16052.png | 33.34dB
22-01-12 02:27:48.768 : ---6-->   2092.png | 28.93dB
22-01-12 02:27:49.057 : ---7-->   8049.png | 27.02dB
22-01-12 02:27:49.340 : ---8-->   8143.png | 19.99dB
22-01-12 02:27:49.381 : <epoch:159, iter:  45,000, Average PSNR : 27.15dB

22-01-12 02:28:15.450 : <epoch:159, iter:  45,200, lr:2.000e-04> G_loss: 2.184e-02 
22-01-12 02:28:42.063 : <epoch:160, iter:  45,400, lr:2.000e-04> G_loss: 4.694e-02 
22-01-12 02:29:08.656 : <epoch:161, iter:  45,600, lr:2.000e-04> G_loss: 4.694e-02 
22-01-12 02:29:34.701 : <epoch:161, iter:  45,800, lr:2.000e-04> G_loss: 1.482e-02 
22-01-12 02:30:01.437 : <epoch:162, iter:  46,000, lr:2.000e-04> G_loss: 2.544e-02 
22-01-12 02:30:28.130 : <epoch:163, iter:  46,200, lr:2.000e-04> G_loss: 2.518e-02 
22-01-12 02:30:54.192 : <epoch:163, iter:  46,400, lr:2.000e-04> G_loss: 1.333e-02 
22-01-12 02:31:20.824 : <epoch:164, iter:  46,600, lr:2.000e-04> G_loss: 6.569e-02 
22-01-12 02:31:47.500 : <epoch:165, iter:  46,800, lr:2.000e-04> G_loss: 6.389e-02 
22-01-12 02:32:14.220 : <epoch:166, iter:  47,000, lr:2.000e-04> G_loss: 2.861e-02 
22-01-12 02:32:40.422 : <epoch:166, iter:  47,200, lr:2.000e-04> G_loss: 5.542e-02 
22-01-12 02:33:07.064 : <epoch:167, iter:  47,400, lr:2.000e-04> G_loss: 3.062e-02 
22-01-12 02:33:33.657 : <epoch:168, iter:  47,600, lr:2.000e-04> G_loss: 7.360e-02 
22-01-12 02:33:59.855 : <epoch:168, iter:  47,800, lr:2.000e-04> G_loss: 3.217e-02 
22-01-12 02:34:26.506 : <epoch:169, iter:  48,000, lr:2.000e-04> G_loss: 1.845e-02 
22-01-12 02:34:53.130 : <epoch:170, iter:  48,200, lr:2.000e-04> G_loss: 2.430e-02 
22-01-12 02:35:19.782 : <epoch:171, iter:  48,400, lr:2.000e-04> G_loss: 2.951e-02 
22-01-12 02:35:45.968 : <epoch:171, iter:  48,600, lr:2.000e-04> G_loss: 1.240e-02 
22-01-12 02:36:12.755 : <epoch:172, iter:  48,800, lr:2.000e-04> G_loss: 2.881e-02 
22-01-12 02:36:39.372 : <epoch:173, iter:  49,000, lr:2.000e-04> G_loss: 3.752e-02 
22-01-12 02:37:05.475 : <epoch:173, iter:  49,200, lr:2.000e-04> G_loss: 4.196e-02 
22-01-12 02:37:32.119 : <epoch:174, iter:  49,400, lr:2.000e-04> G_loss: 2.058e-02 
22-01-12 02:37:58.728 : <epoch:175, iter:  49,600, lr:2.000e-04> G_loss: 2.250e-02 
22-01-12 02:38:24.780 : <epoch:175, iter:  49,800, lr:2.000e-04> G_loss: 3.154e-02 
22-01-12 02:38:51.460 : <epoch:176, iter:  50,000, lr:2.000e-04> G_loss: 1.149e-02 
22-01-12 02:38:51.461 : Saving the model.
22-01-12 02:38:52.084 : ---1-->  12003.png | 28.18dB
22-01-12 02:38:52.377 : ---2-->  12074.png | 30.87dB
22-01-12 02:38:52.685 : ---3-->  15004.png | 24.54dB
22-01-12 02:38:53.001 : ---4-->  15088.png | 24.99dB
22-01-12 02:38:53.283 : ---5-->  16052.png | 33.54dB
22-01-12 02:38:53.585 : ---6-->   2092.png | 28.92dB
22-01-12 02:38:53.873 : ---7-->   8049.png | 27.15dB
22-01-12 02:38:54.155 : ---8-->   8143.png | 20.00dB
22-01-12 02:38:54.187 : <epoch:176, iter:  50,000, Average PSNR : 27.27dB

22-01-12 02:39:20.869 : <epoch:177, iter:  50,200, lr:2.000e-04> G_loss: 1.339e-02 
22-01-12 02:39:47.524 : <epoch:178, iter:  50,400, lr:2.000e-04> G_loss: 1.418e-02 
22-01-12 02:40:13.566 : <epoch:178, iter:  50,600, lr:2.000e-04> G_loss: 4.280e-02 
22-01-12 02:40:40.210 : <epoch:179, iter:  50,800, lr:2.000e-04> G_loss: 5.265e-02 
22-01-12 02:41:06.994 : <epoch:180, iter:  51,000, lr:2.000e-04> G_loss: 3.002e-02 
22-01-12 02:41:33.039 : <epoch:180, iter:  51,200, lr:2.000e-04> G_loss: 4.978e-02 
22-01-12 02:41:59.720 : <epoch:181, iter:  51,400, lr:2.000e-04> G_loss: 1.125e-02 
22-01-12 02:42:26.347 : <epoch:182, iter:  51,600, lr:2.000e-04> G_loss: 5.942e-02 
22-01-12 02:42:53.008 : <epoch:183, iter:  51,800, lr:2.000e-04> G_loss: 1.027e-02 
22-01-12 02:43:19.232 : <epoch:183, iter:  52,000, lr:2.000e-04> G_loss: 5.006e-02 
22-01-12 02:43:45.868 : <epoch:184, iter:  52,200, lr:2.000e-04> G_loss: 4.492e-02 
22-01-12 02:44:12.567 : <epoch:185, iter:  52,400, lr:2.000e-04> G_loss: 1.364e-02 
22-01-12 02:44:38.777 : <epoch:185, iter:  52,600, lr:2.000e-04> G_loss: 3.613e-02 
22-01-12 02:45:05.446 : <epoch:186, iter:  52,800, lr:2.000e-04> G_loss: 5.242e-02 
22-01-12 02:45:32.086 : <epoch:187, iter:  53,000, lr:2.000e-04> G_loss: 2.028e-02 
22-01-12 02:45:58.154 : <epoch:187, iter:  53,200, lr:2.000e-04> G_loss: 4.273e-02 
22-01-12 02:46:24.818 : <epoch:188, iter:  53,400, lr:2.000e-04> G_loss: 2.828e-02 
22-01-12 02:46:51.468 : <epoch:189, iter:  53,600, lr:2.000e-04> G_loss: 1.068e-02 
22-01-12 02:47:18.104 : <epoch:190, iter:  53,800, lr:2.000e-04> G_loss: 1.346e-02 
22-01-12 02:47:44.202 : <epoch:190, iter:  54,000, lr:2.000e-04> G_loss: 1.191e-02 
22-01-12 02:48:10.974 : <epoch:191, iter:  54,200, lr:2.000e-04> G_loss: 1.126e-02 
22-01-12 02:48:37.600 : <epoch:192, iter:  54,400, lr:2.000e-04> G_loss: 1.229e-02 
22-01-12 02:49:03.847 : <epoch:192, iter:  54,600, lr:2.000e-04> G_loss: 1.368e-02 
22-01-12 02:49:30.544 : <epoch:193, iter:  54,800, lr:2.000e-04> G_loss: 2.545e-02 
22-01-12 02:49:57.183 : <epoch:194, iter:  55,000, lr:2.000e-04> G_loss: 4.436e-02 
22-01-12 02:49:57.183 : Saving the model.
22-01-12 02:49:57.855 : ---1-->  12003.png | 28.17dB
22-01-12 02:49:58.131 : ---2-->  12074.png | 30.84dB
22-01-12 02:49:58.484 : ---3-->  15004.png | 24.51dB
22-01-12 02:49:58.797 : ---4-->  15088.png | 24.99dB
22-01-12 02:49:59.079 : ---5-->  16052.png | 33.48dB
22-01-12 02:49:59.387 : ---6-->   2092.png | 29.05dB
22-01-12 02:49:59.666 : ---7-->   8049.png | 27.16dB
22-01-12 02:49:59.949 : ---8-->   8143.png | 20.00dB
22-01-12 02:49:59.980 : <epoch:194, iter:  55,000, Average PSNR : 27.27dB

22-01-12 02:50:26.619 : <epoch:195, iter:  55,200, lr:2.000e-04> G_loss: 2.156e-02 
22-01-12 02:50:52.739 : <epoch:195, iter:  55,400, lr:2.000e-04> G_loss: 2.967e-02 
22-01-12 02:51:19.405 : <epoch:196, iter:  55,600, lr:2.000e-04> G_loss: 5.364e-02 
22-01-12 02:51:46.019 : <epoch:197, iter:  55,800, lr:2.000e-04> G_loss: 5.107e-02 
22-01-12 02:52:12.076 : <epoch:197, iter:  56,000, lr:2.000e-04> G_loss: 4.928e-02 
22-01-12 02:52:38.700 : <epoch:198, iter:  56,200, lr:2.000e-04> G_loss: 3.403e-02 
22-01-12 02:53:05.416 : <epoch:199, iter:  56,400, lr:2.000e-04> G_loss: 4.465e-02 
22-01-12 02:53:31.407 : <epoch:199, iter:  56,600, lr:2.000e-04> G_loss: 1.223e-02 
22-01-12 02:53:58.173 : <epoch:200, iter:  56,800, lr:2.000e-04> G_loss: 4.503e-02 
22-01-12 02:54:24.725 : <epoch:201, iter:  57,000, lr:2.000e-04> G_loss: 6.203e-02 
22-01-12 02:54:51.329 : <epoch:202, iter:  57,200, lr:2.000e-04> G_loss: 1.673e-02 
22-01-12 02:55:17.384 : <epoch:202, iter:  57,400, lr:2.000e-04> G_loss: 2.314e-02 
22-01-12 02:55:44.046 : <epoch:203, iter:  57,600, lr:2.000e-04> G_loss: 2.014e-02 
22-01-12 02:56:10.645 : <epoch:204, iter:  57,800, lr:2.000e-04> G_loss: 1.337e-02 
22-01-12 02:56:36.672 : <epoch:204, iter:  58,000, lr:2.000e-04> G_loss: 9.034e-02 
22-01-12 02:57:03.340 : <epoch:205, iter:  58,200, lr:2.000e-04> G_loss: 2.001e-02 
22-01-12 02:57:30.146 : <epoch:206, iter:  58,400, lr:2.000e-04> G_loss: 9.398e-03 
22-01-12 02:57:56.839 : <epoch:207, iter:  58,600, lr:2.000e-04> G_loss: 2.619e-02 
22-01-12 02:58:22.980 : <epoch:207, iter:  58,800, lr:2.000e-04> G_loss: 3.895e-02 
22-01-12 02:58:49.627 : <epoch:208, iter:  59,000, lr:2.000e-04> G_loss: 6.454e-02 
22-01-12 02:59:16.222 : <epoch:209, iter:  59,200, lr:2.000e-04> G_loss: 2.844e-02 
22-01-12 02:59:42.294 : <epoch:209, iter:  59,400, lr:2.000e-04> G_loss: 2.428e-02 
22-01-12 03:00:08.928 : <epoch:210, iter:  59,600, lr:2.000e-04> G_loss: 1.153e-02 
22-01-12 03:00:35.670 : <epoch:211, iter:  59,800, lr:2.000e-04> G_loss: 2.426e-02 
22-01-12 03:01:02.300 : <epoch:212, iter:  60,000, lr:2.000e-04> G_loss: 1.474e-02 
22-01-12 03:01:02.300 : Saving the model.
22-01-12 03:01:02.984 : ---1-->  12003.png | 28.27dB
22-01-12 03:01:03.291 : ---2-->  12074.png | 30.79dB
22-01-12 03:01:03.607 : ---3-->  15004.png | 24.54dB
22-01-12 03:01:03.939 : ---4-->  15088.png | 25.00dB
22-01-12 03:01:04.251 : ---5-->  16052.png | 33.56dB
22-01-12 03:01:04.558 : ---6-->   2092.png | 29.00dB
22-01-12 03:01:04.859 : ---7-->   8049.png | 27.19dB
22-01-12 03:01:05.164 : ---8-->   8143.png | 20.00dB
22-01-12 03:01:05.200 : <epoch:212, iter:  60,000, Average PSNR : 27.29dB

22-01-12 03:01:31.380 : <epoch:212, iter:  60,200, lr:2.000e-04> G_loss: 8.662e-02 
22-01-12 03:01:57.996 : <epoch:213, iter:  60,400, lr:2.000e-04> G_loss: 5.230e-02 
22-01-12 03:02:24.708 : <epoch:214, iter:  60,600, lr:2.000e-04> G_loss: 2.954e-02 
22-01-12 03:02:50.779 : <epoch:214, iter:  60,800, lr:2.000e-04> G_loss: 2.802e-02 
22-01-12 03:03:17.548 : <epoch:215, iter:  61,000, lr:2.000e-04> G_loss: 1.889e-02 
22-01-12 03:03:44.263 : <epoch:216, iter:  61,200, lr:2.000e-04> G_loss: 1.205e-02 
22-01-12 03:04:10.334 : <epoch:216, iter:  61,400, lr:2.000e-04> G_loss: 2.307e-02 
22-01-12 03:04:37.199 : <epoch:217, iter:  61,600, lr:2.000e-04> G_loss: 5.688e-02 
22-01-12 03:05:03.750 : <epoch:218, iter:  61,800, lr:2.000e-04> G_loss: 4.243e-02 
22-01-12 03:05:30.310 : <epoch:219, iter:  62,000, lr:2.000e-04> G_loss: 4.965e-02 
22-01-12 03:05:56.429 : <epoch:219, iter:  62,200, lr:2.000e-04> G_loss: 2.143e-02 
22-01-12 03:06:23.063 : <epoch:220, iter:  62,400, lr:2.000e-04> G_loss: 4.932e-02 
22-01-12 03:06:49.761 : <epoch:221, iter:  62,600, lr:2.000e-04> G_loss: 4.315e-02 
22-01-12 03:07:15.814 : <epoch:221, iter:  62,800, lr:2.000e-04> G_loss: 2.833e-02 
22-01-12 03:07:42.459 : <epoch:222, iter:  63,000, lr:2.000e-04> G_loss: 5.810e-02 
22-01-12 03:08:09.073 : <epoch:223, iter:  63,200, lr:2.000e-04> G_loss: 2.835e-02 
22-01-12 03:08:35.682 : <epoch:224, iter:  63,400, lr:2.000e-04> G_loss: 1.958e-02 
22-01-12 03:09:01.895 : <epoch:224, iter:  63,600, lr:2.000e-04> G_loss: 1.360e-02 
22-01-12 03:09:28.516 : <epoch:225, iter:  63,800, lr:2.000e-04> G_loss: 3.501e-02 
22-01-12 03:09:55.148 : <epoch:226, iter:  64,000, lr:2.000e-04> G_loss: 1.255e-02 
22-01-12 03:10:21.223 : <epoch:226, iter:  64,200, lr:2.000e-04> G_loss: 7.304e-02 
22-01-12 03:10:47.823 : <epoch:227, iter:  64,400, lr:2.000e-04> G_loss: 1.627e-02 
22-01-12 03:11:14.498 : <epoch:228, iter:  64,600, lr:2.000e-04> G_loss: 3.459e-02 
22-01-12 03:11:40.620 : <epoch:228, iter:  64,800, lr:2.000e-04> G_loss: 2.684e-02 
22-01-12 03:12:07.275 : <epoch:229, iter:  65,000, lr:2.000e-04> G_loss: 1.330e-02 
22-01-12 03:12:07.275 : Saving the model.
22-01-12 03:12:07.934 : ---1-->  12003.png | 28.13dB
22-01-12 03:12:08.218 : ---2-->  12074.png | 30.76dB
22-01-12 03:12:08.547 : ---3-->  15004.png | 24.48dB
22-01-12 03:12:08.841 : ---4-->  15088.png | 24.78dB
22-01-12 03:12:09.140 : ---5-->  16052.png | 33.25dB
22-01-12 03:12:09.442 : ---6-->   2092.png | 28.72dB
22-01-12 03:12:09.720 : ---7-->   8049.png | 26.88dB
22-01-12 03:12:10.015 : ---8-->   8143.png | 20.04dB
22-01-12 03:12:10.046 : <epoch:229, iter:  65,000, Average PSNR : 27.13dB

22-01-12 03:12:36.807 : <epoch:230, iter:  65,200, lr:2.000e-04> G_loss: 1.694e-02 
22-01-12 03:13:03.521 : <epoch:231, iter:  65,400, lr:2.000e-04> G_loss: 2.301e-02 
22-01-12 03:13:29.621 : <epoch:231, iter:  65,600, lr:2.000e-04> G_loss: 1.626e-02 
22-01-12 03:13:56.313 : <epoch:232, iter:  65,800, lr:2.000e-04> G_loss: 1.162e-02 
22-01-12 03:14:22.939 : <epoch:233, iter:  66,000, lr:2.000e-04> G_loss: 1.685e-02 
22-01-12 03:14:48.974 : <epoch:233, iter:  66,200, lr:2.000e-04> G_loss: 2.080e-02 
22-01-12 03:15:15.624 : <epoch:234, iter:  66,400, lr:2.000e-04> G_loss: 1.680e-02 
22-01-12 03:15:42.314 : <epoch:235, iter:  66,600, lr:2.000e-04> G_loss: 4.811e-02 
22-01-12 03:16:08.960 : <epoch:236, iter:  66,800, lr:2.000e-04> G_loss: 2.558e-02 
22-01-12 03:16:35.210 : <epoch:236, iter:  67,000, lr:2.000e-04> G_loss: 3.170e-02 
22-01-12 03:17:01.877 : <epoch:237, iter:  67,200, lr:2.000e-04> G_loss: 2.936e-02 
22-01-12 03:17:28.470 : <epoch:238, iter:  67,400, lr:2.000e-04> G_loss: 2.125e-02 
22-01-12 03:17:54.533 : <epoch:238, iter:  67,600, lr:2.000e-04> G_loss: 6.593e-02 
22-01-12 03:18:21.181 : <epoch:239, iter:  67,800, lr:2.000e-04> G_loss: 5.336e-02 
22-01-12 03:18:47.875 : <epoch:240, iter:  68,000, lr:2.000e-04> G_loss: 1.582e-02 
22-01-12 03:19:13.910 : <epoch:240, iter:  68,200, lr:2.000e-04> G_loss: 4.149e-02 
22-01-12 03:19:40.553 : <epoch:241, iter:  68,400, lr:2.000e-04> G_loss: 3.521e-02 
22-01-12 03:20:07.200 : <epoch:242, iter:  68,600, lr:2.000e-04> G_loss: 6.719e-02 
22-01-12 03:20:33.740 : <epoch:243, iter:  68,800, lr:2.000e-04> G_loss: 3.786e-02 
22-01-12 03:20:59.769 : <epoch:243, iter:  69,000, lr:2.000e-04> G_loss: 1.370e-02 
22-01-12 03:21:26.419 : <epoch:244, iter:  69,200, lr:2.000e-04> G_loss: 5.594e-02 
22-01-12 03:21:53.165 : <epoch:245, iter:  69,400, lr:2.000e-04> G_loss: 3.732e-02 
22-01-12 03:22:19.226 : <epoch:245, iter:  69,600, lr:2.000e-04> G_loss: 1.470e-02 
22-01-12 03:22:45.869 : <epoch:246, iter:  69,800, lr:2.000e-04> G_loss: 3.336e-02 
22-01-12 03:23:12.489 : <epoch:247, iter:  70,000, lr:2.000e-04> G_loss: 3.788e-02 
22-01-12 03:23:12.489 : Saving the model.
22-01-12 03:23:13.124 : ---1-->  12003.png | 28.17dB
22-01-12 03:23:13.457 : ---2-->  12074.png | 30.91dB
22-01-12 03:23:13.767 : ---3-->  15004.png | 24.53dB
22-01-12 03:23:14.066 : ---4-->  15088.png | 24.97dB
22-01-12 03:23:14.381 : ---5-->  16052.png | 33.51dB
22-01-12 03:23:14.714 : ---6-->   2092.png | 28.98dB
22-01-12 03:23:15.011 : ---7-->   8049.png | 27.14dB
22-01-12 03:23:15.301 : ---8-->   8143.png | 20.04dB
22-01-12 03:23:15.333 : <epoch:247, iter:  70,000, Average PSNR : 27.28dB

22-01-12 03:23:41.940 : <epoch:248, iter:  70,200, lr:2.000e-04> G_loss: 1.462e-02 
22-01-12 03:24:08.084 : <epoch:248, iter:  70,400, lr:2.000e-04> G_loss: 4.943e-02 
22-01-12 03:24:34.745 : <epoch:249, iter:  70,600, lr:2.000e-04> G_loss: 1.882e-02 
22-01-12 03:25:01.386 : <epoch:250, iter:  70,800, lr:2.000e-04> G_loss: 4.862e-02 
22-01-12 03:25:27.418 : <epoch:250, iter:  71,000, lr:2.000e-04> G_loss: 2.290e-02 
22-01-12 03:25:54.118 : <epoch:251, iter:  71,200, lr:2.000e-04> G_loss: 3.158e-02 
22-01-12 03:26:20.754 : <epoch:252, iter:  71,400, lr:2.000e-04> G_loss: 3.993e-02 
22-01-12 03:26:47.383 : <epoch:253, iter:  71,600, lr:2.000e-04> G_loss: 4.797e-02 
22-01-12 03:27:13.440 : <epoch:253, iter:  71,800, lr:2.000e-04> G_loss: 4.097e-02 
22-01-12 03:27:40.085 : <epoch:254, iter:  72,000, lr:2.000e-04> G_loss: 2.254e-02 
22-01-12 03:28:06.892 : <epoch:255, iter:  72,200, lr:2.000e-04> G_loss: 2.001e-02 
22-01-12 03:28:32.969 : <epoch:255, iter:  72,400, lr:2.000e-04> G_loss: 1.100e-02 
22-01-12 03:28:59.644 : <epoch:256, iter:  72,600, lr:2.000e-04> G_loss: 3.974e-02 
22-01-12 03:29:26.253 : <epoch:257, iter:  72,800, lr:2.000e-04> G_loss: 1.897e-02 
22-01-12 03:29:52.443 : <epoch:257, iter:  73,000, lr:2.000e-04> G_loss: 2.352e-02 
22-01-12 03:30:19.123 : <epoch:258, iter:  73,200, lr:2.000e-04> G_loss: 5.042e-02 
22-01-12 03:30:45.779 : <epoch:259, iter:  73,400, lr:2.000e-04> G_loss: 3.684e-02 
22-01-12 03:31:12.404 : <epoch:260, iter:  73,600, lr:2.000e-04> G_loss: 1.196e-02 
22-01-12 03:31:38.484 : <epoch:260, iter:  73,800, lr:2.000e-04> G_loss: 7.098e-02 
22-01-12 03:32:05.192 : <epoch:261, iter:  74,000, lr:2.000e-04> G_loss: 2.924e-02 
22-01-12 03:32:31.866 : <epoch:262, iter:  74,200, lr:2.000e-04> G_loss: 1.751e-02 
22-01-12 03:32:58.024 : <epoch:262, iter:  74,400, lr:2.000e-04> G_loss: 1.341e-02 
22-01-12 03:33:24.645 : <epoch:263, iter:  74,600, lr:2.000e-04> G_loss: 4.379e-02 
22-01-12 03:33:51.302 : <epoch:264, iter:  74,800, lr:2.000e-04> G_loss: 3.802e-02 
22-01-12 03:34:17.940 : <epoch:265, iter:  75,000, lr:2.000e-04> G_loss: 3.488e-02 
22-01-12 03:34:17.940 : Saving the model.
22-01-12 03:34:18.605 : ---1-->  12003.png | 28.30dB
22-01-12 03:34:18.909 : ---2-->  12074.png | 30.93dB
22-01-12 03:34:19.221 : ---3-->  15004.png | 24.55dB
22-01-12 03:34:19.543 : ---4-->  15088.png | 25.00dB
22-01-12 03:34:19.868 : ---5-->  16052.png | 33.53dB
22-01-12 03:34:20.200 : ---6-->   2092.png | 29.07dB
22-01-12 03:34:20.483 : ---7-->   8049.png | 27.19dB
22-01-12 03:34:20.787 : ---8-->   8143.png | 20.01dB
22-01-12 03:34:20.820 : <epoch:265, iter:  75,000, Average PSNR : 27.32dB

22-01-12 03:34:46.931 : <epoch:265, iter:  75,200, lr:2.000e-04> G_loss: 6.422e-03 
22-01-12 03:35:13.541 : <epoch:266, iter:  75,400, lr:2.000e-04> G_loss: 2.700e-02 
22-01-12 03:35:40.197 : <epoch:267, iter:  75,600, lr:2.000e-04> G_loss: 4.855e-02 
22-01-12 03:36:06.285 : <epoch:267, iter:  75,800, lr:2.000e-04> G_loss: 4.465e-02 
22-01-12 03:36:32.915 : <epoch:268, iter:  76,000, lr:2.000e-04> G_loss: 2.074e-02 
22-01-12 03:36:59.505 : <epoch:269, iter:  76,200, lr:2.000e-04> G_loss: 5.121e-02 
22-01-12 03:37:25.561 : <epoch:269, iter:  76,400, lr:2.000e-04> G_loss: 3.537e-02 
22-01-12 03:37:52.207 : <epoch:270, iter:  76,600, lr:2.000e-04> G_loss: 5.780e-02 
22-01-12 03:38:18.799 : <epoch:271, iter:  76,800, lr:2.000e-04> G_loss: 2.139e-02 
22-01-12 03:38:45.506 : <epoch:272, iter:  77,000, lr:2.000e-04> G_loss: 1.679e-02 
22-01-12 03:39:11.614 : <epoch:272, iter:  77,200, lr:2.000e-04> G_loss: 1.308e-02 
22-01-12 03:39:38.242 : <epoch:273, iter:  77,400, lr:2.000e-04> G_loss: 2.714e-02 
22-01-12 03:40:04.898 : <epoch:274, iter:  77,600, lr:2.000e-04> G_loss: 1.574e-02 
22-01-12 03:40:30.970 : <epoch:274, iter:  77,800, lr:2.000e-04> G_loss: 2.523e-02 
22-01-12 03:40:57.668 : <epoch:275, iter:  78,000, lr:2.000e-04> G_loss: 2.596e-02 
22-01-12 03:41:24.387 : <epoch:276, iter:  78,200, lr:2.000e-04> G_loss: 2.671e-02 
22-01-12 03:41:50.959 : <epoch:277, iter:  78,400, lr:2.000e-04> G_loss: 2.438e-02 
22-01-12 03:42:17.028 : <epoch:277, iter:  78,600, lr:2.000e-04> G_loss: 8.987e-03 
22-01-12 03:42:43.685 : <epoch:278, iter:  78,800, lr:2.000e-04> G_loss: 3.050e-02 
22-01-12 03:43:10.390 : <epoch:279, iter:  79,000, lr:2.000e-04> G_loss: 2.831e-02 
22-01-12 03:43:36.407 : <epoch:279, iter:  79,200, lr:2.000e-04> G_loss: 3.584e-02 
22-01-12 03:44:03.011 : <epoch:280, iter:  79,400, lr:2.000e-04> G_loss: 2.639e-02 
22-01-12 03:44:29.666 : <epoch:281, iter:  79,600, lr:2.000e-04> G_loss: 3.535e-02 
22-01-12 03:44:55.728 : <epoch:281, iter:  79,800, lr:2.000e-04> G_loss: 3.154e-02 
22-01-12 03:45:22.514 : <epoch:282, iter:  80,000, lr:2.000e-04> G_loss: 3.936e-02 
22-01-12 03:45:22.514 : Saving the model.
22-01-12 03:45:23.155 : ---1-->  12003.png | 28.20dB
22-01-12 03:45:23.464 : ---2-->  12074.png | 30.68dB
22-01-12 03:45:23.780 : ---3-->  15004.png | 24.49dB
22-01-12 03:45:24.120 : ---4-->  15088.png | 24.93dB
22-01-12 03:45:24.442 : ---5-->  16052.png | 33.29dB
22-01-12 03:45:24.760 : ---6-->   2092.png | 28.80dB
22-01-12 03:45:25.080 : ---7-->   8049.png | 27.11dB
22-01-12 03:45:25.405 : ---8-->   8143.png | 20.03dB
22-01-12 03:45:25.437 : <epoch:282, iter:  80,000, Average PSNR : 27.19dB

22-01-12 03:45:52.075 : <epoch:283, iter:  80,200, lr:2.000e-04> G_loss: 2.707e-02 
22-01-12 03:46:18.731 : <epoch:284, iter:  80,400, lr:2.000e-04> G_loss: 4.695e-02 
22-01-12 03:46:44.913 : <epoch:284, iter:  80,600, lr:2.000e-04> G_loss: 2.383e-02 
22-01-12 03:47:11.567 : <epoch:285, iter:  80,800, lr:2.000e-04> G_loss: 2.458e-02 
22-01-12 03:47:38.226 : <epoch:286, iter:  81,000, lr:2.000e-04> G_loss: 5.184e-02 
22-01-12 03:48:04.297 : <epoch:286, iter:  81,200, lr:2.000e-04> G_loss: 3.040e-02 
22-01-12 03:48:30.943 : <epoch:287, iter:  81,400, lr:2.000e-04> G_loss: 1.357e-02 
22-01-12 03:48:57.707 : <epoch:288, iter:  81,600, lr:2.000e-04> G_loss: 2.632e-02 
22-01-12 03:49:24.249 : <epoch:289, iter:  81,800, lr:2.000e-04> G_loss: 1.382e-02 
22-01-12 03:49:50.278 : <epoch:289, iter:  82,000, lr:2.000e-04> G_loss: 2.039e-02 
22-01-12 03:50:16.922 : <epoch:290, iter:  82,200, lr:2.000e-04> G_loss: 1.028e-02 
22-01-12 03:50:43.575 : <epoch:291, iter:  82,400, lr:2.000e-04> G_loss: 2.591e-02 
22-01-12 03:51:09.660 : <epoch:291, iter:  82,600, lr:2.000e-04> G_loss: 2.215e-02 
22-01-12 03:51:36.337 : <epoch:292, iter:  82,800, lr:2.000e-04> G_loss: 2.109e-02 
22-01-12 03:52:03.015 : <epoch:293, iter:  83,000, lr:2.000e-04> G_loss: 3.470e-02 
22-01-12 03:52:29.049 : <epoch:293, iter:  83,200, lr:2.000e-04> G_loss: 3.082e-02 
22-01-12 03:52:55.811 : <epoch:294, iter:  83,400, lr:2.000e-04> G_loss: 3.386e-02 
22-01-12 03:53:22.535 : <epoch:295, iter:  83,600, lr:2.000e-04> G_loss: 1.962e-02 
22-01-12 03:53:49.215 : <epoch:296, iter:  83,800, lr:2.000e-04> G_loss: 5.334e-02 
22-01-12 03:54:15.371 : <epoch:296, iter:  84,000, lr:2.000e-04> G_loss: 3.074e-02 
22-01-12 03:54:42.019 : <epoch:297, iter:  84,200, lr:2.000e-04> G_loss: 3.247e-02 
22-01-12 03:55:08.786 : <epoch:298, iter:  84,400, lr:2.000e-04> G_loss: 4.565e-02 
22-01-12 03:55:34.836 : <epoch:298, iter:  84,600, lr:2.000e-04> G_loss: 1.283e-02 
22-01-12 03:56:01.479 : <epoch:299, iter:  84,800, lr:2.000e-04> G_loss: 1.859e-02 
22-01-12 03:56:28.147 : <epoch:300, iter:  85,000, lr:2.000e-04> G_loss: 5.115e-02 
22-01-12 03:56:28.147 : Saving the model.
22-01-12 03:56:28.790 : ---1-->  12003.png | 28.11dB
22-01-12 03:56:29.081 : ---2-->  12074.png | 30.79dB
22-01-12 03:56:29.392 : ---3-->  15004.png | 24.49dB
22-01-12 03:56:29.712 : ---4-->  15088.png | 24.99dB
22-01-12 03:56:29.988 : ---5-->  16052.png | 33.43dB
22-01-12 03:56:30.265 : ---6-->   2092.png | 29.05dB
22-01-12 03:56:30.544 : ---7-->   8049.png | 27.18dB
22-01-12 03:56:30.849 : ---8-->   8143.png | 20.01dB
22-01-12 03:56:30.881 : <epoch:300, iter:  85,000, Average PSNR : 27.26dB

22-01-12 03:56:57.467 : <epoch:301, iter:  85,200, lr:2.000e-04> G_loss: 3.896e-03 
22-01-12 03:57:23.496 : <epoch:301, iter:  85,400, lr:2.000e-04> G_loss: 1.198e-02 
22-01-12 03:57:50.082 : <epoch:302, iter:  85,600, lr:2.000e-04> G_loss: 2.541e-02 
22-01-12 03:58:16.597 : <epoch:303, iter:  85,800, lr:2.000e-04> G_loss: 2.603e-02 
22-01-12 03:58:42.647 : <epoch:303, iter:  86,000, lr:2.000e-04> G_loss: 2.201e-02 
22-01-12 03:59:09.335 : <epoch:304, iter:  86,200, lr:2.000e-04> G_loss: 3.582e-02 
22-01-12 03:59:36.003 : <epoch:305, iter:  86,400, lr:2.000e-04> G_loss: 2.672e-02 
22-01-12 04:00:02.772 : <epoch:306, iter:  86,600, lr:2.000e-04> G_loss: 3.909e-02 
22-01-12 04:00:28.809 : <epoch:306, iter:  86,800, lr:2.000e-04> G_loss: 5.615e-02 
22-01-12 04:00:55.431 : <epoch:307, iter:  87,000, lr:2.000e-04> G_loss: 6.511e-02 
22-01-12 04:01:22.067 : <epoch:308, iter:  87,200, lr:2.000e-04> G_loss: 3.763e-02 
22-01-12 04:01:48.158 : <epoch:308, iter:  87,400, lr:2.000e-04> G_loss: 2.326e-02 
22-01-12 04:02:14.818 : <epoch:309, iter:  87,600, lr:2.000e-04> G_loss: 1.255e-02 
22-01-12 04:02:41.510 : <epoch:310, iter:  87,800, lr:2.000e-04> G_loss: 5.120e-02 
22-01-12 04:03:07.615 : <epoch:310, iter:  88,000, lr:2.000e-04> G_loss: 5.216e-02 
22-01-12 04:03:34.273 : <epoch:311, iter:  88,200, lr:2.000e-04> G_loss: 2.575e-02 
22-01-12 04:04:00.861 : <epoch:312, iter:  88,400, lr:2.000e-04> G_loss: 4.884e-02 
22-01-12 04:04:27.526 : <epoch:313, iter:  88,600, lr:2.000e-04> G_loss: 5.972e-02 
22-01-12 04:04:53.574 : <epoch:313, iter:  88,800, lr:2.000e-04> G_loss: 1.686e-02 
22-01-12 04:05:20.370 : <epoch:314, iter:  89,000, lr:2.000e-04> G_loss: 2.268e-02 
22-01-12 04:05:47.070 : <epoch:315, iter:  89,200, lr:2.000e-04> G_loss: 3.909e-02 
22-01-12 04:06:13.128 : <epoch:315, iter:  89,400, lr:2.000e-04> G_loss: 2.880e-02 
22-01-12 04:06:39.780 : <epoch:316, iter:  89,600, lr:2.000e-04> G_loss: 4.091e-02 
22-01-12 04:07:06.431 : <epoch:317, iter:  89,800, lr:2.000e-04> G_loss: 4.499e-02 
22-01-12 04:07:33.053 : <epoch:318, iter:  90,000, lr:2.000e-04> G_loss: 3.645e-02 
22-01-12 04:07:33.053 : Saving the model.
22-01-12 04:07:33.712 : ---1-->  12003.png | 28.28dB
22-01-12 04:07:34.020 : ---2-->  12074.png | 30.79dB
22-01-12 04:07:34.359 : ---3-->  15004.png | 24.54dB
22-01-12 04:07:34.680 : ---4-->  15088.png | 24.98dB
22-01-12 04:07:34.987 : ---5-->  16052.png | 33.46dB
22-01-12 04:07:35.318 : ---6-->   2092.png | 29.06dB
22-01-12 04:07:35.597 : ---7-->   8049.png | 27.17dB
22-01-12 04:07:35.870 : ---8-->   8143.png | 20.02dB
22-01-12 04:07:35.902 : <epoch:318, iter:  90,000, Average PSNR : 27.29dB

22-01-12 04:08:01.961 : <epoch:318, iter:  90,200, lr:2.000e-04> G_loss: 1.879e-02 
22-01-12 04:08:28.715 : <epoch:319, iter:  90,400, lr:2.000e-04> G_loss: 3.416e-02 
22-01-12 04:08:55.346 : <epoch:320, iter:  90,600, lr:2.000e-04> G_loss: 2.124e-02 
22-01-12 04:09:21.374 : <epoch:320, iter:  90,800, lr:2.000e-04> G_loss: 2.004e-02 
22-01-12 04:09:47.999 : <epoch:321, iter:  91,000, lr:2.000e-04> G_loss: 3.218e-02 
22-01-12 04:10:14.648 : <epoch:322, iter:  91,200, lr:2.000e-04> G_loss: 3.703e-02 
22-01-12 04:10:40.671 : <epoch:322, iter:  91,400, lr:2.000e-04> G_loss: 2.022e-02 
22-01-12 04:11:07.300 : <epoch:323, iter:  91,600, lr:2.000e-04> G_loss: 1.244e-02 
22-01-12 04:11:33.996 : <epoch:324, iter:  91,800, lr:2.000e-04> G_loss: 2.150e-02 
22-01-12 04:12:00.898 : <epoch:325, iter:  92,000, lr:2.000e-04> G_loss: 3.357e-02 
22-01-12 04:12:26.945 : <epoch:325, iter:  92,200, lr:2.000e-04> G_loss: 2.030e-02 
22-01-12 04:12:53.687 : <epoch:326, iter:  92,400, lr:2.000e-04> G_loss: 2.091e-02 
22-01-12 04:13:20.464 : <epoch:327, iter:  92,600, lr:2.000e-04> G_loss: 2.196e-02 
22-01-12 04:13:46.496 : <epoch:327, iter:  92,800, lr:2.000e-04> G_loss: 3.856e-02 
22-01-12 04:14:13.237 : <epoch:328, iter:  93,000, lr:2.000e-04> G_loss: 2.206e-02 
22-01-12 04:14:39.877 : <epoch:329, iter:  93,200, lr:2.000e-04> G_loss: 4.840e-02 
22-01-12 04:15:06.539 : <epoch:330, iter:  93,400, lr:2.000e-04> G_loss: 5.569e-02 
22-01-12 04:15:32.584 : <epoch:330, iter:  93,600, lr:2.000e-04> G_loss: 3.497e-02 
22-01-12 04:15:59.214 : <epoch:331, iter:  93,800, lr:2.000e-04> G_loss: 1.237e-02 
22-01-12 04:16:25.820 : <epoch:332, iter:  94,000, lr:2.000e-04> G_loss: 3.406e-02 
22-01-12 04:16:51.875 : <epoch:332, iter:  94,200, lr:2.000e-04> G_loss: 2.640e-02 
22-01-12 04:17:18.512 : <epoch:333, iter:  94,400, lr:2.000e-04> G_loss: 3.130e-02 
22-01-12 04:17:45.134 : <epoch:334, iter:  94,600, lr:2.000e-04> G_loss: 1.480e-02 
22-01-12 04:18:11.193 : <epoch:334, iter:  94,800, lr:2.000e-04> G_loss: 1.286e-02 
22-01-12 04:18:37.824 : <epoch:335, iter:  95,000, lr:2.000e-04> G_loss: 1.610e-02 
22-01-12 04:18:37.825 : Saving the model.
22-01-12 04:18:38.506 : ---1-->  12003.png | 28.26dB
22-01-12 04:18:38.816 : ---2-->  12074.png | 30.88dB
22-01-12 04:18:39.123 : ---3-->  15004.png | 24.50dB
22-01-12 04:18:39.416 : ---4-->  15088.png | 25.01dB
22-01-12 04:18:39.719 : ---5-->  16052.png | 33.50dB
22-01-12 04:18:40.028 : ---6-->   2092.png | 29.04dB
22-01-12 04:18:40.322 : ---7-->   8049.png | 27.20dB
22-01-12 04:18:40.578 : ---8-->   8143.png | 20.05dB
22-01-12 04:18:40.609 : <epoch:335, iter:  95,000, Average PSNR : 27.30dB

22-01-12 04:19:07.348 : <epoch:336, iter:  95,200, lr:2.000e-04> G_loss: 1.677e-02 
22-01-12 04:19:33.975 : <epoch:337, iter:  95,400, lr:2.000e-04> G_loss: 4.656e-02 
22-01-12 04:20:00.062 : <epoch:337, iter:  95,600, lr:2.000e-04> G_loss: 1.882e-02 
22-01-12 04:20:26.695 : <epoch:338, iter:  95,800, lr:2.000e-04> G_loss: 2.363e-02 
22-01-12 04:20:53.347 : <epoch:339, iter:  96,000, lr:2.000e-04> G_loss: 2.623e-02 
22-01-12 04:21:19.398 : <epoch:339, iter:  96,200, lr:2.000e-04> G_loss: 1.874e-02 
22-01-12 04:21:46.084 : <epoch:340, iter:  96,400, lr:2.000e-04> G_loss: 1.920e-02 
22-01-12 04:22:12.727 : <epoch:341, iter:  96,600, lr:2.000e-04> G_loss: 2.091e-02 
22-01-12 04:22:39.373 : <epoch:342, iter:  96,800, lr:2.000e-04> G_loss: 8.458e-03 
22-01-12 04:23:05.451 : <epoch:342, iter:  97,000, lr:2.000e-04> G_loss: 2.515e-02 
22-01-12 04:23:32.078 : <epoch:343, iter:  97,200, lr:2.000e-04> G_loss: 4.687e-02 
22-01-12 04:23:58.747 : <epoch:344, iter:  97,400, lr:2.000e-04> G_loss: 3.736e-02 
22-01-12 04:24:24.821 : <epoch:344, iter:  97,600, lr:2.000e-04> G_loss: 1.459e-02 
22-01-12 04:24:51.521 : <epoch:345, iter:  97,800, lr:2.000e-04> G_loss: 4.356e-02 
22-01-12 04:25:18.215 : <epoch:346, iter:  98,000, lr:2.000e-04> G_loss: 1.439e-02 
22-01-12 04:25:44.264 : <epoch:346, iter:  98,200, lr:2.000e-04> G_loss: 4.150e-02 
22-01-12 04:26:10.941 : <epoch:347, iter:  98,400, lr:2.000e-04> G_loss: 8.492e-03 
22-01-12 04:26:37.562 : <epoch:348, iter:  98,600, lr:2.000e-04> G_loss: 2.872e-02 
22-01-12 04:27:04.221 : <epoch:349, iter:  98,800, lr:2.000e-04> G_loss: 4.717e-02 
22-01-12 04:27:30.284 : <epoch:349, iter:  99,000, lr:2.000e-04> G_loss: 2.924e-02 
22-01-12 04:27:56.954 : <epoch:350, iter:  99,200, lr:2.000e-04> G_loss: 3.305e-03 
22-01-12 04:28:23.552 : <epoch:351, iter:  99,400, lr:2.000e-04> G_loss: 6.000e-02 
22-01-12 04:28:49.655 : <epoch:351, iter:  99,600, lr:2.000e-04> G_loss: 4.904e-02 
22-01-12 04:29:16.305 : <epoch:352, iter:  99,800, lr:2.000e-04> G_loss: 2.578e-02 
22-01-12 04:29:42.927 : <epoch:353, iter: 100,000, lr:2.000e-04> G_loss: 4.425e-02 
22-01-12 04:29:42.928 : Saving the model.
22-01-12 04:29:43.583 : ---1-->  12003.png | 28.19dB
22-01-12 04:29:43.864 : ---2-->  12074.png | 30.83dB
22-01-12 04:29:44.177 : ---3-->  15004.png | 24.53dB
22-01-12 04:29:44.486 : ---4-->  15088.png | 24.96dB
22-01-12 04:29:44.797 : ---5-->  16052.png | 33.35dB
22-01-12 04:29:45.121 : ---6-->   2092.png | 28.99dB
22-01-12 04:29:45.408 : ---7-->   8049.png | 27.11dB
22-01-12 04:29:45.723 : ---8-->   8143.png | 20.05dB
22-01-12 04:29:45.756 : <epoch:353, iter: 100,000, Average PSNR : 27.25dB

22-01-12 04:30:12.363 : <epoch:354, iter: 100,200, lr:2.000e-04> G_loss: 3.996e-02 
22-01-12 04:30:38.449 : <epoch:354, iter: 100,400, lr:2.000e-04> G_loss: 1.728e-02 
22-01-12 04:31:05.073 : <epoch:355, iter: 100,600, lr:2.000e-04> G_loss: 7.654e-03 
22-01-12 04:31:31.672 : <epoch:356, iter: 100,800, lr:2.000e-04> G_loss: 3.857e-02 
22-01-12 04:31:57.763 : <epoch:356, iter: 101,000, lr:2.000e-04> G_loss: 3.405e-02 
22-01-12 04:32:24.344 : <epoch:357, iter: 101,200, lr:2.000e-04> G_loss: 9.215e-03 
22-01-12 04:32:50.901 : <epoch:358, iter: 101,400, lr:2.000e-04> G_loss: 2.394e-02 
22-01-12 04:33:17.629 : <epoch:359, iter: 101,600, lr:2.000e-04> G_loss: 3.067e-02 
22-01-12 04:33:43.818 : <epoch:359, iter: 101,800, lr:2.000e-04> G_loss: 1.873e-02 
22-01-12 04:34:10.533 : <epoch:360, iter: 102,000, lr:2.000e-04> G_loss: 1.363e-02 
22-01-12 04:34:37.179 : <epoch:361, iter: 102,200, lr:2.000e-04> G_loss: 3.865e-02 
22-01-12 04:35:03.297 : <epoch:361, iter: 102,400, lr:2.000e-04> G_loss: 2.538e-02 
22-01-12 04:35:30.001 : <epoch:362, iter: 102,600, lr:2.000e-04> G_loss: 1.716e-02 
22-01-12 04:35:56.553 : <epoch:363, iter: 102,800, lr:2.000e-04> G_loss: 1.731e-02 
22-01-12 04:36:22.638 : <epoch:363, iter: 103,000, lr:2.000e-04> G_loss: 3.648e-02 
22-01-12 04:36:49.298 : <epoch:364, iter: 103,200, lr:2.000e-04> G_loss: 1.820e-02 
22-01-12 04:37:15.938 : <epoch:365, iter: 103,400, lr:2.000e-04> G_loss: 4.450e-03 
22-01-12 04:37:42.617 : <epoch:366, iter: 103,600, lr:2.000e-04> G_loss: 1.054e-02 
22-01-12 04:38:08.796 : <epoch:366, iter: 103,800, lr:2.000e-04> G_loss: 1.858e-02 
22-01-12 04:38:35.450 : <epoch:367, iter: 104,000, lr:2.000e-04> G_loss: 4.520e-02 
22-01-12 04:39:02.175 : <epoch:368, iter: 104,200, lr:2.000e-04> G_loss: 5.817e-02 
22-01-12 04:39:28.241 : <epoch:368, iter: 104,400, lr:2.000e-04> G_loss: 1.252e-02 
22-01-12 04:39:54.936 : <epoch:369, iter: 104,600, lr:2.000e-04> G_loss: 6.755e-02 
22-01-12 04:40:21.576 : <epoch:370, iter: 104,800, lr:2.000e-04> G_loss: 2.676e-02 
22-01-12 04:40:48.244 : <epoch:371, iter: 105,000, lr:2.000e-04> G_loss: 1.336e-02 
22-01-12 04:40:48.244 : Saving the model.
22-01-12 04:40:48.899 : ---1-->  12003.png | 28.38dB
22-01-12 04:40:49.215 : ---2-->  12074.png | 30.95dB
22-01-12 04:40:49.524 : ---3-->  15004.png | 24.55dB
22-01-12 04:40:49.855 : ---4-->  15088.png | 25.12dB
22-01-12 04:40:50.147 : ---5-->  16052.png | 33.37dB
22-01-12 04:40:50.460 : ---6-->   2092.png | 29.09dB
22-01-12 04:40:50.756 : ---7-->   8049.png | 27.34dB
22-01-12 04:40:51.054 : ---8-->   8143.png | 20.08dB
22-01-12 04:40:51.086 : <epoch:371, iter: 105,000, Average PSNR : 27.36dB

22-01-12 04:41:17.193 : <epoch:371, iter: 105,200, lr:2.000e-04> G_loss: 4.768e-02 
22-01-12 04:41:43.774 : <epoch:372, iter: 105,400, lr:2.000e-04> G_loss: 1.154e-02 
22-01-12 04:42:10.557 : <epoch:373, iter: 105,600, lr:2.000e-04> G_loss: 1.728e-02 
22-01-12 04:42:36.605 : <epoch:373, iter: 105,800, lr:2.000e-04> G_loss: 2.527e-02 
22-01-12 04:43:03.359 : <epoch:374, iter: 106,000, lr:2.000e-04> G_loss: 5.807e-02 
22-01-12 04:43:29.982 : <epoch:375, iter: 106,200, lr:2.000e-04> G_loss: 1.016e-02 
22-01-12 04:43:56.049 : <epoch:375, iter: 106,400, lr:2.000e-04> G_loss: 2.594e-03 
22-01-12 04:44:22.798 : <epoch:376, iter: 106,600, lr:2.000e-04> G_loss: 2.230e-02 
22-01-12 04:44:49.444 : <epoch:377, iter: 106,800, lr:2.000e-04> G_loss: 3.771e-02 
22-01-12 04:45:16.186 : <epoch:378, iter: 107,000, lr:2.000e-04> G_loss: 3.812e-02 
22-01-12 04:45:42.261 : <epoch:378, iter: 107,200, lr:2.000e-04> G_loss: 4.396e-02 
22-01-12 04:46:08.970 : <epoch:379, iter: 107,400, lr:2.000e-04> G_loss: 2.689e-02 
22-01-12 04:46:35.640 : <epoch:380, iter: 107,600, lr:2.000e-04> G_loss: 2.956e-02 
22-01-12 04:47:01.706 : <epoch:380, iter: 107,800, lr:2.000e-04> G_loss: 1.641e-02 
22-01-12 04:47:28.406 : <epoch:381, iter: 108,000, lr:2.000e-04> G_loss: 2.096e-02 
22-01-12 04:47:55.048 : <epoch:382, iter: 108,200, lr:2.000e-04> G_loss: 1.448e-02 
22-01-12 04:48:21.671 : <epoch:383, iter: 108,400, lr:2.000e-04> G_loss: 2.735e-02 
22-01-12 04:48:47.726 : <epoch:383, iter: 108,600, lr:2.000e-04> G_loss: 3.459e-02 
22-01-12 04:49:14.552 : <epoch:384, iter: 108,800, lr:2.000e-04> G_loss: 3.168e-02 
22-01-12 04:49:41.169 : <epoch:385, iter: 109,000, lr:2.000e-04> G_loss: 2.055e-02 
22-01-12 04:50:07.217 : <epoch:385, iter: 109,200, lr:2.000e-04> G_loss: 1.363e-02 
22-01-12 04:50:33.847 : <epoch:386, iter: 109,400, lr:2.000e-04> G_loss: 1.492e-02 
22-01-12 04:51:00.483 : <epoch:387, iter: 109,600, lr:2.000e-04> G_loss: 2.767e-02 
22-01-12 04:51:26.546 : <epoch:387, iter: 109,800, lr:2.000e-04> G_loss: 5.587e-02 
22-01-12 04:51:53.260 : <epoch:388, iter: 110,000, lr:2.000e-04> G_loss: 6.244e-02 
22-01-12 04:51:53.261 : Saving the model.
22-01-12 04:51:53.924 : ---1-->  12003.png | 28.39dB
22-01-12 04:51:54.236 : ---2-->  12074.png | 30.89dB
22-01-12 04:51:54.557 : ---3-->  15004.png | 24.58dB
22-01-12 04:51:54.848 : ---4-->  15088.png | 25.07dB
22-01-12 04:51:55.156 : ---5-->  16052.png | 33.45dB
22-01-12 04:51:55.473 : ---6-->   2092.png | 28.91dB
22-01-12 04:51:55.780 : ---7-->   8049.png | 27.25dB
22-01-12 04:51:56.094 : ---8-->   8143.png | 20.08dB
22-01-12 04:51:56.125 : <epoch:388, iter: 110,000, Average PSNR : 27.33dB

22-01-12 04:52:22.752 : <epoch:389, iter: 110,200, lr:2.000e-04> G_loss: 3.202e-02 
22-01-12 04:52:49.327 : <epoch:390, iter: 110,400, lr:2.000e-04> G_loss: 1.418e-02 
22-01-12 04:53:15.405 : <epoch:390, iter: 110,600, lr:2.000e-04> G_loss: 1.526e-02 
22-01-12 04:53:42.042 : <epoch:391, iter: 110,800, lr:2.000e-04> G_loss: 2.317e-02 
22-01-12 04:54:08.775 : <epoch:392, iter: 111,000, lr:2.000e-04> G_loss: 2.242e-02 
22-01-12 04:54:34.853 : <epoch:392, iter: 111,200, lr:2.000e-04> G_loss: 4.473e-02 
22-01-12 04:55:01.484 : <epoch:393, iter: 111,400, lr:2.000e-04> G_loss: 4.149e-02 
22-01-12 04:55:28.090 : <epoch:394, iter: 111,600, lr:2.000e-04> G_loss: 3.052e-02 
22-01-12 04:55:54.736 : <epoch:395, iter: 111,800, lr:2.000e-04> G_loss: 6.765e-02 
22-01-12 04:56:20.830 : <epoch:395, iter: 112,000, lr:2.000e-04> G_loss: 1.413e-02 
22-01-12 04:56:47.468 : <epoch:396, iter: 112,200, lr:2.000e-04> G_loss: 2.405e-02 
22-01-12 04:57:14.100 : <epoch:397, iter: 112,400, lr:2.000e-04> G_loss: 2.247e-02 
22-01-12 04:57:40.151 : <epoch:397, iter: 112,600, lr:2.000e-04> G_loss: 5.148e-02 
22-01-12 04:58:06.791 : <epoch:398, iter: 112,800, lr:2.000e-04> G_loss: 3.450e-02 
22-01-12 04:58:33.404 : <epoch:399, iter: 113,000, lr:2.000e-04> G_loss: 2.861e-02 
22-01-12 04:58:59.508 : <epoch:399, iter: 113,200, lr:2.000e-04> G_loss: 4.467e-02 
22-01-12 04:59:26.297 : <epoch:400, iter: 113,400, lr:2.000e-04> G_loss: 4.100e-02 
22-01-12 04:59:52.910 : <epoch:401, iter: 113,600, lr:2.000e-04> G_loss: 3.052e-02 
22-01-12 05:00:19.568 : <epoch:402, iter: 113,800, lr:2.000e-04> G_loss: 4.871e-02 
22-01-12 05:00:45.647 : <epoch:402, iter: 114,000, lr:2.000e-04> G_loss: 3.197e-02 
22-01-12 05:01:12.319 : <epoch:403, iter: 114,200, lr:2.000e-04> G_loss: 3.334e-02 
22-01-12 05:01:38.938 : <epoch:404, iter: 114,400, lr:2.000e-04> G_loss: 1.422e-02 
22-01-12 05:02:05.039 : <epoch:404, iter: 114,600, lr:2.000e-04> G_loss: 3.922e-02 
22-01-12 05:02:31.659 : <epoch:405, iter: 114,800, lr:2.000e-04> G_loss: 4.527e-02 
22-01-12 05:02:58.376 : <epoch:406, iter: 115,000, lr:2.000e-04> G_loss: 3.101e-02 
22-01-12 05:02:58.376 : Saving the model.
22-01-12 05:02:59.024 : ---1-->  12003.png | 28.43dB
22-01-12 05:02:59.316 : ---2-->  12074.png | 30.85dB
22-01-12 05:02:59.620 : ---3-->  15004.png | 24.53dB
22-01-12 05:02:59.923 : ---4-->  15088.png | 25.17dB
22-01-12 05:03:00.228 : ---5-->  16052.png | 33.31dB
22-01-12 05:03:00.554 : ---6-->   2092.png | 28.96dB
22-01-12 05:03:00.852 : ---7-->   8049.png | 27.45dB
22-01-12 05:03:01.134 : ---8-->   8143.png | 20.08dB
22-01-12 05:03:01.169 : <epoch:406, iter: 115,000, Average PSNR : 27.35dB

22-01-12 05:03:27.891 : <epoch:407, iter: 115,200, lr:2.000e-04> G_loss: 3.278e-02 
22-01-12 05:03:53.981 : <epoch:407, iter: 115,400, lr:2.000e-04> G_loss: 3.672e-02 
22-01-12 05:04:20.697 : <epoch:408, iter: 115,600, lr:2.000e-04> G_loss: 1.304e-02 
22-01-12 05:04:47.345 : <epoch:409, iter: 115,800, lr:2.000e-04> G_loss: 1.313e-02 
22-01-12 05:05:13.478 : <epoch:409, iter: 116,000, lr:2.000e-04> G_loss: 2.230e-02 
22-01-12 05:05:40.125 : <epoch:410, iter: 116,200, lr:2.000e-04> G_loss: 4.808e-02 
22-01-12 05:06:06.857 : <epoch:411, iter: 116,400, lr:2.000e-04> G_loss: 1.576e-02 
22-01-12 05:06:33.488 : <epoch:412, iter: 116,600, lr:2.000e-04> G_loss: 3.756e-02 
22-01-12 05:06:59.643 : <epoch:412, iter: 116,800, lr:2.000e-04> G_loss: 7.468e-02 
22-01-12 05:07:26.267 : <epoch:413, iter: 117,000, lr:2.000e-04> G_loss: 3.368e-02 
22-01-12 05:07:53.114 : <epoch:414, iter: 117,200, lr:2.000e-04> G_loss: 2.724e-02 
22-01-12 05:08:19.203 : <epoch:414, iter: 117,400, lr:2.000e-04> G_loss: 3.172e-02 
22-01-12 05:08:45.801 : <epoch:415, iter: 117,600, lr:2.000e-04> G_loss: 1.797e-02 
22-01-12 05:09:12.474 : <epoch:416, iter: 117,800, lr:2.000e-04> G_loss: 1.194e-02 
22-01-12 05:09:38.559 : <epoch:416, iter: 118,000, lr:2.000e-04> G_loss: 2.942e-02 
22-01-12 05:10:05.228 : <epoch:417, iter: 118,200, lr:2.000e-04> G_loss: 2.043e-02 
22-01-12 05:10:31.865 : <epoch:418, iter: 118,400, lr:2.000e-04> G_loss: 1.607e-02 
22-01-12 05:10:58.677 : <epoch:419, iter: 118,600, lr:2.000e-04> G_loss: 6.044e-02 
22-01-12 05:11:24.838 : <epoch:419, iter: 118,800, lr:2.000e-04> G_loss: 2.298e-02 
22-01-12 05:11:51.480 : <epoch:420, iter: 119,000, lr:2.000e-04> G_loss: 1.995e-02 
22-01-12 05:12:18.144 : <epoch:421, iter: 119,200, lr:2.000e-04> G_loss: 2.786e-02 
22-01-12 05:12:44.206 : <epoch:421, iter: 119,400, lr:2.000e-04> G_loss: 3.166e-02 
22-01-12 05:13:10.806 : <epoch:422, iter: 119,600, lr:2.000e-04> G_loss: 2.673e-02 
22-01-12 05:13:37.434 : <epoch:423, iter: 119,800, lr:2.000e-04> G_loss: 5.672e-02 
22-01-12 05:14:04.178 : <epoch:424, iter: 120,000, lr:2.000e-04> G_loss: 3.982e-02 
22-01-12 05:14:04.179 : Saving the model.
22-01-12 05:14:04.857 : ---1-->  12003.png | 28.42dB
22-01-12 05:14:05.177 : ---2-->  12074.png | 31.03dB
22-01-12 05:14:05.486 : ---3-->  15004.png | 24.57dB
22-01-12 05:14:05.796 : ---4-->  15088.png | 25.27dB
22-01-12 05:14:06.115 : ---5-->  16052.png | 33.32dB
22-01-12 05:14:06.433 : ---6-->   2092.png | 29.02dB
22-01-12 05:14:06.707 : ---7-->   8049.png | 27.49dB
22-01-12 05:14:06.969 : ---8-->   8143.png | 20.15dB
22-01-12 05:14:07.001 : <epoch:424, iter: 120,000, Average PSNR : 27.41dB

22-01-12 05:14:33.076 : <epoch:424, iter: 120,200, lr:2.000e-04> G_loss: 1.732e-02 
22-01-12 05:14:59.833 : <epoch:425, iter: 120,400, lr:2.000e-04> G_loss: 2.309e-02 
22-01-12 05:15:26.447 : <epoch:426, iter: 120,600, lr:2.000e-04> G_loss: 1.647e-02 
22-01-12 05:15:52.497 : <epoch:426, iter: 120,800, lr:2.000e-04> G_loss: 1.408e-02 
22-01-12 05:16:19.207 : <epoch:427, iter: 121,000, lr:2.000e-04> G_loss: 1.514e-02 
22-01-12 05:16:45.805 : <epoch:428, iter: 121,200, lr:2.000e-04> G_loss: 4.222e-03 
22-01-12 05:17:11.881 : <epoch:428, iter: 121,400, lr:2.000e-04> G_loss: 4.161e-02 
22-01-12 05:17:38.536 : <epoch:429, iter: 121,600, lr:2.000e-04> G_loss: 1.521e-02 
22-01-12 05:18:05.153 : <epoch:430, iter: 121,800, lr:2.000e-04> G_loss: 2.433e-02 
22-01-12 05:18:31.912 : <epoch:431, iter: 122,000, lr:2.000e-04> G_loss: 4.541e-02 
22-01-12 05:18:57.982 : <epoch:431, iter: 122,200, lr:2.000e-04> G_loss: 3.452e-02 
22-01-12 05:19:24.643 : <epoch:432, iter: 122,400, lr:2.000e-04> G_loss: 2.692e-02 
22-01-12 05:19:51.268 : <epoch:433, iter: 122,600, lr:2.000e-04> G_loss: 1.153e-02 
22-01-12 05:20:17.325 : <epoch:433, iter: 122,800, lr:2.000e-04> G_loss: 5.557e-03 
22-01-12 05:20:44.152 : <epoch:434, iter: 123,000, lr:2.000e-04> G_loss: 2.172e-02 
22-01-12 05:21:10.806 : <epoch:435, iter: 123,200, lr:2.000e-04> G_loss: 2.207e-02 
22-01-12 05:21:37.439 : <epoch:436, iter: 123,400, lr:2.000e-04> G_loss: 2.407e-02 
22-01-12 05:22:03.608 : <epoch:436, iter: 123,600, lr:2.000e-04> G_loss: 1.291e-02 
22-01-12 05:22:30.274 : <epoch:437, iter: 123,800, lr:2.000e-04> G_loss: 1.204e-02 
22-01-12 05:22:57.003 : <epoch:438, iter: 124,000, lr:2.000e-04> G_loss: 1.181e-02 
22-01-12 05:23:23.121 : <epoch:438, iter: 124,200, lr:2.000e-04> G_loss: 3.031e-02 
22-01-12 05:23:49.781 : <epoch:439, iter: 124,400, lr:2.000e-04> G_loss: 2.672e-02 
22-01-12 05:24:16.469 : <epoch:440, iter: 124,600, lr:2.000e-04> G_loss: 5.545e-02 
22-01-12 05:24:42.531 : <epoch:440, iter: 124,800, lr:2.000e-04> G_loss: 2.300e-02 
22-01-12 05:25:09.136 : <epoch:441, iter: 125,000, lr:2.000e-04> G_loss: 4.155e-02 
22-01-12 05:25:09.136 : Saving the model.
22-01-12 05:25:09.809 : ---1-->  12003.png | 28.47dB
22-01-12 05:25:10.112 : ---2-->  12074.png | 31.04dB
22-01-12 05:25:10.428 : ---3-->  15004.png | 24.57dB
22-01-12 05:25:10.726 : ---4-->  15088.png | 25.11dB
22-01-12 05:25:11.031 : ---5-->  16052.png | 33.49dB
22-01-12 05:25:11.341 : ---6-->   2092.png | 29.06dB
22-01-12 05:25:11.599 : ---7-->   8049.png | 27.34dB
22-01-12 05:25:11.879 : ---8-->   8143.png | 20.09dB
22-01-12 05:25:11.911 : <epoch:441, iter: 125,000, Average PSNR : 27.40dB

22-01-12 05:25:38.608 : <epoch:442, iter: 125,200, lr:2.000e-04> G_loss: 6.224e-02 
22-01-12 05:26:05.255 : <epoch:443, iter: 125,400, lr:2.000e-04> G_loss: 1.966e-02 
22-01-12 05:26:31.330 : <epoch:443, iter: 125,600, lr:2.000e-04> G_loss: 3.000e-02 
22-01-12 05:26:57.971 : <epoch:444, iter: 125,800, lr:2.000e-04> G_loss: 1.226e-02 
22-01-12 05:27:24.693 : <epoch:445, iter: 126,000, lr:2.000e-04> G_loss: 2.345e-02 
22-01-12 05:27:50.796 : <epoch:445, iter: 126,200, lr:2.000e-04> G_loss: 1.251e-02 
22-01-12 05:28:17.455 : <epoch:446, iter: 126,400, lr:2.000e-04> G_loss: 3.645e-02 
22-01-12 05:28:44.053 : <epoch:447, iter: 126,600, lr:2.000e-04> G_loss: 1.514e-02 
22-01-12 05:29:10.759 : <epoch:448, iter: 126,800, lr:2.000e-04> G_loss: 5.356e-02 
22-01-12 05:29:36.856 : <epoch:448, iter: 127,000, lr:2.000e-04> G_loss: 4.407e-02 
22-01-12 05:30:03.659 : <epoch:449, iter: 127,200, lr:2.000e-04> G_loss: 6.245e-02 
22-01-12 05:30:30.301 : <epoch:450, iter: 127,400, lr:2.000e-04> G_loss: 2.341e-02 
22-01-12 05:30:56.392 : <epoch:450, iter: 127,600, lr:2.000e-04> G_loss: 2.353e-02 
22-01-12 05:31:23.051 : <epoch:451, iter: 127,800, lr:2.000e-04> G_loss: 3.269e-02 
22-01-12 05:31:49.742 : <epoch:452, iter: 128,000, lr:2.000e-04> G_loss: 2.481e-02 
22-01-12 05:32:16.426 : <epoch:453, iter: 128,200, lr:2.000e-04> G_loss: 1.718e-02 
22-01-12 05:32:42.613 : <epoch:453, iter: 128,400, lr:2.000e-04> G_loss: 2.366e-02 
22-01-12 05:33:09.249 : <epoch:454, iter: 128,600, lr:2.000e-04> G_loss: 1.942e-02 
22-01-12 05:33:35.983 : <epoch:455, iter: 128,800, lr:2.000e-04> G_loss: 1.835e-02 
22-01-12 05:34:02.135 : <epoch:455, iter: 129,000, lr:2.000e-04> G_loss: 5.741e-02 
22-01-12 05:34:28.847 : <epoch:456, iter: 129,200, lr:2.000e-04> G_loss: 3.113e-02 
22-01-12 05:34:55.465 : <epoch:457, iter: 129,400, lr:2.000e-04> G_loss: 3.980e-02 
22-01-12 05:35:21.584 : <epoch:457, iter: 129,600, lr:2.000e-04> G_loss: 2.010e-02 
22-01-12 05:35:48.245 : <epoch:458, iter: 129,800, lr:2.000e-04> G_loss: 1.308e-02 
22-01-12 05:36:14.901 : <epoch:459, iter: 130,000, lr:2.000e-04> G_loss: 2.475e-02 
22-01-12 05:36:14.901 : Saving the model.
22-01-12 05:36:15.583 : ---1-->  12003.png | 28.42dB
22-01-12 05:36:15.897 : ---2-->  12074.png | 30.95dB
22-01-12 05:36:16.219 : ---3-->  15004.png | 24.57dB
22-01-12 05:36:16.541 : ---4-->  15088.png | 25.11dB
22-01-12 05:36:16.849 : ---5-->  16052.png | 33.44dB
22-01-12 05:36:17.148 : ---6-->   2092.png | 29.08dB
22-01-12 05:36:17.429 : ---7-->   8049.png | 27.41dB
22-01-12 05:36:17.696 : ---8-->   8143.png | 20.06dB
22-01-12 05:36:17.731 : <epoch:459, iter: 130,000, Average PSNR : 27.38dB

22-01-12 05:36:44.442 : <epoch:460, iter: 130,200, lr:2.000e-04> G_loss: 2.997e-02 
22-01-12 05:37:10.517 : <epoch:460, iter: 130,400, lr:2.000e-04> G_loss: 3.691e-02 
22-01-12 05:37:37.165 : <epoch:461, iter: 130,600, lr:2.000e-04> G_loss: 7.950e-02 
22-01-12 05:38:03.761 : <epoch:462, iter: 130,800, lr:2.000e-04> G_loss: 2.136e-02 
22-01-12 05:38:30.027 : <epoch:462, iter: 131,000, lr:2.000e-04> G_loss: 8.417e-03 
22-01-12 05:38:56.800 : <epoch:463, iter: 131,200, lr:2.000e-04> G_loss: 4.493e-02 
22-01-12 05:39:23.448 : <epoch:464, iter: 131,400, lr:2.000e-04> G_loss: 2.175e-02 
22-01-12 05:39:50.154 : <epoch:465, iter: 131,600, lr:2.000e-04> G_loss: 2.317e-02 
22-01-12 05:40:16.227 : <epoch:465, iter: 131,800, lr:2.000e-04> G_loss: 1.618e-02 
22-01-12 05:40:42.920 : <epoch:466, iter: 132,000, lr:2.000e-04> G_loss: 4.747e-02 
22-01-12 05:41:09.586 : <epoch:467, iter: 132,200, lr:2.000e-04> G_loss: 2.597e-02 
22-01-12 05:41:35.752 : <epoch:467, iter: 132,400, lr:2.000e-04> G_loss: 6.126e-02 
22-01-12 05:42:02.425 : <epoch:468, iter: 132,600, lr:2.000e-04> G_loss: 4.653e-02 
22-01-12 05:42:29.094 : <epoch:469, iter: 132,800, lr:2.000e-04> G_loss: 2.359e-02 
22-01-12 05:42:55.148 : <epoch:469, iter: 133,000, lr:2.000e-04> G_loss: 3.522e-02 
22-01-12 05:43:21.795 : <epoch:470, iter: 133,200, lr:2.000e-04> G_loss: 2.366e-02 
22-01-12 05:43:48.566 : <epoch:471, iter: 133,400, lr:2.000e-04> G_loss: 3.283e-02 
22-01-12 05:44:15.161 : <epoch:472, iter: 133,600, lr:2.000e-04> G_loss: 3.354e-02 
22-01-12 05:44:41.256 : <epoch:472, iter: 133,800, lr:2.000e-04> G_loss: 1.339e-02 
22-01-12 05:45:07.906 : <epoch:473, iter: 134,000, lr:2.000e-04> G_loss: 4.422e-02 
22-01-12 05:45:34.560 : <epoch:474, iter: 134,200, lr:2.000e-04> G_loss: 3.965e-02 
22-01-12 05:46:00.667 : <epoch:474, iter: 134,400, lr:2.000e-04> G_loss: 8.980e-02 
22-01-12 05:46:27.483 : <epoch:475, iter: 134,600, lr:2.000e-04> G_loss: 3.684e-02 
22-01-12 05:46:54.119 : <epoch:476, iter: 134,800, lr:2.000e-04> G_loss: 3.016e-02 
22-01-12 05:47:20.789 : <epoch:477, iter: 135,000, lr:2.000e-04> G_loss: 1.507e-02 
22-01-12 05:47:20.790 : Saving the model.
22-01-12 05:47:21.495 : ---1-->  12003.png | 28.54dB
22-01-12 05:47:21.801 : ---2-->  12074.png | 31.06dB
22-01-12 05:47:22.114 : ---3-->  15004.png | 24.62dB
22-01-12 05:47:22.433 : ---4-->  15088.png | 25.27dB
22-01-12 05:47:22.755 : ---5-->  16052.png | 33.44dB
22-01-12 05:47:23.070 : ---6-->   2092.png | 29.07dB
22-01-12 05:47:23.347 : ---7-->   8049.png | 27.57dB
22-01-12 05:47:23.634 : ---8-->   8143.png | 20.15dB
22-01-12 05:47:23.666 : <epoch:477, iter: 135,000, Average PSNR : 27.46dB

22-01-12 05:47:49.722 : <epoch:477, iter: 135,200, lr:2.000e-04> G_loss: 9.256e-03 
22-01-12 05:48:16.419 : <epoch:478, iter: 135,400, lr:2.000e-04> G_loss: 3.257e-02 
22-01-12 05:48:42.955 : <epoch:479, iter: 135,600, lr:2.000e-04> G_loss: 4.233e-02 
22-01-12 05:49:09.006 : <epoch:479, iter: 135,800, lr:2.000e-04> G_loss: 2.941e-02 
22-01-12 05:49:35.649 : <epoch:480, iter: 136,000, lr:2.000e-04> G_loss: 2.043e-02 
22-01-12 05:50:02.280 : <epoch:481, iter: 136,200, lr:2.000e-04> G_loss: 4.875e-02 
22-01-12 05:50:28.361 : <epoch:481, iter: 136,400, lr:2.000e-04> G_loss: 7.627e-03 
22-01-12 05:50:54.985 : <epoch:482, iter: 136,600, lr:2.000e-04> G_loss: 1.570e-02 
22-01-12 05:51:21.642 : <epoch:483, iter: 136,800, lr:2.000e-04> G_loss: 3.417e-02 
22-01-12 05:51:48.248 : <epoch:484, iter: 137,000, lr:2.000e-04> G_loss: 1.066e-02 
22-01-12 05:52:14.360 : <epoch:484, iter: 137,200, lr:2.000e-04> G_loss: 4.111e-02 
22-01-12 05:52:40.964 : <epoch:485, iter: 137,400, lr:2.000e-04> G_loss: 2.513e-02 
22-01-12 05:53:07.603 : <epoch:486, iter: 137,600, lr:2.000e-04> G_loss: 5.008e-02 
22-01-12 05:53:33.618 : <epoch:486, iter: 137,800, lr:2.000e-04> G_loss: 1.770e-02 
22-01-12 05:54:00.280 : <epoch:487, iter: 138,000, lr:2.000e-04> G_loss: 1.061e-02 
22-01-12 05:54:26.884 : <epoch:488, iter: 138,200, lr:2.000e-04> G_loss: 2.584e-02 
22-01-12 05:54:53.503 : <epoch:489, iter: 138,400, lr:2.000e-04> G_loss: 1.173e-02 
22-01-12 05:55:19.776 : <epoch:489, iter: 138,600, lr:2.000e-04> G_loss: 1.192e-02 
22-01-12 05:55:46.430 : <epoch:490, iter: 138,800, lr:2.000e-04> G_loss: 1.312e-02 
22-01-12 05:56:13.167 : <epoch:491, iter: 139,000, lr:2.000e-04> G_loss: 1.257e-02 
22-01-12 05:56:39.243 : <epoch:491, iter: 139,200, lr:2.000e-04> G_loss: 1.397e-02 
22-01-12 05:57:05.915 : <epoch:492, iter: 139,400, lr:2.000e-04> G_loss: 3.355e-02 
22-01-12 05:57:32.561 : <epoch:493, iter: 139,600, lr:2.000e-04> G_loss: 8.345e-03 
22-01-12 05:57:58.616 : <epoch:493, iter: 139,800, lr:2.000e-04> G_loss: 2.296e-02 
22-01-12 05:58:25.165 : <epoch:494, iter: 140,000, lr:2.000e-04> G_loss: 3.301e-02 
22-01-12 05:58:25.165 : Saving the model.
22-01-12 05:58:25.791 : ---1-->  12003.png | 28.53dB
22-01-12 05:58:26.110 : ---2-->  12074.png | 31.02dB
22-01-12 05:58:26.414 : ---3-->  15004.png | 24.60dB
22-01-12 05:58:26.729 : ---4-->  15088.png | 25.27dB
22-01-12 05:58:27.058 : ---5-->  16052.png | 33.23dB
22-01-12 05:58:27.358 : ---6-->   2092.png | 29.18dB
22-01-12 05:58:27.673 : ---7-->   8049.png | 27.58dB
22-01-12 05:58:27.964 : ---8-->   8143.png | 20.18dB
22-01-12 05:58:27.996 : <epoch:494, iter: 140,000, Average PSNR : 27.45dB

22-01-12 05:58:54.753 : <epoch:495, iter: 140,200, lr:2.000e-04> G_loss: 2.210e-02 
22-01-12 05:59:21.525 : <epoch:496, iter: 140,400, lr:2.000e-04> G_loss: 1.798e-02 
22-01-12 05:59:47.727 : <epoch:496, iter: 140,600, lr:2.000e-04> G_loss: 1.032e-02 
22-01-12 06:00:14.351 : <epoch:497, iter: 140,800, lr:2.000e-04> G_loss: 3.436e-02 
22-01-12 06:00:41.035 : <epoch:498, iter: 141,000, lr:2.000e-04> G_loss: 2.449e-02 
22-01-12 06:01:07.238 : <epoch:498, iter: 141,200, lr:2.000e-04> G_loss: 4.233e-02 
22-01-12 06:01:33.878 : <epoch:499, iter: 141,400, lr:2.000e-04> G_loss: 5.694e-02 
22-01-12 06:02:00.470 : <epoch:500, iter: 141,600, lr:2.000e-04> G_loss: 4.839e-02 
22-01-12 06:02:27.143 : <epoch:501, iter: 141,800, lr:2.000e-04> G_loss: 5.129e-02 
22-01-12 06:02:53.219 : <epoch:501, iter: 142,000, lr:2.000e-04> G_loss: 9.975e-03 
22-01-12 06:03:19.922 : <epoch:502, iter: 142,200, lr:2.000e-04> G_loss: 3.928e-02 
22-01-12 06:03:46.705 : <epoch:503, iter: 142,400, lr:2.000e-04> G_loss: 2.355e-02 
22-01-12 06:04:12.815 : <epoch:503, iter: 142,600, lr:2.000e-04> G_loss: 1.366e-02 
22-01-12 06:04:39.598 : <epoch:504, iter: 142,800, lr:2.000e-04> G_loss: 3.051e-02 
22-01-12 06:05:06.165 : <epoch:505, iter: 143,000, lr:2.000e-04> G_loss: 4.050e-03 
22-01-12 06:05:32.911 : <epoch:506, iter: 143,200, lr:2.000e-04> G_loss: 2.433e-02 
22-01-12 06:05:58.984 : <epoch:506, iter: 143,400, lr:2.000e-04> G_loss: 2.831e-02 
22-01-12 06:06:25.662 : <epoch:507, iter: 143,600, lr:2.000e-04> G_loss: 2.638e-02 
22-01-12 06:06:52.292 : <epoch:508, iter: 143,800, lr:2.000e-04> G_loss: 2.585e-02 
22-01-12 06:07:18.511 : <epoch:508, iter: 144,000, lr:2.000e-04> G_loss: 1.262e-02 
22-01-12 06:07:45.056 : <epoch:509, iter: 144,200, lr:2.000e-04> G_loss: 3.141e-02 
22-01-12 06:08:11.785 : <epoch:510, iter: 144,400, lr:2.000e-04> G_loss: 2.315e-02 
22-01-12 06:08:37.905 : <epoch:510, iter: 144,600, lr:2.000e-04> G_loss: 8.430e-03 
22-01-12 06:09:04.509 : <epoch:511, iter: 144,800, lr:2.000e-04> G_loss: 4.081e-02 
22-01-12 06:09:31.168 : <epoch:512, iter: 145,000, lr:2.000e-04> G_loss: 2.172e-02 
22-01-12 06:09:31.168 : Saving the model.
22-01-12 06:09:31.828 : ---1-->  12003.png | 28.56dB
22-01-12 06:09:32.138 : ---2-->  12074.png | 30.85dB
22-01-12 06:09:32.453 : ---3-->  15004.png | 24.60dB
22-01-12 06:09:32.766 : ---4-->  15088.png | 25.32dB
22-01-12 06:09:33.073 : ---5-->  16052.png | 33.24dB
22-01-12 06:09:33.386 : ---6-->   2092.png | 29.12dB
22-01-12 06:09:33.681 : ---7-->   8049.png | 27.59dB
22-01-12 06:09:33.974 : ---8-->   8143.png | 20.13dB
22-01-12 06:09:34.006 : <epoch:512, iter: 145,000, Average PSNR : 27.43dB

22-01-12 06:10:00.643 : <epoch:513, iter: 145,200, lr:2.000e-04> G_loss: 2.147e-02 
22-01-12 06:10:26.802 : <epoch:513, iter: 145,400, lr:2.000e-04> G_loss: 1.957e-02 
22-01-12 06:10:53.560 : <epoch:514, iter: 145,600, lr:2.000e-04> G_loss: 4.986e-02 
22-01-12 06:11:20.294 : <epoch:515, iter: 145,800, lr:2.000e-04> G_loss: 5.323e-03 
22-01-12 06:11:46.366 : <epoch:515, iter: 146,000, lr:2.000e-04> G_loss: 2.444e-02 
22-01-12 06:12:13.046 : <epoch:516, iter: 146,200, lr:2.000e-04> G_loss: 3.582e-02 
22-01-12 06:12:39.821 : <epoch:517, iter: 146,400, lr:2.000e-04> G_loss: 3.139e-02 
22-01-12 06:13:06.393 : <epoch:518, iter: 146,600, lr:2.000e-04> G_loss: 1.180e-02 
22-01-12 06:13:32.583 : <epoch:518, iter: 146,800, lr:2.000e-04> G_loss: 7.741e-02 
22-01-12 06:13:59.237 : <epoch:519, iter: 147,000, lr:2.000e-04> G_loss: 1.523e-02 
22-01-12 06:14:25.991 : <epoch:520, iter: 147,200, lr:2.000e-04> G_loss: 1.653e-02 
22-01-12 06:14:52.077 : <epoch:520, iter: 147,400, lr:2.000e-04> G_loss: 1.961e-02 
22-01-12 06:15:18.736 : <epoch:521, iter: 147,600, lr:2.000e-04> G_loss: 4.820e-02 
22-01-12 06:15:45.383 : <epoch:522, iter: 147,800, lr:2.000e-04> G_loss: 4.129e-02 
22-01-12 06:16:11.446 : <epoch:522, iter: 148,000, lr:2.000e-04> G_loss: 3.745e-02 
22-01-12 06:16:38.092 : <epoch:523, iter: 148,200, lr:2.000e-04> G_loss: 4.074e-02 
22-01-12 06:17:04.695 : <epoch:524, iter: 148,400, lr:2.000e-04> G_loss: 3.945e-02 
22-01-12 06:17:31.324 : <epoch:525, iter: 148,600, lr:2.000e-04> G_loss: 4.432e-02 
22-01-12 06:17:57.392 : <epoch:525, iter: 148,800, lr:2.000e-04> G_loss: 6.209e-03 
22-01-12 06:18:24.021 : <epoch:526, iter: 149,000, lr:2.000e-04> G_loss: 1.381e-02 
22-01-12 06:18:50.719 : <epoch:527, iter: 149,200, lr:2.000e-04> G_loss: 3.038e-02 
22-01-12 06:19:16.798 : <epoch:527, iter: 149,400, lr:2.000e-04> G_loss: 1.857e-02 
22-01-12 06:19:43.481 : <epoch:528, iter: 149,600, lr:2.000e-04> G_loss: 2.472e-02 
22-01-12 06:20:09.999 : <epoch:529, iter: 149,800, lr:2.000e-04> G_loss: 2.263e-02 
22-01-12 06:20:36.743 : <epoch:530, iter: 150,000, lr:2.000e-04> G_loss: 2.212e-02 
22-01-12 06:20:36.743 : Saving the model.
22-01-12 06:20:37.397 : ---1-->  12003.png | 28.53dB
22-01-12 06:20:37.702 : ---2-->  12074.png | 31.10dB
22-01-12 06:20:38.039 : ---3-->  15004.png | 24.62dB
22-01-12 06:20:38.382 : ---4-->  15088.png | 25.23dB
22-01-12 06:20:38.713 : ---5-->  16052.png | 33.44dB
22-01-12 06:20:39.020 : ---6-->   2092.png | 29.19dB
22-01-12 06:20:39.302 : ---7-->   8049.png | 27.63dB
22-01-12 06:20:39.607 : ---8-->   8143.png | 20.23dB
22-01-12 06:20:39.639 : <epoch:530, iter: 150,000, Average PSNR : 27.50dB

22-01-12 06:21:05.620 : <epoch:530, iter: 150,200, lr:2.000e-04> G_loss: 2.971e-02 
22-01-12 06:21:32.277 : <epoch:531, iter: 150,400, lr:2.000e-04> G_loss: 5.450e-03 
22-01-12 06:21:58.921 : <epoch:532, iter: 150,600, lr:2.000e-04> G_loss: 1.097e-02 
22-01-12 06:22:24.977 : <epoch:532, iter: 150,800, lr:2.000e-04> G_loss: 1.291e-02 
22-01-12 06:22:51.619 : <epoch:533, iter: 151,000, lr:2.000e-04> G_loss: 3.954e-02 
22-01-12 06:23:18.369 : <epoch:534, iter: 151,200, lr:2.000e-04> G_loss: 4.503e-02 
22-01-12 06:23:44.416 : <epoch:534, iter: 151,400, lr:2.000e-04> G_loss: 3.021e-02 
22-01-12 06:24:11.022 : <epoch:535, iter: 151,600, lr:2.000e-04> G_loss: 4.703e-03 
22-01-12 06:24:37.719 : <epoch:536, iter: 151,800, lr:2.000e-04> G_loss: 2.223e-02 
22-01-12 06:25:04.451 : <epoch:537, iter: 152,000, lr:2.000e-04> G_loss: 3.756e-02 
22-01-12 06:25:30.551 : <epoch:537, iter: 152,200, lr:2.000e-04> G_loss: 2.500e-02 
22-01-12 06:26:10.835 : <epoch:538, iter: 152,400, lr:2.000e-04> G_loss: 9.466e-03 
22-01-12 06:26:54.299 : <epoch:539, iter: 152,600, lr:2.000e-04> G_loss: 2.870e-02 
22-01-12 06:27:22.746 : <epoch:539, iter: 152,800, lr:2.000e-04> G_loss: 2.700e-02 
22-01-12 06:27:49.371 : <epoch:540, iter: 153,000, lr:2.000e-04> G_loss: 2.269e-02 
22-01-12 06:28:16.047 : <epoch:541, iter: 153,200, lr:2.000e-04> G_loss: 3.809e-02 
22-01-12 06:28:42.673 : <epoch:542, iter: 153,400, lr:2.000e-04> G_loss: 2.556e-02 
22-01-12 06:29:08.775 : <epoch:542, iter: 153,600, lr:2.000e-04> G_loss: 2.005e-02 
22-01-12 06:29:35.533 : <epoch:543, iter: 153,800, lr:2.000e-04> G_loss: 2.127e-02 
22-01-12 06:30:02.335 : <epoch:544, iter: 154,000, lr:2.000e-04> G_loss: 8.759e-03 
22-01-12 06:30:28.368 : <epoch:544, iter: 154,200, lr:2.000e-04> G_loss: 1.042e-02 
22-01-12 06:30:54.991 : <epoch:545, iter: 154,400, lr:2.000e-04> G_loss: 2.012e-02 
22-01-12 06:31:21.565 : <epoch:546, iter: 154,600, lr:2.000e-04> G_loss: 4.067e-02 
22-01-12 06:31:47.656 : <epoch:546, iter: 154,800, lr:2.000e-04> G_loss: 5.659e-02 
22-01-12 06:32:14.368 : <epoch:547, iter: 155,000, lr:2.000e-04> G_loss: 9.687e-03 
22-01-12 06:32:14.368 : Saving the model.
22-01-12 06:32:15.033 : ---1-->  12003.png | 28.66dB
22-01-12 06:32:15.355 : ---2-->  12074.png | 31.13dB
22-01-12 06:32:15.684 : ---3-->  15004.png | 24.68dB
22-01-12 06:32:15.997 : ---4-->  15088.png | 25.25dB
22-01-12 06:32:16.345 : ---5-->  16052.png | 33.36dB
22-01-12 06:32:16.678 : ---6-->   2092.png | 29.23dB
22-01-12 06:32:16.988 : ---7-->   8049.png | 27.59dB
22-01-12 06:32:17.293 : ---8-->   8143.png | 20.18dB
22-01-12 06:32:17.325 : <epoch:547, iter: 155,000, Average PSNR : 27.51dB

22-01-12 06:32:44.080 : <epoch:548, iter: 155,200, lr:2.000e-04> G_loss: 1.357e-02 
22-01-12 06:33:10.833 : <epoch:549, iter: 155,400, lr:2.000e-04> G_loss: 2.298e-02 
22-01-12 06:33:36.882 : <epoch:549, iter: 155,600, lr:2.000e-04> G_loss: 1.558e-02 
22-01-12 06:34:03.502 : <epoch:550, iter: 155,800, lr:2.000e-04> G_loss: 7.135e-03 
22-01-12 06:34:30.162 : <epoch:551, iter: 156,000, lr:2.000e-04> G_loss: 1.509e-02 
22-01-12 06:34:56.243 : <epoch:551, iter: 156,200, lr:2.000e-04> G_loss: 1.259e-02 
22-01-12 06:35:22.873 : <epoch:552, iter: 156,400, lr:2.000e-04> G_loss: 3.036e-02 
22-01-12 06:35:49.528 : <epoch:553, iter: 156,600, lr:2.000e-04> G_loss: 3.384e-02 
22-01-12 06:36:16.162 : <epoch:554, iter: 156,800, lr:2.000e-04> G_loss: 5.072e-02 
22-01-12 06:36:42.244 : <epoch:554, iter: 157,000, lr:2.000e-04> G_loss: 1.157e-02 
22-01-12 06:37:08.898 : <epoch:555, iter: 157,200, lr:2.000e-04> G_loss: 2.200e-02 
22-01-12 06:37:35.549 : <epoch:556, iter: 157,400, lr:2.000e-04> G_loss: 2.250e-02 
22-01-12 06:38:01.692 : <epoch:556, iter: 157,600, lr:2.000e-04> G_loss: 3.750e-02 
22-01-12 06:38:28.340 : <epoch:557, iter: 157,800, lr:2.000e-04> G_loss: 3.038e-02 
22-01-12 06:38:54.982 : <epoch:558, iter: 158,000, lr:2.000e-04> G_loss: 1.938e-02 
22-01-12 06:39:21.711 : <epoch:559, iter: 158,200, lr:2.000e-04> G_loss: 1.548e-02 
22-01-12 06:39:47.798 : <epoch:559, iter: 158,400, lr:2.000e-04> G_loss: 1.610e-02 
22-01-12 06:40:14.416 : <epoch:560, iter: 158,600, lr:2.000e-04> G_loss: 6.220e-02 
22-01-12 06:40:41.092 : <epoch:561, iter: 158,800, lr:2.000e-04> G_loss: 1.535e-02 
22-01-12 06:41:07.172 : <epoch:561, iter: 159,000, lr:2.000e-04> G_loss: 1.584e-02 
22-01-12 06:41:33.837 : <epoch:562, iter: 159,200, lr:2.000e-04> G_loss: 3.760e-02 
22-01-12 06:42:00.475 : <epoch:563, iter: 159,400, lr:2.000e-04> G_loss: 1.152e-02 
22-01-12 06:42:26.725 : <epoch:563, iter: 159,600, lr:2.000e-04> G_loss: 4.563e-02 
22-01-12 06:42:53.428 : <epoch:564, iter: 159,800, lr:2.000e-04> G_loss: 2.069e-02 
22-01-12 06:43:20.152 : <epoch:565, iter: 160,000, lr:2.000e-04> G_loss: 2.751e-02 
22-01-12 06:43:20.152 : Saving the model.
22-01-12 06:43:20.794 : ---1-->  12003.png | 27.50dB
22-01-12 06:43:21.112 : ---2-->  12074.png | 30.38dB
22-01-12 06:43:21.420 : ---3-->  15004.png | 24.49dB
22-01-12 06:43:21.717 : ---4-->  15088.png | 25.25dB
22-01-12 06:43:22.017 : ---5-->  16052.png | 32.25dB
22-01-12 06:43:22.319 : ---6-->   2092.png | 28.57dB
22-01-12 06:43:22.616 : ---7-->   8049.png | 27.19dB
22-01-12 06:43:22.911 : ---8-->   8143.png | 20.15dB
22-01-12 06:43:22.942 : <epoch:565, iter: 160,000, Average PSNR : 26.97dB

22-01-12 06:43:49.504 : <epoch:566, iter: 160,200, lr:2.000e-04> G_loss: 2.364e-02 
22-01-12 06:44:15.580 : <epoch:566, iter: 160,400, lr:2.000e-04> G_loss: 2.854e-02 
22-01-12 06:44:42.253 : <epoch:567, iter: 160,600, lr:2.000e-04> G_loss: 2.118e-02 
22-01-12 06:45:08.926 : <epoch:568, iter: 160,800, lr:2.000e-04> G_loss: 1.661e-02 
22-01-12 06:45:35.020 : <epoch:568, iter: 161,000, lr:2.000e-04> G_loss: 3.111e-02 
22-01-12 06:46:01.827 : <epoch:569, iter: 161,200, lr:2.000e-04> G_loss: 2.162e-02 
22-01-12 06:46:28.463 : <epoch:570, iter: 161,400, lr:2.000e-04> G_loss: 4.359e-02 
22-01-12 06:46:55.123 : <epoch:571, iter: 161,600, lr:2.000e-04> G_loss: 5.689e-02 
22-01-12 06:47:21.191 : <epoch:571, iter: 161,800, lr:2.000e-04> G_loss: 2.706e-02 
22-01-12 06:47:47.830 : <epoch:572, iter: 162,000, lr:2.000e-04> G_loss: 2.917e-02 
22-01-12 06:48:14.463 : <epoch:573, iter: 162,200, lr:2.000e-04> G_loss: 2.817e-02 
22-01-12 06:48:40.534 : <epoch:573, iter: 162,400, lr:2.000e-04> G_loss: 2.423e-02 
22-01-12 06:49:07.163 : <epoch:574, iter: 162,600, lr:2.000e-04> G_loss: 4.709e-02 
22-01-12 06:49:33.748 : <epoch:575, iter: 162,800, lr:2.000e-04> G_loss: 4.202e-02 
22-01-12 06:49:59.809 : <epoch:575, iter: 163,000, lr:2.000e-04> G_loss: 3.026e-02 
22-01-12 06:50:26.498 : <epoch:576, iter: 163,200, lr:2.000e-04> G_loss: 2.949e-02 
22-01-12 06:50:53.234 : <epoch:577, iter: 163,400, lr:2.000e-04> G_loss: 2.867e-02 
22-01-12 06:51:19.849 : <epoch:578, iter: 163,600, lr:2.000e-04> G_loss: 3.040e-02 
22-01-12 06:51:45.932 : <epoch:578, iter: 163,800, lr:2.000e-04> G_loss: 8.951e-03 
22-01-12 06:52:12.696 : <epoch:579, iter: 164,000, lr:2.000e-04> G_loss: 3.967e-02 
22-01-12 06:52:39.304 : <epoch:580, iter: 164,200, lr:2.000e-04> G_loss: 4.728e-02 
22-01-12 06:53:05.383 : <epoch:580, iter: 164,400, lr:2.000e-04> G_loss: 1.968e-02 
22-01-12 06:53:32.029 : <epoch:581, iter: 164,600, lr:2.000e-04> G_loss: 5.975e-02 
22-01-12 06:53:58.657 : <epoch:582, iter: 164,800, lr:2.000e-04> G_loss: 3.889e-02 
22-01-12 06:54:25.315 : <epoch:583, iter: 165,000, lr:2.000e-04> G_loss: 4.130e-02 
22-01-12 06:54:25.315 : Saving the model.
22-01-12 06:54:25.980 : ---1-->  12003.png | 28.67dB
22-01-12 06:54:26.280 : ---2-->  12074.png | 31.26dB
22-01-12 06:54:26.595 : ---3-->  15004.png | 24.72dB
22-01-12 06:54:26.894 : ---4-->  15088.png | 25.22dB
22-01-12 06:54:27.200 : ---5-->  16052.png | 33.54dB
22-01-12 06:54:27.493 : ---6-->   2092.png | 29.24dB
22-01-12 06:54:27.778 : ---7-->   8049.png | 27.68dB
22-01-12 06:54:28.041 : ---8-->   8143.png | 20.25dB
22-01-12 06:54:28.077 : <epoch:583, iter: 165,000, Average PSNR : 27.57dB

22-01-12 06:54:54.136 : <epoch:583, iter: 165,200, lr:2.000e-04> G_loss: 3.538e-02 
22-01-12 06:55:20.831 : <epoch:584, iter: 165,400, lr:2.000e-04> G_loss: 2.188e-02 
22-01-12 06:55:47.592 : <epoch:585, iter: 165,600, lr:2.000e-04> G_loss: 2.819e-02 
22-01-12 06:56:13.580 : <epoch:585, iter: 165,800, lr:2.000e-04> G_loss: 2.964e-02 
22-01-12 06:56:40.230 : <epoch:586, iter: 166,000, lr:2.000e-04> G_loss: 2.032e-02 
22-01-12 06:57:06.898 : <epoch:587, iter: 166,200, lr:2.000e-04> G_loss: 1.139e-02 
22-01-12 06:57:32.891 : <epoch:587, iter: 166,400, lr:2.000e-04> G_loss: 4.484e-02 
22-01-12 06:57:59.520 : <epoch:588, iter: 166,600, lr:2.000e-04> G_loss: 3.827e-02 
22-01-12 06:58:26.113 : <epoch:589, iter: 166,800, lr:2.000e-04> G_loss: 2.804e-02 
22-01-12 06:58:52.784 : <epoch:590, iter: 167,000, lr:2.000e-04> G_loss: 2.862e-02 
22-01-12 06:59:18.904 : <epoch:590, iter: 167,200, lr:2.000e-04> G_loss: 2.493e-02 
22-01-12 06:59:45.575 : <epoch:591, iter: 167,400, lr:2.000e-04> G_loss: 8.101e-02 
22-01-12 07:00:12.189 : <epoch:592, iter: 167,600, lr:2.000e-04> G_loss: 4.449e-02 
22-01-12 07:00:38.261 : <epoch:592, iter: 167,800, lr:2.000e-04> G_loss: 4.594e-02 
22-01-12 07:01:04.887 : <epoch:593, iter: 168,000, lr:2.000e-04> G_loss: 1.971e-02 
22-01-12 07:01:31.507 : <epoch:594, iter: 168,200, lr:2.000e-04> G_loss: 2.194e-02 
22-01-12 07:01:58.181 : <epoch:595, iter: 168,400, lr:2.000e-04> G_loss: 1.479e-02 
22-01-12 07:02:24.213 : <epoch:595, iter: 168,600, lr:2.000e-04> G_loss: 9.700e-03 
22-01-12 07:02:50.876 : <epoch:596, iter: 168,800, lr:2.000e-04> G_loss: 1.311e-02 
22-01-12 07:03:17.532 : <epoch:597, iter: 169,000, lr:2.000e-04> G_loss: 2.640e-02 
22-01-12 07:03:43.592 : <epoch:597, iter: 169,200, lr:2.000e-04> G_loss: 1.987e-02 
22-01-12 07:04:10.267 : <epoch:598, iter: 169,400, lr:2.000e-04> G_loss: 1.896e-02 
22-01-12 07:04:36.888 : <epoch:599, iter: 169,600, lr:2.000e-04> G_loss: 3.719e-02 
22-01-12 07:05:02.930 : <epoch:599, iter: 169,800, lr:2.000e-04> G_loss: 1.972e-02 
22-01-12 07:05:29.576 : <epoch:600, iter: 170,000, lr:2.000e-04> G_loss: 2.415e-02 
22-01-12 07:05:29.576 : Saving the model.
22-01-12 07:05:30.203 : ---1-->  12003.png | 28.83dB
22-01-12 07:05:30.510 : ---2-->  12074.png | 31.13dB
22-01-12 07:05:30.820 : ---3-->  15004.png | 24.65dB
22-01-12 07:05:31.140 : ---4-->  15088.png | 25.35dB
22-01-12 07:05:31.438 : ---5-->  16052.png | 33.26dB
22-01-12 07:05:31.768 : ---6-->   2092.png | 29.26dB
22-01-12 07:05:32.070 : ---7-->   8049.png | 27.72dB
22-01-12 07:05:32.362 : ---8-->   8143.png | 20.22dB
22-01-12 07:05:32.395 : <epoch:600, iter: 170,000, Average PSNR : 27.55dB

22-01-12 07:05:59.087 : <epoch:601, iter: 170,200, lr:2.000e-04> G_loss: 3.449e-02 
22-01-12 07:06:25.713 : <epoch:602, iter: 170,400, lr:2.000e-04> G_loss: 4.227e-02 
22-01-12 07:06:51.780 : <epoch:602, iter: 170,600, lr:2.000e-04> G_loss: 3.996e-02 
22-01-12 07:07:18.471 : <epoch:603, iter: 170,800, lr:2.000e-04> G_loss: 5.989e-02 
22-01-12 07:07:45.109 : <epoch:604, iter: 171,000, lr:2.000e-04> G_loss: 1.143e-02 
22-01-12 07:08:11.189 : <epoch:604, iter: 171,200, lr:2.000e-04> G_loss: 9.130e-03 
22-01-12 07:08:37.867 : <epoch:605, iter: 171,400, lr:2.000e-04> G_loss: 1.722e-02 
22-01-12 07:09:04.501 : <epoch:606, iter: 171,600, lr:2.000e-04> G_loss: 5.104e-02 
22-01-12 07:09:31.152 : <epoch:607, iter: 171,800, lr:2.000e-04> G_loss: 2.607e-02 
22-01-12 07:09:57.226 : <epoch:607, iter: 172,000, lr:2.000e-04> G_loss: 2.244e-02 
22-01-12 07:10:23.873 : <epoch:608, iter: 172,200, lr:2.000e-04> G_loss: 5.106e-02 
22-01-12 07:10:50.562 : <epoch:609, iter: 172,400, lr:2.000e-04> G_loss: 3.112e-02 
22-01-12 07:11:16.610 : <epoch:609, iter: 172,600, lr:2.000e-04> G_loss: 2.615e-02 
22-01-12 07:11:43.264 : <epoch:610, iter: 172,800, lr:2.000e-04> G_loss: 3.239e-02 
22-01-12 07:12:10.031 : <epoch:611, iter: 173,000, lr:2.000e-04> G_loss: 9.530e-03 
22-01-12 07:12:36.628 : <epoch:612, iter: 173,200, lr:2.000e-04> G_loss: 2.481e-02 
22-01-12 07:13:02.745 : <epoch:612, iter: 173,400, lr:2.000e-04> G_loss: 2.574e-02 
22-01-12 07:13:29.336 : <epoch:613, iter: 173,600, lr:2.000e-04> G_loss: 3.456e-02 
22-01-12 07:13:55.958 : <epoch:614, iter: 173,800, lr:2.000e-04> G_loss: 2.578e-02 
22-01-12 07:14:22.038 : <epoch:614, iter: 174,000, lr:2.000e-04> G_loss: 4.407e-02 
22-01-12 07:14:48.683 : <epoch:615, iter: 174,200, lr:2.000e-04> G_loss: 1.465e-02 
22-01-12 07:15:15.307 : <epoch:616, iter: 174,400, lr:2.000e-04> G_loss: 1.590e-02 
22-01-12 07:15:41.350 : <epoch:616, iter: 174,600, lr:2.000e-04> G_loss: 1.667e-02 
22-01-12 07:16:08.120 : <epoch:617, iter: 174,800, lr:2.000e-04> G_loss: 2.345e-02 
22-01-12 07:16:34.827 : <epoch:618, iter: 175,000, lr:2.000e-04> G_loss: 1.292e-02 
22-01-12 07:16:34.827 : Saving the model.
22-01-12 07:16:35.458 : ---1-->  12003.png | 28.64dB
22-01-12 07:16:35.757 : ---2-->  12074.png | 31.25dB
22-01-12 07:16:36.079 : ---3-->  15004.png | 24.70dB
22-01-12 07:16:36.405 : ---4-->  15088.png | 25.33dB
22-01-12 07:16:36.710 : ---5-->  16052.png | 33.43dB
22-01-12 07:16:37.013 : ---6-->   2092.png | 29.28dB
22-01-12 07:16:37.301 : ---7-->   8049.png | 27.68dB
22-01-12 07:16:37.614 : ---8-->   8143.png | 20.26dB
22-01-12 07:16:37.645 : <epoch:618, iter: 175,000, Average PSNR : 27.57dB

22-01-12 07:17:04.356 : <epoch:619, iter: 175,200, lr:2.000e-04> G_loss: 9.712e-03 
22-01-12 07:17:30.443 : <epoch:619, iter: 175,400, lr:2.000e-04> G_loss: 4.033e-02 
22-01-12 07:17:57.133 : <epoch:620, iter: 175,600, lr:2.000e-04> G_loss: 4.358e-02 
22-01-12 07:18:23.797 : <epoch:621, iter: 175,800, lr:2.000e-04> G_loss: 1.697e-02 
22-01-12 07:18:49.902 : <epoch:621, iter: 176,000, lr:2.000e-04> G_loss: 7.010e-02 
22-01-12 07:19:16.645 : <epoch:622, iter: 176,200, lr:2.000e-04> G_loss: 2.948e-02 
22-01-12 07:19:43.429 : <epoch:623, iter: 176,400, lr:2.000e-04> G_loss: 1.743e-02 
22-01-12 07:20:10.063 : <epoch:624, iter: 176,600, lr:2.000e-04> G_loss: 1.753e-02 
22-01-12 07:20:36.166 : <epoch:624, iter: 176,800, lr:2.000e-04> G_loss: 4.022e-02 
22-01-12 07:21:02.796 : <epoch:625, iter: 177,000, lr:2.000e-04> G_loss: 5.503e-02 
22-01-12 07:21:29.454 : <epoch:626, iter: 177,200, lr:2.000e-04> G_loss: 4.718e-02 
22-01-12 07:21:55.625 : <epoch:626, iter: 177,400, lr:2.000e-04> G_loss: 9.838e-03 
22-01-12 07:22:22.247 : <epoch:627, iter: 177,600, lr:2.000e-04> G_loss: 1.342e-02 
22-01-12 07:22:48.902 : <epoch:628, iter: 177,800, lr:2.000e-04> G_loss: 1.830e-02 
22-01-12 07:23:15.100 : <epoch:628, iter: 178,000, lr:2.000e-04> G_loss: 1.793e-02 
22-01-12 07:23:41.736 : <epoch:629, iter: 178,200, lr:2.000e-04> G_loss: 2.371e-02 
22-01-12 07:24:08.492 : <epoch:630, iter: 178,400, lr:2.000e-04> G_loss: 4.004e-02 
22-01-12 07:24:35.135 : <epoch:631, iter: 178,600, lr:2.000e-04> G_loss: 1.447e-02 
22-01-12 07:25:01.357 : <epoch:631, iter: 178,800, lr:2.000e-04> G_loss: 1.614e-02 
22-01-12 07:25:27.983 : <epoch:632, iter: 179,000, lr:2.000e-04> G_loss: 4.172e-02 
22-01-12 07:25:54.654 : <epoch:633, iter: 179,200, lr:2.000e-04> G_loss: 6.945e-02 
22-01-12 07:26:20.734 : <epoch:633, iter: 179,400, lr:2.000e-04> G_loss: 1.765e-02 
22-01-12 07:26:47.423 : <epoch:634, iter: 179,600, lr:2.000e-04> G_loss: 1.890e-02 
22-01-12 07:27:14.096 : <epoch:635, iter: 179,800, lr:2.000e-04> G_loss: 2.562e-02 
22-01-12 07:27:40.759 : <epoch:636, iter: 180,000, lr:2.000e-04> G_loss: 1.578e-02 
22-01-12 07:27:40.759 : Saving the model.
22-01-12 07:27:41.408 : ---1-->  12003.png | 28.78dB
22-01-12 07:27:41.750 : ---2-->  12074.png | 31.15dB
22-01-12 07:27:42.081 : ---3-->  15004.png | 24.72dB
22-01-12 07:27:42.429 : ---4-->  15088.png | 25.35dB
22-01-12 07:27:42.747 : ---5-->  16052.png | 33.57dB
22-01-12 07:27:43.063 : ---6-->   2092.png | 29.21dB
22-01-12 07:27:43.376 : ---7-->   8049.png | 27.70dB
22-01-12 07:27:43.647 : ---8-->   8143.png | 20.31dB
22-01-12 07:27:43.681 : <epoch:636, iter: 180,000, Average PSNR : 27.60dB

22-01-12 07:28:09.734 : <epoch:636, iter: 180,200, lr:2.000e-04> G_loss: 2.350e-02 
22-01-12 07:28:36.437 : <epoch:637, iter: 180,400, lr:2.000e-04> G_loss: 2.456e-02 
22-01-12 07:29:03.093 : <epoch:638, iter: 180,600, lr:2.000e-04> G_loss: 7.269e-02 
22-01-12 07:29:29.159 : <epoch:638, iter: 180,800, lr:2.000e-04> G_loss: 2.777e-02 
22-01-12 07:29:55.815 : <epoch:639, iter: 181,000, lr:2.000e-04> G_loss: 3.014e-02 
22-01-12 07:30:22.450 : <epoch:640, iter: 181,200, lr:2.000e-04> G_loss: 9.555e-03 
22-01-12 07:30:48.467 : <epoch:640, iter: 181,400, lr:2.000e-04> G_loss: 2.455e-02 
22-01-12 07:31:15.092 : <epoch:641, iter: 181,600, lr:2.000e-04> G_loss: 4.968e-02 
22-01-12 07:31:41.753 : <epoch:642, iter: 181,800, lr:2.000e-04> G_loss: 1.744e-02 
22-01-12 07:32:08.357 : <epoch:643, iter: 182,000, lr:2.000e-04> G_loss: 4.165e-02 
22-01-12 07:32:34.477 : <epoch:643, iter: 182,200, lr:2.000e-04> G_loss: 5.413e-02 
22-01-12 07:33:01.134 : <epoch:644, iter: 182,400, lr:2.000e-04> G_loss: 1.713e-02 
22-01-12 07:33:27.760 : <epoch:645, iter: 182,600, lr:2.000e-04> G_loss: 3.717e-03 
22-01-12 07:33:53.835 : <epoch:645, iter: 182,800, lr:2.000e-04> G_loss: 2.609e-02 
22-01-12 07:34:20.599 : <epoch:646, iter: 183,000, lr:2.000e-04> G_loss: 2.529e-02 
22-01-12 07:34:47.160 : <epoch:647, iter: 183,200, lr:2.000e-04> G_loss: 2.604e-02 
22-01-12 07:35:13.785 : <epoch:648, iter: 183,400, lr:2.000e-04> G_loss: 3.841e-02 
22-01-12 07:35:39.903 : <epoch:648, iter: 183,600, lr:2.000e-04> G_loss: 2.664e-02 
22-01-12 07:36:06.507 : <epoch:649, iter: 183,800, lr:2.000e-04> G_loss: 2.606e-02 
22-01-12 07:36:33.201 : <epoch:650, iter: 184,000, lr:2.000e-04> G_loss: 5.295e-02 
22-01-12 07:36:59.405 : <epoch:650, iter: 184,200, lr:2.000e-04> G_loss: 3.301e-02 
22-01-12 07:37:26.110 : <epoch:651, iter: 184,400, lr:2.000e-04> G_loss: 1.773e-02 
22-01-12 07:37:52.726 : <epoch:652, iter: 184,600, lr:2.000e-04> G_loss: 3.469e-03 
22-01-12 07:38:19.324 : <epoch:653, iter: 184,800, lr:2.000e-04> G_loss: 6.414e-02 
22-01-12 07:38:45.411 : <epoch:653, iter: 185,000, lr:2.000e-04> G_loss: 2.822e-02 
22-01-12 07:38:45.412 : Saving the model.
22-01-12 07:38:46.058 : ---1-->  12003.png | 28.68dB
22-01-12 07:38:46.344 : ---2-->  12074.png | 31.26dB
22-01-12 07:38:46.677 : ---3-->  15004.png | 24.73dB
22-01-12 07:38:46.960 : ---4-->  15088.png | 25.23dB
22-01-12 07:38:47.252 : ---5-->  16052.png | 33.64dB
22-01-12 07:38:47.529 : ---6-->   2092.png | 29.19dB
22-01-12 07:38:47.821 : ---7-->   8049.png | 27.67dB
22-01-12 07:38:48.116 : ---8-->   8143.png | 20.32dB
22-01-12 07:38:48.151 : <epoch:653, iter: 185,000, Average PSNR : 27.59dB

22-01-12 07:39:14.788 : <epoch:654, iter: 185,200, lr:2.000e-04> G_loss: 1.860e-02 
22-01-12 07:39:41.458 : <epoch:655, iter: 185,400, lr:2.000e-04> G_loss: 2.496e-02 
22-01-12 07:40:07.529 : <epoch:655, iter: 185,600, lr:2.000e-04> G_loss: 6.097e-02 
22-01-12 07:40:34.165 : <epoch:656, iter: 185,800, lr:2.000e-04> G_loss: 3.781e-02 
22-01-12 07:41:00.814 : <epoch:657, iter: 186,000, lr:2.000e-04> G_loss: 2.164e-02 
22-01-12 07:41:26.911 : <epoch:657, iter: 186,200, lr:2.000e-04> G_loss: 2.052e-02 
22-01-12 07:41:53.510 : <epoch:658, iter: 186,400, lr:2.000e-04> G_loss: 3.294e-02 
22-01-12 07:42:20.234 : <epoch:659, iter: 186,600, lr:2.000e-04> G_loss: 2.166e-02 
22-01-12 07:42:46.853 : <epoch:660, iter: 186,800, lr:2.000e-04> G_loss: 1.896e-02 
22-01-12 07:43:13.005 : <epoch:660, iter: 187,000, lr:2.000e-04> G_loss: 3.720e-02 
22-01-12 07:43:39.644 : <epoch:661, iter: 187,200, lr:2.000e-04> G_loss: 3.060e-02 
22-01-12 07:44:06.260 : <epoch:662, iter: 187,400, lr:2.000e-04> G_loss: 4.257e-02 
22-01-12 07:44:32.392 : <epoch:662, iter: 187,600, lr:2.000e-04> G_loss: 1.717e-02 
22-01-12 07:44:58.999 : <epoch:663, iter: 187,800, lr:2.000e-04> G_loss: 3.468e-02 
22-01-12 07:45:25.644 : <epoch:664, iter: 188,000, lr:2.000e-04> G_loss: 4.629e-02 
22-01-12 07:45:52.316 : <epoch:665, iter: 188,200, lr:2.000e-04> G_loss: 5.961e-02 
22-01-12 07:46:18.386 : <epoch:665, iter: 188,400, lr:2.000e-04> G_loss: 2.861e-02 
22-01-12 07:46:45.045 : <epoch:666, iter: 188,600, lr:2.000e-04> G_loss: 1.780e-02 
22-01-12 07:47:11.715 : <epoch:667, iter: 188,800, lr:2.000e-04> G_loss: 6.289e-02 
22-01-12 07:47:37.830 : <epoch:667, iter: 189,000, lr:2.000e-04> G_loss: 1.909e-02 
22-01-12 07:48:04.519 : <epoch:668, iter: 189,200, lr:2.000e-04> G_loss: 2.661e-02 
22-01-12 07:48:31.298 : <epoch:669, iter: 189,400, lr:2.000e-04> G_loss: 4.657e-02 
22-01-12 07:48:57.395 : <epoch:669, iter: 189,600, lr:2.000e-04> G_loss: 1.788e-02 
22-01-12 07:49:24.118 : <epoch:670, iter: 189,800, lr:2.000e-04> G_loss: 1.021e-02 
22-01-12 07:49:50.792 : <epoch:671, iter: 190,000, lr:2.000e-04> G_loss: 9.365e-03 
22-01-12 07:49:50.792 : Saving the model.
22-01-12 07:49:51.423 : ---1-->  12003.png | 28.74dB
22-01-12 07:49:51.750 : ---2-->  12074.png | 31.34dB
22-01-12 07:49:52.064 : ---3-->  15004.png | 24.74dB
22-01-12 07:49:52.374 : ---4-->  15088.png | 25.38dB
22-01-12 07:49:52.677 : ---5-->  16052.png | 33.70dB
22-01-12 07:49:53.010 : ---6-->   2092.png | 29.26dB
22-01-12 07:49:53.295 : ---7-->   8049.png | 27.73dB
22-01-12 07:49:53.591 : ---8-->   8143.png | 20.34dB
22-01-12 07:49:53.623 : <epoch:671, iter: 190,000, Average PSNR : 27.66dB

22-01-12 07:50:20.315 : <epoch:672, iter: 190,200, lr:2.000e-04> G_loss: 1.951e-02 
22-01-12 07:50:46.371 : <epoch:672, iter: 190,400, lr:2.000e-04> G_loss: 4.737e-03 
22-01-12 07:51:13.042 : <epoch:673, iter: 190,600, lr:2.000e-04> G_loss: 7.055e-03 
22-01-12 07:51:39.742 : <epoch:674, iter: 190,800, lr:2.000e-04> G_loss: 2.206e-02 
22-01-12 07:52:05.769 : <epoch:674, iter: 191,000, lr:2.000e-04> G_loss: 2.912e-02 
22-01-12 07:52:32.585 : <epoch:675, iter: 191,200, lr:2.000e-04> G_loss: 4.630e-02 
22-01-12 07:52:59.241 : <epoch:676, iter: 191,400, lr:2.000e-04> G_loss: 2.785e-02 
22-01-12 07:53:25.947 : <epoch:677, iter: 191,600, lr:2.000e-04> G_loss: 6.364e-02 
22-01-12 07:53:52.067 : <epoch:677, iter: 191,800, lr:2.000e-04> G_loss: 1.688e-02 
22-01-12 07:54:18.632 : <epoch:678, iter: 192,000, lr:2.000e-04> G_loss: 5.174e-02 
22-01-12 07:54:45.264 : <epoch:679, iter: 192,200, lr:2.000e-04> G_loss: 2.786e-02 
22-01-12 07:55:11.388 : <epoch:679, iter: 192,400, lr:2.000e-04> G_loss: 1.377e-02 
22-01-12 07:55:37.996 : <epoch:680, iter: 192,600, lr:2.000e-04> G_loss: 4.845e-02 
22-01-12 07:56:04.601 : <epoch:681, iter: 192,800, lr:2.000e-04> G_loss: 2.189e-02 
22-01-12 07:56:30.694 : <epoch:681, iter: 193,000, lr:2.000e-04> G_loss: 2.658e-02 
22-01-12 07:56:57.450 : <epoch:682, iter: 193,200, lr:2.000e-04> G_loss: 1.817e-02 
22-01-12 07:57:24.151 : <epoch:683, iter: 193,400, lr:2.000e-04> G_loss: 4.418e-02 
22-01-12 07:57:50.792 : <epoch:684, iter: 193,600, lr:2.000e-04> G_loss: 4.611e-02 
22-01-12 07:58:16.883 : <epoch:684, iter: 193,800, lr:2.000e-04> G_loss: 2.728e-02 
22-01-12 07:58:43.571 : <epoch:685, iter: 194,000, lr:2.000e-04> G_loss: 2.598e-02 
22-01-12 07:59:10.250 : <epoch:686, iter: 194,200, lr:2.000e-04> G_loss: 3.073e-02 
22-01-12 07:59:36.404 : <epoch:686, iter: 194,400, lr:2.000e-04> G_loss: 1.321e-02 
22-01-12 08:00:03.056 : <epoch:687, iter: 194,600, lr:2.000e-04> G_loss: 1.670e-02 
22-01-12 08:00:29.756 : <epoch:688, iter: 194,800, lr:2.000e-04> G_loss: 7.022e-02 
22-01-12 08:00:56.365 : <epoch:689, iter: 195,000, lr:2.000e-04> G_loss: 2.087e-02 
22-01-12 08:00:56.365 : Saving the model.
22-01-12 08:00:57.024 : ---1-->  12003.png | 28.84dB
22-01-12 08:00:57.339 : ---2-->  12074.png | 31.24dB
22-01-12 08:00:57.633 : ---3-->  15004.png | 24.70dB
22-01-12 08:00:57.951 : ---4-->  15088.png | 25.43dB
22-01-12 08:00:58.257 : ---5-->  16052.png | 33.53dB
22-01-12 08:00:58.569 : ---6-->   2092.png | 29.27dB
22-01-12 08:00:58.855 : ---7-->   8049.png | 27.70dB
22-01-12 08:00:59.166 : ---8-->   8143.png | 20.33dB
22-01-12 08:00:59.197 : <epoch:689, iter: 195,000, Average PSNR : 27.63dB

22-01-12 08:01:25.231 : <epoch:689, iter: 195,200, lr:2.000e-04> G_loss: 1.303e-02 
22-01-12 08:01:51.852 : <epoch:690, iter: 195,400, lr:2.000e-04> G_loss: 5.027e-02 
22-01-12 08:02:18.544 : <epoch:691, iter: 195,600, lr:2.000e-04> G_loss: 1.303e-02 
22-01-12 08:02:44.628 : <epoch:691, iter: 195,800, lr:2.000e-04> G_loss: 1.349e-02 
22-01-12 08:03:11.248 : <epoch:692, iter: 196,000, lr:2.000e-04> G_loss: 2.097e-02 
22-01-12 08:03:37.907 : <epoch:693, iter: 196,200, lr:2.000e-04> G_loss: 1.110e-02 
22-01-12 08:04:04.039 : <epoch:693, iter: 196,400, lr:2.000e-04> G_loss: 1.885e-02 
22-01-12 08:04:30.770 : <epoch:694, iter: 196,600, lr:2.000e-04> G_loss: 2.001e-02 
22-01-12 08:04:57.359 : <epoch:695, iter: 196,800, lr:2.000e-04> G_loss: 3.259e-02 
22-01-12 08:05:23.920 : <epoch:696, iter: 197,000, lr:2.000e-04> G_loss: 4.627e-02 
22-01-12 08:05:50.038 : <epoch:696, iter: 197,200, lr:2.000e-04> G_loss: 2.257e-02 
22-01-12 08:06:16.790 : <epoch:697, iter: 197,400, lr:2.000e-04> G_loss: 1.605e-02 
22-01-12 08:06:43.426 : <epoch:698, iter: 197,600, lr:2.000e-04> G_loss: 2.738e-02 
22-01-12 08:07:09.503 : <epoch:698, iter: 197,800, lr:2.000e-04> G_loss: 1.674e-02 
22-01-12 08:07:36.176 : <epoch:699, iter: 198,000, lr:2.000e-04> G_loss: 3.438e-02 
22-01-12 08:08:02.821 : <epoch:700, iter: 198,200, lr:2.000e-04> G_loss: 4.324e-02 
22-01-12 08:08:29.458 : <epoch:701, iter: 198,400, lr:2.000e-04> G_loss: 6.636e-02 
22-01-12 08:08:55.483 : <epoch:701, iter: 198,600, lr:2.000e-04> G_loss: 2.801e-02 
22-01-12 08:09:22.104 : <epoch:702, iter: 198,800, lr:2.000e-04> G_loss: 3.831e-02 
22-01-12 08:09:48.791 : <epoch:703, iter: 199,000, lr:2.000e-04> G_loss: 1.366e-02 
22-01-12 08:10:14.872 : <epoch:703, iter: 199,200, lr:2.000e-04> G_loss: 9.574e-03 
22-01-12 08:10:41.501 : <epoch:704, iter: 199,400, lr:2.000e-04> G_loss: 3.495e-02 
22-01-12 08:11:08.163 : <epoch:705, iter: 199,600, lr:2.000e-04> G_loss: 1.777e-02 
22-01-12 08:11:34.915 : <epoch:706, iter: 199,800, lr:2.000e-04> G_loss: 2.994e-02 
22-01-12 08:12:00.894 : <epoch:706, iter: 200,000, lr:2.000e-04> G_loss: 9.966e-03 
22-01-12 08:12:00.894 : Saving the model.
22-01-12 08:12:01.534 : ---1-->  12003.png | 28.70dB
22-01-12 08:12:01.848 : ---2-->  12074.png | 31.18dB
22-01-12 08:12:02.161 : ---3-->  15004.png | 24.75dB
22-01-12 08:12:02.467 : ---4-->  15088.png | 25.37dB
22-01-12 08:12:02.778 : ---5-->  16052.png | 33.57dB
22-01-12 08:12:03.097 : ---6-->   2092.png | 29.25dB
22-01-12 08:12:03.391 : ---7-->   8049.png | 27.75dB
22-01-12 08:12:03.678 : ---8-->   8143.png | 20.30dB
22-01-12 08:12:03.710 : <epoch:706, iter: 200,000, Average PSNR : 27.61dB

22-01-12 08:12:30.400 : <epoch:707, iter: 200,200, lr:2.000e-04> G_loss: 1.238e-02 
22-01-12 08:12:57.052 : <epoch:708, iter: 200,400, lr:2.000e-04> G_loss: 9.581e-03 
22-01-12 08:13:23.130 : <epoch:708, iter: 200,600, lr:2.000e-04> G_loss: 2.820e-02 
22-01-12 08:13:49.809 : <epoch:709, iter: 200,800, lr:2.000e-04> G_loss: 1.390e-02 
22-01-12 08:14:16.462 : <epoch:710, iter: 201,000, lr:2.000e-04> G_loss: 7.922e-02 
22-01-12 08:14:42.505 : <epoch:710, iter: 201,200, lr:2.000e-04> G_loss: 2.951e-02 
22-01-12 08:15:09.171 : <epoch:711, iter: 201,400, lr:2.000e-04> G_loss: 2.353e-02 
22-01-12 08:15:35.843 : <epoch:712, iter: 201,600, lr:2.000e-04> G_loss: 1.737e-02 
22-01-12 08:16:02.475 : <epoch:713, iter: 201,800, lr:2.000e-04> G_loss: 2.568e-02 
22-01-12 08:16:28.578 : <epoch:713, iter: 202,000, lr:2.000e-04> G_loss: 3.016e-02 
22-01-12 08:16:55.234 : <epoch:714, iter: 202,200, lr:2.000e-04> G_loss: 5.870e-02 
22-01-12 08:17:21.890 : <epoch:715, iter: 202,400, lr:2.000e-04> G_loss: 1.728e-02 
22-01-12 08:17:47.949 : <epoch:715, iter: 202,600, lr:2.000e-04> G_loss: 4.166e-02 
22-01-12 08:18:14.591 : <epoch:716, iter: 202,800, lr:2.000e-04> G_loss: 1.411e-02 
22-01-12 08:18:41.365 : <epoch:717, iter: 203,000, lr:2.000e-04> G_loss: 3.099e-02 
22-01-12 08:19:08.006 : <epoch:718, iter: 203,200, lr:2.000e-04> G_loss: 4.088e-02 
22-01-12 08:19:34.127 : <epoch:718, iter: 203,400, lr:2.000e-04> G_loss: 1.811e-02 
22-01-12 08:20:00.811 : <epoch:719, iter: 203,600, lr:2.000e-04> G_loss: 2.528e-02 
22-01-12 08:20:27.466 : <epoch:720, iter: 203,800, lr:2.000e-04> G_loss: 5.560e-02 
22-01-12 08:20:53.535 : <epoch:720, iter: 204,000, lr:2.000e-04> G_loss: 5.646e-02 
22-01-12 08:21:20.153 : <epoch:721, iter: 204,200, lr:2.000e-04> G_loss: 1.779e-02 
22-01-12 08:21:46.815 : <epoch:722, iter: 204,400, lr:2.000e-04> G_loss: 7.831e-02 
22-01-12 08:22:12.881 : <epoch:722, iter: 204,600, lr:2.000e-04> G_loss: 1.818e-02 
22-01-12 08:22:39.527 : <epoch:723, iter: 204,800, lr:2.000e-04> G_loss: 4.775e-02 
22-01-12 08:23:06.189 : <epoch:724, iter: 205,000, lr:2.000e-04> G_loss: 4.945e-02 
22-01-12 08:23:06.189 : Saving the model.
22-01-12 08:23:06.861 : ---1-->  12003.png | 28.84dB
22-01-12 08:23:07.174 : ---2-->  12074.png | 31.23dB
22-01-12 08:23:07.477 : ---3-->  15004.png | 24.78dB
22-01-12 08:23:07.764 : ---4-->  15088.png | 25.43dB
22-01-12 08:23:08.053 : ---5-->  16052.png | 33.60dB
22-01-12 08:23:08.351 : ---6-->   2092.png | 29.30dB
22-01-12 08:23:08.644 : ---7-->   8049.png | 27.82dB
22-01-12 08:23:08.906 : ---8-->   8143.png | 20.32dB
22-01-12 08:23:08.938 : <epoch:724, iter: 205,000, Average PSNR : 27.66dB

22-01-12 08:23:35.755 : <epoch:725, iter: 205,200, lr:2.000e-04> G_loss: 2.364e-02 
22-01-12 08:24:01.934 : <epoch:725, iter: 205,400, lr:2.000e-04> G_loss: 3.478e-02 
22-01-12 08:24:28.543 : <epoch:726, iter: 205,600, lr:2.000e-04> G_loss: 1.340e-02 
22-01-12 08:24:55.180 : <epoch:727, iter: 205,800, lr:2.000e-04> G_loss: 3.304e-02 
22-01-12 08:25:21.320 : <epoch:727, iter: 206,000, lr:2.000e-04> G_loss: 1.875e-02 
22-01-12 08:25:47.929 : <epoch:728, iter: 206,200, lr:2.000e-04> G_loss: 2.687e-02 
22-01-12 08:26:14.566 : <epoch:729, iter: 206,400, lr:2.000e-04> G_loss: 2.629e-02 
22-01-12 08:26:41.287 : <epoch:730, iter: 206,600, lr:2.000e-04> G_loss: 2.965e-02 
22-01-12 08:27:07.431 : <epoch:730, iter: 206,800, lr:2.000e-04> G_loss: 3.737e-02 
22-01-12 08:27:34.217 : <epoch:731, iter: 207,000, lr:2.000e-04> G_loss: 3.053e-02 
22-01-12 08:28:00.814 : <epoch:732, iter: 207,200, lr:2.000e-04> G_loss: 3.489e-02 
22-01-12 08:28:26.853 : <epoch:732, iter: 207,400, lr:2.000e-04> G_loss: 1.818e-02 
22-01-12 08:28:53.558 : <epoch:733, iter: 207,600, lr:2.000e-04> G_loss: 5.682e-02 
22-01-12 08:29:20.353 : <epoch:734, iter: 207,800, lr:2.000e-04> G_loss: 4.727e-03 
22-01-12 08:29:46.360 : <epoch:734, iter: 208,000, lr:2.000e-04> G_loss: 1.222e-02 
22-01-12 08:30:13.046 : <epoch:735, iter: 208,200, lr:2.000e-04> G_loss: 9.893e-03 
22-01-12 08:30:39.681 : <epoch:736, iter: 208,400, lr:2.000e-04> G_loss: 7.867e-03 
22-01-12 08:31:06.353 : <epoch:737, iter: 208,600, lr:2.000e-04> G_loss: 3.081e-02 
22-01-12 08:31:32.431 : <epoch:737, iter: 208,800, lr:2.000e-04> G_loss: 5.553e-02 
22-01-12 08:31:59.236 : <epoch:738, iter: 209,000, lr:2.000e-04> G_loss: 2.050e-02 
22-01-12 08:32:25.901 : <epoch:739, iter: 209,200, lr:2.000e-04> G_loss: 1.713e-02 
22-01-12 08:32:51.976 : <epoch:739, iter: 209,400, lr:2.000e-04> G_loss: 2.570e-02 
22-01-12 08:33:18.650 : <epoch:740, iter: 209,600, lr:2.000e-04> G_loss: 2.886e-02 
22-01-12 08:33:45.278 : <epoch:741, iter: 209,800, lr:2.000e-04> G_loss: 2.435e-02 
22-01-12 08:34:11.882 : <epoch:742, iter: 210,000, lr:2.000e-04> G_loss: 8.270e-03 
22-01-12 08:34:11.882 : Saving the model.
22-01-12 08:34:12.537 : ---1-->  12003.png | 28.80dB
22-01-12 08:34:12.847 : ---2-->  12074.png | 31.24dB
22-01-12 08:34:13.153 : ---3-->  15004.png | 24.78dB
22-01-12 08:34:13.456 : ---4-->  15088.png | 25.46dB
22-01-12 08:34:13.768 : ---5-->  16052.png | 33.70dB
22-01-12 08:34:14.054 : ---6-->   2092.png | 29.25dB
22-01-12 08:34:14.341 : ---7-->   8049.png | 27.78dB
22-01-12 08:34:14.628 : ---8-->   8143.png | 20.34dB
22-01-12 08:34:14.662 : <epoch:742, iter: 210,000, Average PSNR : 27.67dB

22-01-12 08:34:40.751 : <epoch:742, iter: 210,200, lr:2.000e-04> G_loss: 2.809e-02 
22-01-12 08:35:07.339 : <epoch:743, iter: 210,400, lr:2.000e-04> G_loss: 2.636e-02 
22-01-12 08:35:33.915 : <epoch:744, iter: 210,600, lr:2.000e-04> G_loss: 1.700e-02 
22-01-12 08:36:00.007 : <epoch:744, iter: 210,800, lr:2.000e-04> G_loss: 2.600e-02 
22-01-12 08:36:26.831 : <epoch:745, iter: 211,000, lr:2.000e-04> G_loss: 1.531e-02 
22-01-12 08:36:53.468 : <epoch:746, iter: 211,200, lr:2.000e-04> G_loss: 4.046e-02 
22-01-12 08:37:19.518 : <epoch:746, iter: 211,400, lr:2.000e-04> G_loss: 1.357e-02 
22-01-12 08:37:46.184 : <epoch:747, iter: 211,600, lr:2.000e-04> G_loss: 3.944e-02 
22-01-12 08:38:12.833 : <epoch:748, iter: 211,800, lr:2.000e-04> G_loss: 5.118e-02 
22-01-12 08:38:39.468 : <epoch:749, iter: 212,000, lr:2.000e-04> G_loss: 2.773e-02 
22-01-12 08:39:05.535 : <epoch:749, iter: 212,200, lr:2.000e-04> G_loss: 1.284e-02 
22-01-12 08:39:32.212 : <epoch:750, iter: 212,400, lr:2.000e-04> G_loss: 2.330e-02 
22-01-12 08:39:58.830 : <epoch:751, iter: 212,600, lr:2.000e-04> G_loss: 3.083e-02 
22-01-12 08:40:25.069 : <epoch:751, iter: 212,800, lr:2.000e-04> G_loss: 4.491e-02 
22-01-12 08:40:51.865 : <epoch:752, iter: 213,000, lr:2.000e-04> G_loss: 1.898e-02 
22-01-12 08:41:18.543 : <epoch:753, iter: 213,200, lr:2.000e-04> G_loss: 2.048e-02 
22-01-12 08:41:45.184 : <epoch:754, iter: 213,400, lr:2.000e-04> G_loss: 1.948e-02 
22-01-12 08:42:11.362 : <epoch:754, iter: 213,600, lr:2.000e-04> G_loss: 1.628e-02 
22-01-12 08:42:38.002 : <epoch:755, iter: 213,800, lr:2.000e-04> G_loss: 3.377e-02 
22-01-12 08:43:04.694 : <epoch:756, iter: 214,000, lr:2.000e-04> G_loss: 1.342e-02 
22-01-12 08:43:30.760 : <epoch:756, iter: 214,200, lr:2.000e-04> G_loss: 3.798e-02 
22-01-12 08:43:57.426 : <epoch:757, iter: 214,400, lr:2.000e-04> G_loss: 4.611e-02 
22-01-12 08:44:24.059 : <epoch:758, iter: 214,600, lr:2.000e-04> G_loss: 2.011e-02 
22-01-12 08:44:50.698 : <epoch:759, iter: 214,800, lr:2.000e-04> G_loss: 3.480e-02 
22-01-12 08:45:16.796 : <epoch:759, iter: 215,000, lr:2.000e-04> G_loss: 1.588e-02 
22-01-12 08:45:16.797 : Saving the model.
22-01-12 08:45:17.483 : ---1-->  12003.png | 28.81dB
22-01-12 08:45:17.759 : ---2-->  12074.png | 31.32dB
22-01-12 08:45:18.143 : ---3-->  15004.png | 24.81dB
22-01-12 08:45:18.449 : ---4-->  15088.png | 25.36dB
22-01-12 08:45:18.731 : ---5-->  16052.png | 33.76dB
22-01-12 08:45:19.031 : ---6-->   2092.png | 29.28dB
22-01-12 08:45:19.293 : ---7-->   8049.png | 27.83dB
22-01-12 08:45:19.555 : ---8-->   8143.png | 20.39dB
22-01-12 08:45:19.587 : <epoch:759, iter: 215,000, Average PSNR : 27.70dB

22-01-12 08:45:46.180 : <epoch:760, iter: 215,200, lr:2.000e-04> G_loss: 7.946e-03 
22-01-12 08:46:12.811 : <epoch:761, iter: 215,400, lr:2.000e-04> G_loss: 2.033e-02 
22-01-12 08:46:38.954 : <epoch:761, iter: 215,600, lr:2.000e-04> G_loss: 1.014e-02 
22-01-12 08:47:05.667 : <epoch:762, iter: 215,800, lr:2.000e-04> G_loss: 2.315e-02 
22-01-12 08:47:32.341 : <epoch:763, iter: 216,000, lr:2.000e-04> G_loss: 5.579e-02 
22-01-12 08:47:58.401 : <epoch:763, iter: 216,200, lr:2.000e-04> G_loss: 1.213e-02 
22-01-12 08:48:25.066 : <epoch:764, iter: 216,400, lr:2.000e-04> G_loss: 2.942e-02 
22-01-12 08:48:51.801 : <epoch:765, iter: 216,600, lr:2.000e-04> G_loss: 1.750e-02 
22-01-12 08:49:18.416 : <epoch:766, iter: 216,800, lr:2.000e-04> G_loss: 3.981e-02 
22-01-12 08:49:44.517 : <epoch:766, iter: 217,000, lr:2.000e-04> G_loss: 2.509e-02 
22-01-12 08:50:11.181 : <epoch:767, iter: 217,200, lr:2.000e-04> G_loss: 1.477e-02 
22-01-12 08:50:37.736 : <epoch:768, iter: 217,400, lr:2.000e-04> G_loss: 2.199e-02 
22-01-12 08:51:03.806 : <epoch:768, iter: 217,600, lr:2.000e-04> G_loss: 2.114e-02 
22-01-12 08:51:30.445 : <epoch:769, iter: 217,800, lr:2.000e-04> G_loss: 1.282e-02 
22-01-12 08:51:57.115 : <epoch:770, iter: 218,000, lr:2.000e-04> G_loss: 1.697e-02 
22-01-12 08:52:23.747 : <epoch:771, iter: 218,200, lr:2.000e-04> G_loss: 6.267e-02 
22-01-12 08:52:49.830 : <epoch:771, iter: 218,400, lr:2.000e-04> G_loss: 9.032e-03 
22-01-12 08:53:16.484 : <epoch:772, iter: 218,600, lr:2.000e-04> G_loss: 1.891e-02 
22-01-12 08:53:43.057 : <epoch:773, iter: 218,800, lr:2.000e-04> G_loss: 3.418e-02 
22-01-12 08:54:09.267 : <epoch:773, iter: 219,000, lr:2.000e-04> G_loss: 2.109e-02 
22-01-12 08:54:36.065 : <epoch:774, iter: 219,200, lr:2.000e-04> G_loss: 5.494e-02 
22-01-12 08:55:02.704 : <epoch:775, iter: 219,400, lr:2.000e-04> G_loss: 2.473e-02 
22-01-12 08:55:28.763 : <epoch:775, iter: 219,600, lr:2.000e-04> G_loss: 3.822e-02 
22-01-12 08:55:55.435 : <epoch:776, iter: 219,800, lr:2.000e-04> G_loss: 3.461e-02 
22-01-12 08:56:22.229 : <epoch:777, iter: 220,000, lr:2.000e-04> G_loss: 2.554e-02 
22-01-12 08:56:22.230 : Saving the model.
22-01-12 08:56:22.888 : ---1-->  12003.png | 28.68dB
22-01-12 08:56:23.181 : ---2-->  12074.png | 31.17dB
22-01-12 08:56:23.495 : ---3-->  15004.png | 24.74dB
22-01-12 08:56:23.795 : ---4-->  15088.png | 25.39dB
22-01-12 08:56:24.100 : ---5-->  16052.png | 33.47dB
22-01-12 08:56:24.435 : ---6-->   2092.png | 29.25dB
22-01-12 08:56:24.693 : ---7-->   8049.png | 27.84dB
22-01-12 08:56:24.958 : ---8-->   8143.png | 20.35dB
22-01-12 08:56:24.992 : <epoch:777, iter: 220,000, Average PSNR : 27.61dB

22-01-12 08:56:51.617 : <epoch:778, iter: 220,200, lr:2.000e-04> G_loss: 2.621e-02 
22-01-12 08:57:17.668 : <epoch:778, iter: 220,400, lr:2.000e-04> G_loss: 3.511e-02 
22-01-12 08:57:44.512 : <epoch:779, iter: 220,600, lr:2.000e-04> G_loss: 2.978e-02 
22-01-12 08:58:11.157 : <epoch:780, iter: 220,800, lr:2.000e-04> G_loss: 3.303e-02 
22-01-12 08:58:37.268 : <epoch:780, iter: 221,000, lr:2.000e-04> G_loss: 1.526e-02 
22-01-12 08:59:04.026 : <epoch:781, iter: 221,200, lr:2.000e-04> G_loss: 2.939e-02 
22-01-12 08:59:30.711 : <epoch:782, iter: 221,400, lr:2.000e-04> G_loss: 2.412e-02 
22-01-12 08:59:57.377 : <epoch:783, iter: 221,600, lr:2.000e-04> G_loss: 1.674e-02 
22-01-12 09:00:23.425 : <epoch:783, iter: 221,800, lr:2.000e-04> G_loss: 3.654e-02 
22-01-12 09:00:50.096 : <epoch:784, iter: 222,000, lr:2.000e-04> G_loss: 4.962e-02 
22-01-12 09:01:16.878 : <epoch:785, iter: 222,200, lr:2.000e-04> G_loss: 2.112e-02 
22-01-12 09:01:42.932 : <epoch:785, iter: 222,400, lr:2.000e-04> G_loss: 2.606e-02 
22-01-12 09:02:09.611 : <epoch:786, iter: 222,600, lr:2.000e-04> G_loss: 1.441e-02 
22-01-12 09:02:36.230 : <epoch:787, iter: 222,800, lr:2.000e-04> G_loss: 2.450e-02 
22-01-12 09:03:02.304 : <epoch:787, iter: 223,000, lr:2.000e-04> G_loss: 6.404e-03 
22-01-12 09:03:29.116 : <epoch:788, iter: 223,200, lr:2.000e-04> G_loss: 2.638e-02 
22-01-12 09:03:55.776 : <epoch:789, iter: 223,400, lr:2.000e-04> G_loss: 1.748e-02 
22-01-12 09:04:22.424 : <epoch:790, iter: 223,600, lr:2.000e-04> G_loss: 4.946e-02 
22-01-12 09:04:48.550 : <epoch:790, iter: 223,800, lr:2.000e-04> G_loss: 3.949e-02 
22-01-12 09:05:15.167 : <epoch:791, iter: 224,000, lr:2.000e-04> G_loss: 4.417e-02 
22-01-12 09:05:41.832 : <epoch:792, iter: 224,200, lr:2.000e-04> G_loss: 2.130e-02 
22-01-12 09:06:07.908 : <epoch:792, iter: 224,400, lr:2.000e-04> G_loss: 3.654e-02 
22-01-12 09:06:34.556 : <epoch:793, iter: 224,600, lr:2.000e-04> G_loss: 4.001e-02 
22-01-12 09:07:01.186 : <epoch:794, iter: 224,800, lr:2.000e-04> G_loss: 6.007e-03 
22-01-12 09:07:27.930 : <epoch:795, iter: 225,000, lr:2.000e-04> G_loss: 3.020e-02 
22-01-12 09:07:27.930 : Saving the model.
22-01-12 09:07:28.578 : ---1-->  12003.png | 28.94dB
22-01-12 09:07:28.881 : ---2-->  12074.png | 31.30dB
22-01-12 09:07:29.187 : ---3-->  15004.png | 24.82dB
22-01-12 09:07:29.490 : ---4-->  15088.png | 25.37dB
22-01-12 09:07:29.791 : ---5-->  16052.png | 33.71dB
22-01-12 09:07:30.093 : ---6-->   2092.png | 29.31dB
22-01-12 09:07:30.387 : ---7-->   8049.png | 27.85dB
22-01-12 09:07:30.663 : ---8-->   8143.png | 20.41dB
22-01-12 09:07:30.696 : <epoch:795, iter: 225,000, Average PSNR : 27.71dB

22-01-12 09:07:56.651 : <epoch:795, iter: 225,200, lr:2.000e-04> G_loss: 2.238e-02 
22-01-12 09:08:23.302 : <epoch:796, iter: 225,400, lr:2.000e-04> G_loss: 1.591e-02 
22-01-12 09:08:50.036 : <epoch:797, iter: 225,600, lr:2.000e-04> G_loss: 2.191e-02 
22-01-12 09:09:16.064 : <epoch:797, iter: 225,800, lr:2.000e-04> G_loss: 2.986e-02 
22-01-12 09:09:42.700 : <epoch:798, iter: 226,000, lr:2.000e-04> G_loss: 5.194e-02 
22-01-12 09:10:09.358 : <epoch:799, iter: 226,200, lr:2.000e-04> G_loss: 2.599e-02 
22-01-12 09:10:35.433 : <epoch:799, iter: 226,400, lr:2.000e-04> G_loss: 4.817e-02 
22-01-12 09:11:02.093 : <epoch:800, iter: 226,600, lr:2.000e-04> G_loss: 4.348e-02 
22-01-12 09:11:28.735 : <epoch:801, iter: 226,800, lr:2.000e-04> G_loss: 3.826e-02 
22-01-12 09:11:55.352 : <epoch:802, iter: 227,000, lr:2.000e-04> G_loss: 3.117e-02 
22-01-12 09:12:21.454 : <epoch:802, iter: 227,200, lr:2.000e-04> G_loss: 1.526e-02 
22-01-12 09:12:48.118 : <epoch:803, iter: 227,400, lr:2.000e-04> G_loss: 1.958e-02 
22-01-12 09:13:14.775 : <epoch:804, iter: 227,600, lr:2.000e-04> G_loss: 1.393e-02 
22-01-12 09:13:40.804 : <epoch:804, iter: 227,800, lr:2.000e-04> G_loss: 9.298e-03 
22-01-12 09:14:07.440 : <epoch:805, iter: 228,000, lr:2.000e-04> G_loss: 1.418e-02 
22-01-12 09:14:34.105 : <epoch:806, iter: 228,200, lr:2.000e-04> G_loss: 2.179e-02 
22-01-12 09:15:00.711 : <epoch:807, iter: 228,400, lr:2.000e-04> G_loss: 2.198e-02 
22-01-12 09:15:26.852 : <epoch:807, iter: 228,600, lr:2.000e-04> G_loss: 2.544e-02 
22-01-12 09:15:53.482 : <epoch:808, iter: 228,800, lr:2.000e-04> G_loss: 3.282e-02 
22-01-12 09:16:20.132 : <epoch:809, iter: 229,000, lr:2.000e-04> G_loss: 1.548e-02 
22-01-12 09:16:46.220 : <epoch:809, iter: 229,200, lr:2.000e-04> G_loss: 3.663e-02 
22-01-12 09:17:12.957 : <epoch:810, iter: 229,400, lr:2.000e-04> G_loss: 2.094e-02 
22-01-12 09:17:39.564 : <epoch:811, iter: 229,600, lr:2.000e-04> G_loss: 1.328e-02 
22-01-12 09:18:06.211 : <epoch:812, iter: 229,800, lr:2.000e-04> G_loss: 5.691e-02 
22-01-12 09:18:32.298 : <epoch:812, iter: 230,000, lr:2.000e-04> G_loss: 1.770e-02 
22-01-12 09:18:32.298 : Saving the model.
22-01-12 09:18:32.912 : ---1-->  12003.png | 28.89dB
22-01-12 09:18:33.220 : ---2-->  12074.png | 31.28dB
22-01-12 09:18:33.538 : ---3-->  15004.png | 24.81dB
22-01-12 09:18:33.863 : ---4-->  15088.png | 25.38dB
22-01-12 09:18:34.176 : ---5-->  16052.png | 33.80dB
22-01-12 09:18:34.480 : ---6-->   2092.png | 29.24dB
22-01-12 09:18:34.783 : ---7-->   8049.png | 27.87dB
22-01-12 09:18:35.046 : ---8-->   8143.png | 20.42dB
22-01-12 09:18:35.077 : <epoch:812, iter: 230,000, Average PSNR : 27.71dB

22-01-12 09:19:01.663 : <epoch:813, iter: 230,200, lr:2.000e-04> G_loss: 2.085e-02 
22-01-12 09:19:28.335 : <epoch:814, iter: 230,400, lr:2.000e-04> G_loss: 3.954e-02 
22-01-12 09:19:54.495 : <epoch:814, iter: 230,600, lr:2.000e-04> G_loss: 9.863e-03 
22-01-12 09:20:21.086 : <epoch:815, iter: 230,800, lr:2.000e-04> G_loss: 2.552e-02 
22-01-12 09:20:47.913 : <epoch:816, iter: 231,000, lr:2.000e-04> G_loss: 2.096e-02 
22-01-12 09:21:14.022 : <epoch:816, iter: 231,200, lr:2.000e-04> G_loss: 6.703e-02 
22-01-12 09:21:40.745 : <epoch:817, iter: 231,400, lr:2.000e-04> G_loss: 9.253e-03 
22-01-12 09:22:07.373 : <epoch:818, iter: 231,600, lr:2.000e-04> G_loss: 1.646e-02 
22-01-12 09:22:34.049 : <epoch:819, iter: 231,800, lr:2.000e-04> G_loss: 3.742e-02 
22-01-12 09:23:00.104 : <epoch:819, iter: 232,000, lr:2.000e-04> G_loss: 5.044e-02 
22-01-12 09:23:26.836 : <epoch:820, iter: 232,200, lr:2.000e-04> G_loss: 5.695e-02 
22-01-12 09:23:53.498 : <epoch:821, iter: 232,400, lr:2.000e-04> G_loss: 8.443e-03 
22-01-12 09:24:19.568 : <epoch:821, iter: 232,600, lr:2.000e-04> G_loss: 4.392e-02 
22-01-12 09:24:46.194 : <epoch:822, iter: 232,800, lr:2.000e-04> G_loss: 4.023e-02 
22-01-12 09:25:12.839 : <epoch:823, iter: 233,000, lr:2.000e-04> G_loss: 2.086e-02 
22-01-12 09:25:39.534 : <epoch:824, iter: 233,200, lr:2.000e-04> G_loss: 9.165e-03 
22-01-12 09:26:05.592 : <epoch:824, iter: 233,400, lr:2.000e-04> G_loss: 1.843e-02 
22-01-12 09:26:32.293 : <epoch:825, iter: 233,600, lr:2.000e-04> G_loss: 2.780e-02 
22-01-12 09:26:59.057 : <epoch:826, iter: 233,800, lr:2.000e-04> G_loss: 2.124e-02 
22-01-12 09:27:25.183 : <epoch:826, iter: 234,000, lr:2.000e-04> G_loss: 4.090e-02 
22-01-12 09:27:51.851 : <epoch:827, iter: 234,200, lr:2.000e-04> G_loss: 8.867e-03 
22-01-12 09:28:18.447 : <epoch:828, iter: 234,400, lr:2.000e-04> G_loss: 2.238e-02 
22-01-12 09:28:44.486 : <epoch:828, iter: 234,600, lr:2.000e-04> G_loss: 2.332e-02 
22-01-12 09:29:11.140 : <epoch:829, iter: 234,800, lr:2.000e-04> G_loss: 3.279e-02 
22-01-12 09:29:37.827 : <epoch:830, iter: 235,000, lr:2.000e-04> G_loss: 2.030e-02 
22-01-12 09:29:37.827 : Saving the model.
22-01-12 09:29:38.460 : ---1-->  12003.png | 28.80dB
22-01-12 09:29:38.745 : ---2-->  12074.png | 31.10dB
22-01-12 09:29:39.040 : ---3-->  15004.png | 24.77dB
22-01-12 09:29:39.349 : ---4-->  15088.png | 25.37dB
22-01-12 09:29:39.661 : ---5-->  16052.png | 33.66dB
22-01-12 09:29:39.933 : ---6-->   2092.png | 29.25dB
22-01-12 09:29:40.211 : ---7-->   8049.png | 27.83dB
22-01-12 09:29:40.498 : ---8-->   8143.png | 20.39dB
22-01-12 09:29:40.532 : <epoch:830, iter: 235,000, Average PSNR : 27.64dB

22-01-12 09:30:07.248 : <epoch:831, iter: 235,200, lr:2.000e-04> G_loss: 7.228e-02 
22-01-12 09:30:33.337 : <epoch:831, iter: 235,400, lr:2.000e-04> G_loss: 1.251e-02 
22-01-12 09:31:00.118 : <epoch:832, iter: 235,600, lr:2.000e-04> G_loss: 1.408e-02 
22-01-12 09:31:26.739 : <epoch:833, iter: 235,800, lr:2.000e-04> G_loss: 1.534e-02 
22-01-12 09:31:52.782 : <epoch:833, iter: 236,000, lr:2.000e-04> G_loss: 2.763e-02 
22-01-12 09:32:19.453 : <epoch:834, iter: 236,200, lr:2.000e-04> G_loss: 2.311e-02 
22-01-12 09:32:46.089 : <epoch:835, iter: 236,400, lr:2.000e-04> G_loss: 2.664e-02 
22-01-12 09:33:12.745 : <epoch:836, iter: 236,600, lr:2.000e-04> G_loss: 6.754e-02 
22-01-12 09:33:38.837 : <epoch:836, iter: 236,800, lr:2.000e-04> G_loss: 3.301e-02 
22-01-12 09:34:05.629 : <epoch:837, iter: 237,000, lr:2.000e-04> G_loss: 9.530e-03 
22-01-12 09:34:32.332 : <epoch:838, iter: 237,200, lr:2.000e-04> G_loss: 1.142e-02 
22-01-12 09:34:58.388 : <epoch:838, iter: 237,400, lr:2.000e-04> G_loss: 2.375e-02 
22-01-12 09:35:25.075 : <epoch:839, iter: 237,600, lr:2.000e-04> G_loss: 5.569e-02 
22-01-12 09:35:51.725 : <epoch:840, iter: 237,800, lr:2.000e-04> G_loss: 1.475e-02 
22-01-12 09:36:17.795 : <epoch:840, iter: 238,000, lr:2.000e-04> G_loss: 1.533e-02 
22-01-12 09:36:44.506 : <epoch:841, iter: 238,200, lr:2.000e-04> G_loss: 2.498e-02 
22-01-12 09:37:11.157 : <epoch:842, iter: 238,400, lr:2.000e-04> G_loss: 2.968e-02 
22-01-12 09:37:37.803 : <epoch:843, iter: 238,600, lr:2.000e-04> G_loss: 3.246e-02 
22-01-12 09:38:03.918 : <epoch:843, iter: 238,800, lr:2.000e-04> G_loss: 2.573e-02 
22-01-12 09:38:30.564 : <epoch:844, iter: 239,000, lr:2.000e-04> G_loss: 2.752e-02 
22-01-12 09:38:57.273 : <epoch:845, iter: 239,200, lr:2.000e-04> G_loss: 1.395e-02 
22-01-12 09:39:23.356 : <epoch:845, iter: 239,400, lr:2.000e-04> G_loss: 1.318e-02 
22-01-12 09:39:50.011 : <epoch:846, iter: 239,600, lr:2.000e-04> G_loss: 6.035e-02 
22-01-12 09:40:16.738 : <epoch:847, iter: 239,800, lr:2.000e-04> G_loss: 3.663e-02 
22-01-12 09:40:43.343 : <epoch:848, iter: 240,000, lr:2.000e-04> G_loss: 1.201e-02 
22-01-12 09:40:43.343 : Saving the model.
22-01-12 09:40:43.996 : ---1-->  12003.png | 28.70dB
22-01-12 09:40:44.309 : ---2-->  12074.png | 31.03dB
22-01-12 09:40:44.635 : ---3-->  15004.png | 24.75dB
22-01-12 09:40:44.951 : ---4-->  15088.png | 25.36dB
22-01-12 09:40:45.261 : ---5-->  16052.png | 33.46dB
22-01-12 09:40:45.538 : ---6-->   2092.png | 29.22dB
22-01-12 09:40:45.837 : ---7-->   8049.png | 27.82dB
22-01-12 09:40:46.125 : ---8-->   8143.png | 20.38dB
22-01-12 09:40:46.157 : <epoch:848, iter: 240,000, Average PSNR : 27.59dB

22-01-12 09:41:12.178 : <epoch:848, iter: 240,200, lr:2.000e-04> G_loss: 1.930e-02 
22-01-12 09:41:38.803 : <epoch:849, iter: 240,400, lr:2.000e-04> G_loss: 3.857e-02 
22-01-12 09:42:05.390 : <epoch:850, iter: 240,600, lr:2.000e-04> G_loss: 5.072e-02 
22-01-12 09:42:31.509 : <epoch:850, iter: 240,800, lr:2.000e-04> G_loss: 5.319e-03 
22-01-12 09:42:58.165 : <epoch:851, iter: 241,000, lr:2.000e-04> G_loss: 1.713e-02 
22-01-12 09:43:24.703 : <epoch:852, iter: 241,200, lr:2.000e-04> G_loss: 3.374e-02 
22-01-12 09:43:51.346 : <epoch:853, iter: 241,400, lr:2.000e-04> G_loss: 1.985e-02 
22-01-12 09:44:17.390 : <epoch:853, iter: 241,600, lr:2.000e-04> G_loss: 4.901e-02 
22-01-12 09:44:44.036 : <epoch:854, iter: 241,800, lr:2.000e-04> G_loss: 2.469e-02 
22-01-12 09:45:10.784 : <epoch:855, iter: 242,000, lr:2.000e-04> G_loss: 1.692e-02 
22-01-12 09:45:36.926 : <epoch:855, iter: 242,200, lr:2.000e-04> G_loss: 1.457e-02 
22-01-12 09:46:03.578 : <epoch:856, iter: 242,400, lr:2.000e-04> G_loss: 4.285e-02 
22-01-12 09:46:30.214 : <epoch:857, iter: 242,600, lr:2.000e-04> G_loss: 2.510e-02 
22-01-12 09:46:56.306 : <epoch:857, iter: 242,800, lr:2.000e-04> G_loss: 3.895e-02 
22-01-12 09:47:22.951 : <epoch:858, iter: 243,000, lr:2.000e-04> G_loss: 5.940e-02 
22-01-12 09:47:49.577 : <epoch:859, iter: 243,200, lr:2.000e-04> G_loss: 5.684e-03 
22-01-12 09:48:16.182 : <epoch:860, iter: 243,400, lr:2.000e-04> G_loss: 1.587e-02 
22-01-12 09:48:42.181 : <epoch:860, iter: 243,600, lr:2.000e-04> G_loss: 2.838e-02 
22-01-12 09:49:09.128 : <epoch:861, iter: 243,800, lr:2.000e-04> G_loss: 1.679e-02 
22-01-12 09:49:35.879 : <epoch:862, iter: 244,000, lr:2.000e-04> G_loss: 2.288e-02 
22-01-12 09:50:01.977 : <epoch:862, iter: 244,200, lr:2.000e-04> G_loss: 6.238e-03 
22-01-12 09:50:28.751 : <epoch:863, iter: 244,400, lr:2.000e-04> G_loss: 1.280e-02 
22-01-12 09:50:55.288 : <epoch:864, iter: 244,600, lr:2.000e-04> G_loss: 6.554e-03 
22-01-12 09:51:21.926 : <epoch:865, iter: 244,800, lr:2.000e-04> G_loss: 1.316e-02 
22-01-12 09:51:47.964 : <epoch:865, iter: 245,000, lr:2.000e-04> G_loss: 5.872e-02 
22-01-12 09:51:47.964 : Saving the model.
22-01-12 09:51:48.647 : ---1-->  12003.png | 28.84dB
22-01-12 09:51:48.933 : ---2-->  12074.png | 31.26dB
22-01-12 09:51:49.244 : ---3-->  15004.png | 24.79dB
22-01-12 09:51:49.540 : ---4-->  15088.png | 25.26dB
22-01-12 09:51:49.826 : ---5-->  16052.png | 33.59dB
22-01-12 09:51:50.127 : ---6-->   2092.png | 29.26dB
22-01-12 09:51:50.389 : ---7-->   8049.png | 27.93dB
22-01-12 09:51:50.713 : ---8-->   8143.png | 20.42dB
22-01-12 09:51:50.745 : <epoch:865, iter: 245,000, Average PSNR : 27.67dB

22-01-12 09:52:17.489 : <epoch:866, iter: 245,200, lr:2.000e-04> G_loss: 2.199e-02 
22-01-12 09:52:44.092 : <epoch:867, iter: 245,400, lr:2.000e-04> G_loss: 1.277e-02 
22-01-12 09:53:10.196 : <epoch:867, iter: 245,600, lr:2.000e-04> G_loss: 3.489e-02 
22-01-12 09:53:36.818 : <epoch:868, iter: 245,800, lr:2.000e-04> G_loss: 2.406e-02 
22-01-12 09:54:03.485 : <epoch:869, iter: 246,000, lr:2.000e-04> G_loss: 1.592e-02 
22-01-12 09:54:29.567 : <epoch:869, iter: 246,200, lr:2.000e-04> G_loss: 8.624e-03 
22-01-12 09:54:56.204 : <epoch:870, iter: 246,400, lr:2.000e-04> G_loss: 2.695e-02 
22-01-12 09:55:22.955 : <epoch:871, iter: 246,600, lr:2.000e-04> G_loss: 1.593e-02 
22-01-12 09:55:49.573 : <epoch:872, iter: 246,800, lr:2.000e-04> G_loss: 3.619e-02 
22-01-12 09:56:15.667 : <epoch:872, iter: 247,000, lr:2.000e-04> G_loss: 5.729e-02 
22-01-12 09:56:42.503 : <epoch:873, iter: 247,200, lr:2.000e-04> G_loss: 3.363e-02 
22-01-12 09:57:09.180 : <epoch:874, iter: 247,400, lr:2.000e-04> G_loss: 3.993e-02 
22-01-12 09:57:35.233 : <epoch:874, iter: 247,600, lr:2.000e-04> G_loss: 2.292e-02 
22-01-12 09:58:01.993 : <epoch:875, iter: 247,800, lr:2.000e-04> G_loss: 5.240e-02 
22-01-12 09:58:28.638 : <epoch:876, iter: 248,000, lr:2.000e-04> G_loss: 2.185e-02 
22-01-12 09:58:55.241 : <epoch:877, iter: 248,200, lr:2.000e-04> G_loss: 1.543e-02 
22-01-12 09:59:21.303 : <epoch:877, iter: 248,400, lr:2.000e-04> G_loss: 5.717e-02 
22-01-12 09:59:47.979 : <epoch:878, iter: 248,600, lr:2.000e-04> G_loss: 5.083e-02 
22-01-12 10:00:14.603 : <epoch:879, iter: 248,800, lr:2.000e-04> G_loss: 6.976e-02 
22-01-12 10:00:40.640 : <epoch:879, iter: 249,000, lr:2.000e-04> G_loss: 1.832e-02 
22-01-12 10:01:07.302 : <epoch:880, iter: 249,200, lr:2.000e-04> G_loss: 1.987e-02 
22-01-12 10:01:33.911 : <epoch:881, iter: 249,400, lr:2.000e-04> G_loss: 2.878e-02 
22-01-12 10:01:59.974 : <epoch:881, iter: 249,600, lr:2.000e-04> G_loss: 7.287e-02 
22-01-12 10:02:26.628 : <epoch:882, iter: 249,800, lr:2.000e-04> G_loss: 5.297e-02 
22-01-12 10:02:53.257 : <epoch:883, iter: 250,000, lr:5.000e-05> G_loss: 1.503e-02 
22-01-12 10:02:53.257 : Saving the model.
22-01-12 10:02:53.908 : ---1-->  12003.png | 28.91dB
22-01-12 10:02:54.211 : ---2-->  12074.png | 31.30dB
22-01-12 10:02:54.554 : ---3-->  15004.png | 24.81dB
22-01-12 10:02:54.864 : ---4-->  15088.png | 25.37dB
22-01-12 10:02:55.180 : ---5-->  16052.png | 33.70dB
22-01-12 10:02:55.488 : ---6-->   2092.png | 29.30dB
22-01-12 10:02:55.765 : ---7-->   8049.png | 27.91dB
22-01-12 10:02:56.039 : ---8-->   8143.png | 20.46dB
22-01-12 10:02:56.071 : <epoch:883, iter: 250,000, Average PSNR : 27.72dB

22-01-12 10:03:22.582 : <epoch:884, iter: 250,200, lr:1.000e-04> G_loss: 1.202e-02 
22-01-12 10:03:48.807 : <epoch:884, iter: 250,400, lr:1.000e-04> G_loss: 2.718e-02 
22-01-12 10:04:15.597 : <epoch:885, iter: 250,600, lr:1.000e-04> G_loss: 1.142e-02 
22-01-12 10:04:42.245 : <epoch:886, iter: 250,800, lr:1.000e-04> G_loss: 1.616e-02 
22-01-12 10:05:08.298 : <epoch:886, iter: 251,000, lr:1.000e-04> G_loss: 2.849e-02 
22-01-12 10:05:34.993 : <epoch:887, iter: 251,200, lr:1.000e-04> G_loss: 2.003e-02 
22-01-12 10:06:01.677 : <epoch:888, iter: 251,400, lr:1.000e-04> G_loss: 2.957e-02 
22-01-12 10:06:28.324 : <epoch:889, iter: 251,600, lr:1.000e-04> G_loss: 2.534e-02 
22-01-12 10:06:54.427 : <epoch:889, iter: 251,800, lr:1.000e-04> G_loss: 2.908e-03 
22-01-12 10:07:21.058 : <epoch:890, iter: 252,000, lr:1.000e-04> G_loss: 4.678e-02 
22-01-12 10:07:47.733 : <epoch:891, iter: 252,200, lr:1.000e-04> G_loss: 5.381e-02 
22-01-12 10:08:13.909 : <epoch:891, iter: 252,400, lr:1.000e-04> G_loss: 2.127e-02 
22-01-12 10:08:40.546 : <epoch:892, iter: 252,600, lr:1.000e-04> G_loss: 2.828e-02 
22-01-12 10:09:07.203 : <epoch:893, iter: 252,800, lr:1.000e-04> G_loss: 3.659e-02 
22-01-12 10:09:33.250 : <epoch:893, iter: 253,000, lr:1.000e-04> G_loss: 2.929e-02 
22-01-12 10:09:59.884 : <epoch:894, iter: 253,200, lr:1.000e-04> G_loss: 7.589e-02 
22-01-12 10:10:26.544 : <epoch:895, iter: 253,400, lr:1.000e-04> G_loss: 2.114e-02 
22-01-12 10:10:53.224 : <epoch:896, iter: 253,600, lr:1.000e-04> G_loss: 1.244e-02 
22-01-12 10:11:19.296 : <epoch:896, iter: 253,800, lr:1.000e-04> G_loss: 6.591e-02 
22-01-12 10:11:45.916 : <epoch:897, iter: 254,000, lr:1.000e-04> G_loss: 1.464e-02 
22-01-12 10:12:12.624 : <epoch:898, iter: 254,200, lr:1.000e-04> G_loss: 1.264e-02 
22-01-12 10:12:38.660 : <epoch:898, iter: 254,400, lr:1.000e-04> G_loss: 2.286e-02 
22-01-12 10:13:05.341 : <epoch:899, iter: 254,600, lr:1.000e-04> G_loss: 1.939e-02 
22-01-12 10:13:32.008 : <epoch:900, iter: 254,800, lr:1.000e-04> G_loss: 3.056e-02 
22-01-12 10:13:58.708 : <epoch:901, iter: 255,000, lr:1.000e-04> G_loss: 1.245e-02 
22-01-12 10:13:58.708 : Saving the model.
22-01-12 10:13:59.360 : ---1-->  12003.png | 28.90dB
22-01-12 10:13:59.677 : ---2-->  12074.png | 31.45dB
22-01-12 10:13:59.977 : ---3-->  15004.png | 24.86dB
22-01-12 10:14:00.280 : ---4-->  15088.png | 25.40dB
22-01-12 10:14:00.561 : ---5-->  16052.png | 33.78dB
22-01-12 10:14:00.861 : ---6-->   2092.png | 29.36dB
22-01-12 10:14:01.173 : ---7-->   8049.png | 28.00dB
22-01-12 10:14:01.468 : ---8-->   8143.png | 20.42dB
22-01-12 10:14:01.500 : <epoch:901, iter: 255,000, Average PSNR : 27.77dB

22-01-12 10:14:27.550 : <epoch:901, iter: 255,200, lr:1.000e-04> G_loss: 1.862e-02 
22-01-12 10:14:54.124 : <epoch:902, iter: 255,400, lr:1.000e-04> G_loss: 9.416e-03 
22-01-12 10:15:20.825 : <epoch:903, iter: 255,600, lr:1.000e-04> G_loss: 1.163e-02 
22-01-12 10:15:46.910 : <epoch:903, iter: 255,800, lr:1.000e-04> G_loss: 2.966e-02 
22-01-12 10:16:13.678 : <epoch:904, iter: 256,000, lr:1.000e-04> G_loss: 2.670e-02 
22-01-12 10:16:40.321 : <epoch:905, iter: 256,200, lr:1.000e-04> G_loss: 4.822e-02 
22-01-12 10:17:06.994 : <epoch:906, iter: 256,400, lr:1.000e-04> G_loss: 3.753e-02 
22-01-12 10:17:33.037 : <epoch:906, iter: 256,600, lr:1.000e-04> G_loss: 2.247e-02 
22-01-12 10:17:59.820 : <epoch:907, iter: 256,800, lr:1.000e-04> G_loss: 2.624e-02 
22-01-12 10:18:26.502 : <epoch:908, iter: 257,000, lr:1.000e-04> G_loss: 4.117e-02 
22-01-12 10:18:52.629 : <epoch:908, iter: 257,200, lr:1.000e-04> G_loss: 1.260e-02 
22-01-12 10:19:19.273 : <epoch:909, iter: 257,400, lr:1.000e-04> G_loss: 2.716e-02 
22-01-12 10:19:45.993 : <epoch:910, iter: 257,600, lr:1.000e-04> G_loss: 5.269e-02 
22-01-12 10:20:12.039 : <epoch:910, iter: 257,800, lr:1.000e-04> G_loss: 4.938e-02 
22-01-12 10:20:38.794 : <epoch:911, iter: 258,000, lr:1.000e-04> G_loss: 2.998e-02 
22-01-12 10:21:05.472 : <epoch:912, iter: 258,200, lr:1.000e-04> G_loss: 1.463e-02 
22-01-12 10:21:32.144 : <epoch:913, iter: 258,400, lr:1.000e-04> G_loss: 1.846e-02 
22-01-12 10:21:58.201 : <epoch:913, iter: 258,600, lr:1.000e-04> G_loss: 3.274e-02 
22-01-12 10:22:24.940 : <epoch:914, iter: 258,800, lr:1.000e-04> G_loss: 2.345e-02 
22-01-12 10:22:51.602 : <epoch:915, iter: 259,000, lr:1.000e-04> G_loss: 9.013e-03 
22-01-12 10:23:17.672 : <epoch:915, iter: 259,200, lr:1.000e-04> G_loss: 4.187e-02 
22-01-12 10:23:44.431 : <epoch:916, iter: 259,400, lr:1.000e-04> G_loss: 3.556e-02 
22-01-12 10:24:11.190 : <epoch:917, iter: 259,600, lr:1.000e-04> G_loss: 8.747e-03 
22-01-12 10:24:37.803 : <epoch:918, iter: 259,800, lr:1.000e-04> G_loss: 2.054e-02 
22-01-12 10:25:04.016 : <epoch:918, iter: 260,000, lr:1.000e-04> G_loss: 1.360e-02 
22-01-12 10:25:04.016 : Saving the model.
22-01-12 10:25:04.668 : ---1-->  12003.png | 28.96dB
22-01-12 10:25:04.980 : ---2-->  12074.png | 31.45dB
22-01-12 10:25:05.282 : ---3-->  15004.png | 24.86dB
22-01-12 10:25:05.584 : ---4-->  15088.png | 25.40dB
22-01-12 10:25:05.886 : ---5-->  16052.png | 33.79dB
22-01-12 10:25:06.181 : ---6-->   2092.png | 29.35dB
22-01-12 10:25:06.472 : ---7-->   8049.png | 28.02dB
22-01-12 10:25:06.759 : ---8-->   8143.png | 20.45dB
22-01-12 10:25:06.791 : <epoch:918, iter: 260,000, Average PSNR : 27.79dB

22-01-12 10:25:33.575 : <epoch:919, iter: 260,200, lr:1.000e-04> G_loss: 4.348e-02 
22-01-12 10:26:00.184 : <epoch:920, iter: 260,400, lr:1.000e-04> G_loss: 1.621e-02 
22-01-12 10:26:26.283 : <epoch:920, iter: 260,600, lr:1.000e-04> G_loss: 1.252e-02 
22-01-12 10:26:52.940 : <epoch:921, iter: 260,800, lr:1.000e-04> G_loss: 3.261e-02 
22-01-12 10:27:19.620 : <epoch:922, iter: 261,000, lr:1.000e-04> G_loss: 4.442e-02 
22-01-12 10:27:45.641 : <epoch:922, iter: 261,200, lr:1.000e-04> G_loss: 1.440e-02 
22-01-12 10:28:12.408 : <epoch:923, iter: 261,400, lr:1.000e-04> G_loss: 8.654e-03 
22-01-12 10:28:39.090 : <epoch:924, iter: 261,600, lr:1.000e-04> G_loss: 7.011e-02 
22-01-12 10:29:05.752 : <epoch:925, iter: 261,800, lr:1.000e-04> G_loss: 1.964e-02 
22-01-12 10:29:31.968 : <epoch:925, iter: 262,000, lr:1.000e-04> G_loss: 1.247e-02 
22-01-12 10:29:58.541 : <epoch:926, iter: 262,200, lr:1.000e-04> G_loss: 3.592e-02 
22-01-12 10:30:25.181 : <epoch:927, iter: 262,400, lr:1.000e-04> G_loss: 9.548e-03 
22-01-12 10:30:51.258 : <epoch:927, iter: 262,600, lr:1.000e-04> G_loss: 3.426e-02 
22-01-12 10:31:17.943 : <epoch:928, iter: 262,800, lr:1.000e-04> G_loss: 2.471e-02 
22-01-12 10:31:44.535 : <epoch:929, iter: 263,000, lr:1.000e-04> G_loss: 8.811e-03 
22-01-12 10:32:11.211 : <epoch:930, iter: 263,200, lr:1.000e-04> G_loss: 2.685e-02 
22-01-12 10:32:37.311 : <epoch:930, iter: 263,400, lr:1.000e-04> G_loss: 7.587e-03 
22-01-12 10:33:03.905 : <epoch:931, iter: 263,600, lr:1.000e-04> G_loss: 8.391e-03 
22-01-12 10:33:30.608 : <epoch:932, iter: 263,800, lr:1.000e-04> G_loss: 1.550e-02 
22-01-12 10:33:56.712 : <epoch:932, iter: 264,000, lr:1.000e-04> G_loss: 2.100e-02 
22-01-12 10:34:23.276 : <epoch:933, iter: 264,200, lr:1.000e-04> G_loss: 1.745e-02 
22-01-12 10:34:49.863 : <epoch:934, iter: 264,400, lr:1.000e-04> G_loss: 1.987e-02 
22-01-12 10:35:15.917 : <epoch:934, iter: 264,600, lr:1.000e-04> G_loss: 1.039e-02 
22-01-12 10:35:42.595 : <epoch:935, iter: 264,800, lr:1.000e-04> G_loss: 1.884e-02 
22-01-12 10:36:09.231 : <epoch:936, iter: 265,000, lr:1.000e-04> G_loss: 8.493e-03 
22-01-12 10:36:09.231 : Saving the model.
22-01-12 10:36:09.890 : ---1-->  12003.png | 28.92dB
22-01-12 10:36:10.211 : ---2-->  12074.png | 31.46dB
22-01-12 10:36:10.524 : ---3-->  15004.png | 24.86dB
22-01-12 10:36:10.874 : ---4-->  15088.png | 25.44dB
22-01-12 10:36:11.165 : ---5-->  16052.png | 33.83dB
22-01-12 10:36:11.482 : ---6-->   2092.png | 29.38dB
22-01-12 10:36:11.770 : ---7-->   8049.png | 27.98dB
22-01-12 10:36:12.061 : ---8-->   8143.png | 20.42dB
22-01-12 10:36:12.093 : <epoch:936, iter: 265,000, Average PSNR : 27.79dB

22-01-12 10:36:38.750 : <epoch:937, iter: 265,200, lr:1.000e-04> G_loss: 1.369e-02 
22-01-12 10:37:04.866 : <epoch:937, iter: 265,400, lr:1.000e-04> G_loss: 4.773e-02 
22-01-12 10:37:31.492 : <epoch:938, iter: 265,600, lr:1.000e-04> G_loss: 2.016e-02 
22-01-12 10:37:58.123 : <epoch:939, iter: 265,800, lr:1.000e-04> G_loss: 3.909e-02 
22-01-12 10:38:24.187 : <epoch:939, iter: 266,000, lr:1.000e-04> G_loss: 9.721e-03 
22-01-12 10:38:50.867 : <epoch:940, iter: 266,200, lr:1.000e-04> G_loss: 1.090e-02 
22-01-12 10:39:17.453 : <epoch:941, iter: 266,400, lr:1.000e-04> G_loss: 3.545e-02 
22-01-12 10:39:44.099 : <epoch:942, iter: 266,600, lr:1.000e-04> G_loss: 2.259e-02 
22-01-12 10:40:10.208 : <epoch:942, iter: 266,800, lr:1.000e-04> G_loss: 1.969e-02 
22-01-12 10:40:36.863 : <epoch:943, iter: 267,000, lr:1.000e-04> G_loss: 1.936e-02 
22-01-12 10:41:03.458 : <epoch:944, iter: 267,200, lr:1.000e-04> G_loss: 2.377e-02 
22-01-12 10:41:29.587 : <epoch:944, iter: 267,400, lr:1.000e-04> G_loss: 2.099e-02 
22-01-12 10:41:56.240 : <epoch:945, iter: 267,600, lr:1.000e-04> G_loss: 2.753e-02 
22-01-12 10:42:22.939 : <epoch:946, iter: 267,800, lr:1.000e-04> G_loss: 1.598e-02 
22-01-12 10:42:48.943 : <epoch:946, iter: 268,000, lr:1.000e-04> G_loss: 8.115e-03 
22-01-12 10:43:15.755 : <epoch:947, iter: 268,200, lr:1.000e-04> G_loss: 8.635e-03 
22-01-12 10:43:42.338 : <epoch:948, iter: 268,400, lr:1.000e-04> G_loss: 1.771e-02 
22-01-12 10:44:09.068 : <epoch:949, iter: 268,600, lr:1.000e-04> G_loss: 1.726e-02 
22-01-12 10:44:35.175 : <epoch:949, iter: 268,800, lr:1.000e-04> G_loss: 1.262e-02 
22-01-12 10:45:01.830 : <epoch:950, iter: 269,000, lr:1.000e-04> G_loss: 7.249e-03 
22-01-12 10:45:28.552 : <epoch:951, iter: 269,200, lr:1.000e-04> G_loss: 1.582e-02 
22-01-12 10:45:54.602 : <epoch:951, iter: 269,400, lr:1.000e-04> G_loss: 6.463e-03 
22-01-12 10:46:21.290 : <epoch:952, iter: 269,600, lr:1.000e-04> G_loss: 4.200e-02 
22-01-12 10:46:47.938 : <epoch:953, iter: 269,800, lr:1.000e-04> G_loss: 3.898e-02 
22-01-12 10:47:14.585 : <epoch:954, iter: 270,000, lr:1.000e-04> G_loss: 1.505e-02 
22-01-12 10:47:14.585 : Saving the model.
22-01-12 10:47:15.237 : ---1-->  12003.png | 28.91dB
22-01-12 10:47:15.556 : ---2-->  12074.png | 31.47dB
22-01-12 10:47:15.843 : ---3-->  15004.png | 24.87dB
22-01-12 10:47:16.127 : ---4-->  15088.png | 25.42dB
22-01-12 10:47:16.440 : ---5-->  16052.png | 33.82dB
22-01-12 10:47:16.762 : ---6-->   2092.png | 29.36dB
22-01-12 10:47:17.083 : ---7-->   8049.png | 28.02dB
22-01-12 10:47:17.368 : ---8-->   8143.png | 20.45dB
22-01-12 10:47:17.400 : <epoch:954, iter: 270,000, Average PSNR : 27.79dB

22-01-12 10:47:43.481 : <epoch:954, iter: 270,200, lr:1.000e-04> G_loss: 1.458e-02 
22-01-12 10:48:10.201 : <epoch:955, iter: 270,400, lr:1.000e-04> G_loss: 5.010e-02 
22-01-12 10:48:36.855 : <epoch:956, iter: 270,600, lr:1.000e-04> G_loss: 7.500e-02 
22-01-12 10:49:02.875 : <epoch:956, iter: 270,800, lr:1.000e-04> G_loss: 2.542e-02 
22-01-12 10:49:29.715 : <epoch:957, iter: 271,000, lr:1.000e-04> G_loss: 1.260e-02 
22-01-12 10:49:56.355 : <epoch:958, iter: 271,200, lr:1.000e-04> G_loss: 1.838e-02 
22-01-12 10:50:23.015 : <epoch:959, iter: 271,400, lr:1.000e-04> G_loss: 3.377e-02 
22-01-12 10:50:49.094 : <epoch:959, iter: 271,600, lr:1.000e-04> G_loss: 2.273e-02 
22-01-12 10:51:15.737 : <epoch:960, iter: 271,800, lr:1.000e-04> G_loss: 3.524e-02 
22-01-12 10:51:42.350 : <epoch:961, iter: 272,000, lr:1.000e-04> G_loss: 1.489e-02 
22-01-12 10:52:08.444 : <epoch:961, iter: 272,200, lr:1.000e-04> G_loss: 4.074e-02 
22-01-12 10:52:35.124 : <epoch:962, iter: 272,400, lr:1.000e-04> G_loss: 1.345e-02 
22-01-12 10:53:01.771 : <epoch:963, iter: 272,600, lr:1.000e-04> G_loss: 3.023e-02 
22-01-12 10:53:27.909 : <epoch:963, iter: 272,800, lr:1.000e-04> G_loss: 1.191e-02 
22-01-12 10:53:54.525 : <epoch:964, iter: 273,000, lr:1.000e-04> G_loss: 3.250e-02 
22-01-12 10:54:21.160 : <epoch:965, iter: 273,200, lr:1.000e-04> G_loss: 8.444e-03 
22-01-12 10:54:47.855 : <epoch:966, iter: 273,400, lr:1.000e-04> G_loss: 1.950e-02 
22-01-12 10:55:14.034 : <epoch:966, iter: 273,600, lr:1.000e-04> G_loss: 1.534e-02 
22-01-12 10:55:40.712 : <epoch:967, iter: 273,800, lr:1.000e-04> G_loss: 1.267e-02 
22-01-12 10:56:07.341 : <epoch:968, iter: 274,000, lr:1.000e-04> G_loss: 1.608e-02 
22-01-12 10:56:33.517 : <epoch:968, iter: 274,200, lr:1.000e-04> G_loss: 2.998e-02 
22-01-12 10:57:00.186 : <epoch:969, iter: 274,400, lr:1.000e-04> G_loss: 9.597e-03 
22-01-12 10:57:26.923 : <epoch:970, iter: 274,600, lr:1.000e-04> G_loss: 3.214e-02 
22-01-12 10:57:53.575 : <epoch:971, iter: 274,800, lr:1.000e-04> G_loss: 1.985e-02 
22-01-12 10:58:19.777 : <epoch:971, iter: 275,000, lr:1.000e-04> G_loss: 2.450e-02 
22-01-12 10:58:19.778 : Saving the model.
22-01-12 10:58:20.431 : ---1-->  12003.png | 29.00dB
22-01-12 10:58:20.722 : ---2-->  12074.png | 31.44dB
22-01-12 10:58:21.017 : ---3-->  15004.png | 24.88dB
22-01-12 10:58:21.325 : ---4-->  15088.png | 25.49dB
22-01-12 10:58:21.620 : ---5-->  16052.png | 33.87dB
22-01-12 10:58:21.940 : ---6-->   2092.png | 29.34dB
22-01-12 10:58:22.214 : ---7-->   8049.png | 28.04dB
22-01-12 10:58:22.515 : ---8-->   8143.png | 20.44dB
22-01-12 10:58:22.546 : <epoch:971, iter: 275,000, Average PSNR : 27.81dB

22-01-12 10:58:49.224 : <epoch:972, iter: 275,200, lr:1.000e-04> G_loss: 1.355e-02 
22-01-12 10:59:15.953 : <epoch:973, iter: 275,400, lr:1.000e-04> G_loss: 1.934e-02 
22-01-12 10:59:42.027 : <epoch:973, iter: 275,600, lr:1.000e-04> G_loss: 1.591e-02 
22-01-12 11:00:08.702 : <epoch:974, iter: 275,800, lr:1.000e-04> G_loss: 4.102e-02 
22-01-12 11:00:35.318 : <epoch:975, iter: 276,000, lr:1.000e-04> G_loss: 1.992e-02 
22-01-12 11:01:01.384 : <epoch:975, iter: 276,200, lr:1.000e-04> G_loss: 9.329e-03 
22-01-12 11:01:28.122 : <epoch:976, iter: 276,400, lr:1.000e-04> G_loss: 2.542e-02 
22-01-12 11:01:54.738 : <epoch:977, iter: 276,600, lr:1.000e-04> G_loss: 2.678e-02 
22-01-12 11:02:21.518 : <epoch:978, iter: 276,800, lr:1.000e-04> G_loss: 1.333e-02 
22-01-12 11:02:47.541 : <epoch:978, iter: 277,000, lr:1.000e-04> G_loss: 1.973e-02 
22-01-12 11:03:14.223 : <epoch:979, iter: 277,200, lr:1.000e-04> G_loss: 4.238e-02 
22-01-12 11:03:40.992 : <epoch:980, iter: 277,400, lr:1.000e-04> G_loss: 1.606e-02 
22-01-12 11:04:07.097 : <epoch:980, iter: 277,600, lr:1.000e-04> G_loss: 3.849e-02 
22-01-12 11:04:33.779 : <epoch:981, iter: 277,800, lr:1.000e-04> G_loss: 3.376e-02 
22-01-12 11:05:00.515 : <epoch:982, iter: 278,000, lr:1.000e-04> G_loss: 1.399e-02 
22-01-12 11:05:27.200 : <epoch:983, iter: 278,200, lr:1.000e-04> G_loss: 1.671e-02 
22-01-12 11:05:53.235 : <epoch:983, iter: 278,400, lr:1.000e-04> G_loss: 2.648e-02 
22-01-12 11:06:19.915 : <epoch:984, iter: 278,600, lr:1.000e-04> G_loss: 2.855e-02 
22-01-12 11:06:46.553 : <epoch:985, iter: 278,800, lr:1.000e-04> G_loss: 2.025e-02 
22-01-12 11:07:12.653 : <epoch:985, iter: 279,000, lr:1.000e-04> G_loss: 2.764e-02 
22-01-12 11:07:39.365 : <epoch:986, iter: 279,200, lr:1.000e-04> G_loss: 1.114e-02 
22-01-12 11:08:05.977 : <epoch:987, iter: 279,400, lr:1.000e-04> G_loss: 1.234e-02 
22-01-12 11:08:32.022 : <epoch:987, iter: 279,600, lr:1.000e-04> G_loss: 2.712e-02 
22-01-12 11:08:58.701 : <epoch:988, iter: 279,800, lr:1.000e-04> G_loss: 3.246e-02 
22-01-12 11:09:25.565 : <epoch:989, iter: 280,000, lr:1.000e-04> G_loss: 1.249e-02 
22-01-12 11:09:25.566 : Saving the model.
22-01-12 11:09:26.235 : ---1-->  12003.png | 28.92dB
22-01-12 11:09:26.536 : ---2-->  12074.png | 31.47dB
22-01-12 11:09:26.841 : ---3-->  15004.png | 24.90dB
22-01-12 11:09:27.143 : ---4-->  15088.png | 25.47dB
22-01-12 11:09:27.451 : ---5-->  16052.png | 33.91dB
22-01-12 11:09:27.763 : ---6-->   2092.png | 29.37dB
22-01-12 11:09:28.052 : ---7-->   8049.png | 28.05dB
22-01-12 11:09:28.334 : ---8-->   8143.png | 20.45dB
22-01-12 11:09:28.365 : <epoch:989, iter: 280,000, Average PSNR : 27.82dB

22-01-12 11:09:55.141 : <epoch:990, iter: 280,200, lr:1.000e-04> G_loss: 2.040e-02 
22-01-12 11:10:21.196 : <epoch:990, iter: 280,400, lr:1.000e-04> G_loss: 4.036e-02 
22-01-12 11:10:47.874 : <epoch:991, iter: 280,600, lr:1.000e-04> G_loss: 2.787e-02 
22-01-12 11:11:14.597 : <epoch:992, iter: 280,800, lr:1.000e-04> G_loss: 3.531e-03 
22-01-12 11:11:40.641 : <epoch:992, iter: 281,000, lr:1.000e-04> G_loss: 3.834e-02 
22-01-12 11:12:07.282 : <epoch:993, iter: 281,200, lr:1.000e-04> G_loss: 4.331e-02 
22-01-12 11:12:33.941 : <epoch:994, iter: 281,400, lr:1.000e-04> G_loss: 2.868e-02 
22-01-12 11:13:00.588 : <epoch:995, iter: 281,600, lr:1.000e-04> G_loss: 1.266e-02 
22-01-12 11:13:26.761 : <epoch:995, iter: 281,800, lr:1.000e-04> G_loss: 3.704e-02 
22-01-12 11:13:53.568 : <epoch:996, iter: 282,000, lr:1.000e-04> G_loss: 3.701e-02 
22-01-12 11:14:20.199 : <epoch:997, iter: 282,200, lr:1.000e-04> G_loss: 3.324e-02 
22-01-12 11:14:46.334 : <epoch:997, iter: 282,400, lr:1.000e-04> G_loss: 6.656e-02 
22-01-12 11:15:13.043 : <epoch:998, iter: 282,600, lr:1.000e-04> G_loss: 4.517e-02 
22-01-12 11:15:39.879 : <epoch:999, iter: 282,800, lr:1.000e-04> G_loss: 2.198e-02 
22-01-12 11:16:05.954 : <epoch:999, iter: 283,000, lr:1.000e-04> G_loss: 1.244e-02 
22-01-12 11:16:32.748 : <epoch:1000, iter: 283,200, lr:1.000e-04> G_loss: 5.566e-03 
22-01-12 11:16:59.526 : <epoch:1001, iter: 283,400, lr:1.000e-04> G_loss: 5.335e-02 
22-01-12 11:17:26.199 : <epoch:1002, iter: 283,600, lr:1.000e-04> G_loss: 2.201e-02 
22-01-12 11:17:52.269 : <epoch:1002, iter: 283,800, lr:1.000e-04> G_loss: 1.477e-02 
22-01-12 11:18:18.936 : <epoch:1003, iter: 284,000, lr:1.000e-04> G_loss: 2.377e-02 
22-01-12 11:18:45.581 : <epoch:1004, iter: 284,200, lr:1.000e-04> G_loss: 1.642e-02 
22-01-12 11:19:11.668 : <epoch:1004, iter: 284,400, lr:1.000e-04> G_loss: 2.313e-02 
22-01-12 11:19:38.335 : <epoch:1005, iter: 284,600, lr:1.000e-04> G_loss: 1.664e-02 
22-01-12 11:20:04.993 : <epoch:1006, iter: 284,800, lr:1.000e-04> G_loss: 7.786e-03 
22-01-12 11:20:31.719 : <epoch:1007, iter: 285,000, lr:1.000e-04> G_loss: 2.847e-02 
22-01-12 11:20:31.720 : Saving the model.
22-01-12 11:20:32.384 : ---1-->  12003.png | 29.02dB
22-01-12 11:20:32.678 : ---2-->  12074.png | 31.39dB
22-01-12 11:20:32.990 : ---3-->  15004.png | 24.86dB
22-01-12 11:20:33.308 : ---4-->  15088.png | 25.45dB
22-01-12 11:20:33.616 : ---5-->  16052.png | 33.78dB
22-01-12 11:20:33.953 : ---6-->   2092.png | 29.28dB
22-01-12 11:20:34.244 : ---7-->   8049.png | 27.98dB
22-01-12 11:20:34.535 : ---8-->   8143.png | 20.45dB
22-01-12 11:20:34.567 : <epoch:1007, iter: 285,000, Average PSNR : 27.77dB

22-01-12 11:21:00.562 : <epoch:1007, iter: 285,200, lr:1.000e-04> G_loss: 2.401e-02 
22-01-12 11:21:27.216 : <epoch:1008, iter: 285,400, lr:1.000e-04> G_loss: 3.420e-02 
22-01-12 11:21:53.890 : <epoch:1009, iter: 285,600, lr:1.000e-04> G_loss: 4.155e-02 
22-01-12 11:22:19.911 : <epoch:1009, iter: 285,800, lr:1.000e-04> G_loss: 5.491e-02 
22-01-12 11:22:46.541 : <epoch:1010, iter: 286,000, lr:1.000e-04> G_loss: 2.398e-02 
22-01-12 11:23:13.172 : <epoch:1011, iter: 286,200, lr:1.000e-04> G_loss: 9.721e-03 
22-01-12 11:23:39.766 : <epoch:1012, iter: 286,400, lr:1.000e-04> G_loss: 4.683e-02 
22-01-12 11:24:05.830 : <epoch:1012, iter: 286,600, lr:1.000e-04> G_loss: 1.870e-02 
22-01-12 11:24:32.617 : <epoch:1013, iter: 286,800, lr:1.000e-04> G_loss: 1.956e-02 
22-01-12 11:24:59.314 : <epoch:1014, iter: 287,000, lr:1.000e-04> G_loss: 4.696e-02 
22-01-12 11:25:25.373 : <epoch:1014, iter: 287,200, lr:1.000e-04> G_loss: 1.498e-02 
22-01-12 11:25:52.128 : <epoch:1015, iter: 287,400, lr:1.000e-04> G_loss: 1.282e-02 
22-01-12 11:26:18.758 : <epoch:1016, iter: 287,600, lr:1.000e-04> G_loss: 3.779e-02 
22-01-12 11:26:44.771 : <epoch:1016, iter: 287,800, lr:1.000e-04> G_loss: 2.622e-02 
22-01-12 11:27:11.432 : <epoch:1017, iter: 288,000, lr:1.000e-04> G_loss: 9.949e-03 
22-01-12 11:27:38.035 : <epoch:1018, iter: 288,200, lr:1.000e-04> G_loss: 1.561e-02 
22-01-12 11:28:04.662 : <epoch:1019, iter: 288,400, lr:1.000e-04> G_loss: 2.184e-02 
22-01-12 11:28:30.712 : <epoch:1019, iter: 288,600, lr:1.000e-04> G_loss: 1.305e-02 
22-01-12 11:28:57.508 : <epoch:1020, iter: 288,800, lr:1.000e-04> G_loss: 1.044e-02 
22-01-12 11:29:24.260 : <epoch:1021, iter: 289,000, lr:1.000e-04> G_loss: 1.412e-02 
22-01-12 11:29:50.336 : <epoch:1021, iter: 289,200, lr:1.000e-04> G_loss: 2.912e-02 
22-01-12 11:30:17.117 : <epoch:1022, iter: 289,400, lr:1.000e-04> G_loss: 1.515e-02 
22-01-12 11:30:43.883 : <epoch:1023, iter: 289,600, lr:1.000e-04> G_loss: 1.909e-02 
22-01-12 11:31:10.606 : <epoch:1024, iter: 289,800, lr:1.000e-04> G_loss: 2.950e-02 
22-01-12 11:31:36.622 : <epoch:1024, iter: 290,000, lr:1.000e-04> G_loss: 1.289e-02 
22-01-12 11:31:36.622 : Saving the model.
22-01-12 11:31:37.287 : ---1-->  12003.png | 28.99dB
22-01-12 11:31:37.597 : ---2-->  12074.png | 31.46dB
22-01-12 11:31:37.896 : ---3-->  15004.png | 24.86dB
22-01-12 11:31:38.198 : ---4-->  15088.png | 25.42dB
22-01-12 11:31:38.499 : ---5-->  16052.png | 33.80dB
22-01-12 11:31:38.807 : ---6-->   2092.png | 29.33dB
22-01-12 11:31:39.082 : ---7-->   8049.png | 28.02dB
22-01-12 11:31:39.370 : ---8-->   8143.png | 20.46dB
22-01-12 11:31:39.402 : <epoch:1024, iter: 290,000, Average PSNR : 27.79dB

22-01-12 11:32:06.057 : <epoch:1025, iter: 290,200, lr:1.000e-04> G_loss: 1.541e-02 
22-01-12 11:32:32.683 : <epoch:1026, iter: 290,400, lr:1.000e-04> G_loss: 2.452e-02 
22-01-12 11:32:59.029 : <epoch:1026, iter: 290,600, lr:1.000e-04> G_loss: 3.707e-02 
22-01-12 11:33:25.740 : <epoch:1027, iter: 290,800, lr:1.000e-04> G_loss: 5.977e-03 
22-01-12 11:33:52.326 : <epoch:1028, iter: 291,000, lr:1.000e-04> G_loss: 2.005e-02 
22-01-12 11:34:18.428 : <epoch:1028, iter: 291,200, lr:1.000e-04> G_loss: 1.204e-02 
22-01-12 11:34:45.074 : <epoch:1029, iter: 291,400, lr:1.000e-04> G_loss: 5.110e-02 
22-01-12 11:35:11.730 : <epoch:1030, iter: 291,600, lr:1.000e-04> G_loss: 1.122e-02 
22-01-12 11:35:38.370 : <epoch:1031, iter: 291,800, lr:1.000e-04> G_loss: 9.662e-03 
22-01-12 11:36:04.473 : <epoch:1031, iter: 292,000, lr:1.000e-04> G_loss: 2.321e-02 
22-01-12 11:36:31.115 : <epoch:1032, iter: 292,200, lr:1.000e-04> G_loss: 8.492e-03 
22-01-12 11:36:57.824 : <epoch:1033, iter: 292,400, lr:1.000e-04> G_loss: 2.024e-02 
22-01-12 11:37:23.875 : <epoch:1033, iter: 292,600, lr:1.000e-04> G_loss: 9.061e-03 
22-01-12 11:37:50.541 : <epoch:1034, iter: 292,800, lr:1.000e-04> G_loss: 2.148e-02 
22-01-12 11:38:17.133 : <epoch:1035, iter: 293,000, lr:1.000e-04> G_loss: 6.560e-02 
22-01-12 11:38:43.892 : <epoch:1036, iter: 293,200, lr:1.000e-04> G_loss: 8.048e-03 
22-01-12 11:39:10.070 : <epoch:1036, iter: 293,400, lr:1.000e-04> G_loss: 1.615e-02 
22-01-12 11:39:36.701 : <epoch:1037, iter: 293,600, lr:1.000e-04> G_loss: 1.438e-02 
22-01-12 11:40:03.363 : <epoch:1038, iter: 293,800, lr:1.000e-04> G_loss: 4.115e-02 
22-01-12 11:40:29.549 : <epoch:1038, iter: 294,000, lr:1.000e-04> G_loss: 2.565e-02 
22-01-12 11:40:56.234 : <epoch:1039, iter: 294,200, lr:1.000e-04> G_loss: 2.255e-02 
22-01-12 11:41:22.861 : <epoch:1040, iter: 294,400, lr:1.000e-04> G_loss: 9.227e-03 
22-01-12 11:41:48.948 : <epoch:1040, iter: 294,600, lr:1.000e-04> G_loss: 4.005e-02 
22-01-12 11:42:15.654 : <epoch:1041, iter: 294,800, lr:1.000e-04> G_loss: 1.984e-02 
22-01-12 11:42:42.253 : <epoch:1042, iter: 295,000, lr:1.000e-04> G_loss: 2.473e-02 
22-01-12 11:42:42.253 : Saving the model.
22-01-12 11:42:42.925 : ---1-->  12003.png | 28.97dB
22-01-12 11:42:43.242 : ---2-->  12074.png | 31.44dB
22-01-12 11:42:43.554 : ---3-->  15004.png | 24.82dB
22-01-12 11:42:43.844 : ---4-->  15088.png | 25.46dB
22-01-12 11:42:44.151 : ---5-->  16052.png | 33.87dB
22-01-12 11:42:44.416 : ---6-->   2092.png | 29.35dB
22-01-12 11:42:44.704 : ---7-->   8049.png | 28.04dB
22-01-12 11:42:44.990 : ---8-->   8143.png | 20.45dB
22-01-12 11:42:45.023 : <epoch:1042, iter: 295,000, Average PSNR : 27.80dB

22-01-12 11:43:11.722 : <epoch:1043, iter: 295,200, lr:1.000e-04> G_loss: 1.571e-02 
22-01-12 11:43:37.846 : <epoch:1043, iter: 295,400, lr:1.000e-04> G_loss: 1.989e-02 
22-01-12 11:44:04.476 : <epoch:1044, iter: 295,600, lr:1.000e-04> G_loss: 1.172e-02 
22-01-12 11:44:31.117 : <epoch:1045, iter: 295,800, lr:1.000e-04> G_loss: 3.851e-02 
22-01-12 11:44:57.183 : <epoch:1045, iter: 296,000, lr:1.000e-04> G_loss: 3.068e-02 
22-01-12 11:45:23.813 : <epoch:1046, iter: 296,200, lr:1.000e-04> G_loss: 3.588e-02 
22-01-12 11:45:50.375 : <epoch:1047, iter: 296,400, lr:1.000e-04> G_loss: 1.073e-02 
22-01-12 11:46:17.144 : <epoch:1048, iter: 296,600, lr:1.000e-04> G_loss: 1.609e-02 
22-01-12 11:46:43.179 : <epoch:1048, iter: 296,800, lr:1.000e-04> G_loss: 1.238e-02 
22-01-12 11:47:09.703 : <epoch:1049, iter: 297,000, lr:1.000e-04> G_loss: 2.315e-02 
22-01-12 11:47:36.378 : <epoch:1050, iter: 297,200, lr:1.000e-04> G_loss: 1.143e-02 
22-01-12 11:48:02.462 : <epoch:1050, iter: 297,400, lr:1.000e-04> G_loss: 5.570e-03 
22-01-12 11:48:29.195 : <epoch:1051, iter: 297,600, lr:1.000e-04> G_loss: 1.607e-02 
22-01-12 11:48:55.966 : <epoch:1052, iter: 297,800, lr:1.000e-04> G_loss: 3.359e-02 
22-01-12 11:49:22.651 : <epoch:1053, iter: 298,000, lr:1.000e-04> G_loss: 1.778e-02 
22-01-12 11:49:48.774 : <epoch:1053, iter: 298,200, lr:1.000e-04> G_loss: 2.523e-02 
22-01-12 11:50:15.422 : <epoch:1054, iter: 298,400, lr:1.000e-04> G_loss: 9.720e-03 
22-01-12 11:50:42.085 : <epoch:1055, iter: 298,600, lr:1.000e-04> G_loss: 2.335e-02 
22-01-12 11:51:08.139 : <epoch:1055, iter: 298,800, lr:1.000e-04> G_loss: 2.117e-02 
22-01-12 11:51:34.823 : <epoch:1056, iter: 299,000, lr:1.000e-04> G_loss: 8.715e-03 
22-01-12 11:52:01.464 : <epoch:1057, iter: 299,200, lr:1.000e-04> G_loss: 1.724e-02 
22-01-12 11:52:27.541 : <epoch:1057, iter: 299,400, lr:1.000e-04> G_loss: 3.655e-02 
22-01-12 11:52:54.179 : <epoch:1058, iter: 299,600, lr:1.000e-04> G_loss: 2.614e-02 
22-01-12 11:53:28.278 : <epoch:1059, iter: 299,800, lr:1.000e-04> G_loss: 6.472e-02 
22-01-12 11:54:12.133 : <epoch:1060, iter: 300,000, lr:1.000e-04> G_loss: 1.611e-02 
22-01-12 11:54:12.134 : Saving the model.
22-01-12 11:54:12.768 : ---1-->  12003.png | 28.99dB
22-01-12 11:54:13.053 : ---2-->  12074.png | 31.43dB
22-01-12 11:54:13.354 : ---3-->  15004.png | 24.86dB
22-01-12 11:54:13.648 : ---4-->  15088.png | 25.46dB
22-01-12 11:54:13.952 : ---5-->  16052.png | 33.84dB
22-01-12 11:54:14.254 : ---6-->   2092.png | 29.29dB
22-01-12 11:54:14.534 : ---7-->   8049.png | 27.99dB
22-01-12 11:54:14.796 : ---8-->   8143.png | 20.41dB
22-01-12 11:54:14.832 : <epoch:1060, iter: 300,000, Average PSNR : 27.78dB

22-01-12 11:54:40.900 : <epoch:1060, iter: 300,200, lr:1.000e-04> G_loss: 1.676e-02 
22-01-12 11:55:07.505 : <epoch:1061, iter: 300,400, lr:1.000e-04> G_loss: 1.584e-02 
22-01-12 11:55:34.029 : <epoch:1062, iter: 300,600, lr:1.000e-04> G_loss: 1.731e-02 
22-01-12 11:56:00.161 : <epoch:1062, iter: 300,800, lr:1.000e-04> G_loss: 1.246e-02 
22-01-12 11:56:26.826 : <epoch:1063, iter: 301,000, lr:1.000e-04> G_loss: 4.660e-02 
22-01-12 11:56:53.406 : <epoch:1064, iter: 301,200, lr:1.000e-04> G_loss: 6.228e-03 
22-01-12 11:57:47.530 : <epoch:1065, iter: 301,400, lr:1.000e-04> G_loss: 2.012e-02 
22-01-12 11:58:16.168 : <epoch:1065, iter: 301,600, lr:1.000e-04> G_loss: 1.887e-02 
22-01-12 11:58:42.748 : <epoch:1066, iter: 301,800, lr:1.000e-04> G_loss: 1.863e-02 
22-01-12 11:59:09.461 : <epoch:1067, iter: 302,000, lr:1.000e-04> G_loss: 3.952e-02 
22-01-12 11:59:35.479 : <epoch:1067, iter: 302,200, lr:1.000e-04> G_loss: 4.665e-02 
22-01-12 12:00:02.151 : <epoch:1068, iter: 302,400, lr:1.000e-04> G_loss: 5.791e-03 
22-01-12 12:00:28.975 : <epoch:1069, iter: 302,600, lr:1.000e-04> G_loss: 1.206e-02 
22-01-12 12:00:55.048 : <epoch:1069, iter: 302,800, lr:1.000e-04> G_loss: 5.917e-02 
22-01-12 12:01:21.724 : <epoch:1070, iter: 303,000, lr:1.000e-04> G_loss: 1.864e-02 
22-01-12 12:01:48.362 : <epoch:1071, iter: 303,200, lr:1.000e-04> G_loss: 1.433e-02 
22-01-12 12:02:15.004 : <epoch:1072, iter: 303,400, lr:1.000e-04> G_loss: 3.500e-02 
22-01-12 12:02:41.168 : <epoch:1072, iter: 303,600, lr:1.000e-04> G_loss: 2.981e-02 
22-01-12 12:03:07.875 : <epoch:1073, iter: 303,800, lr:1.000e-04> G_loss: 3.330e-02 
22-01-12 12:03:34.556 : <epoch:1074, iter: 304,000, lr:1.000e-04> G_loss: 2.264e-02 
22-01-12 12:04:00.662 : <epoch:1074, iter: 304,200, lr:1.000e-04> G_loss: 3.019e-02 
22-01-12 12:04:27.291 : <epoch:1075, iter: 304,400, lr:1.000e-04> G_loss: 3.506e-02 
22-01-12 12:04:53.947 : <epoch:1076, iter: 304,600, lr:1.000e-04> G_loss: 3.447e-02 
22-01-12 12:05:20.672 : <epoch:1077, iter: 304,800, lr:1.000e-04> G_loss: 3.410e-02 
22-01-12 12:05:46.676 : <epoch:1077, iter: 305,000, lr:1.000e-04> G_loss: 1.765e-02 
22-01-12 12:05:46.676 : Saving the model.
22-01-12 12:05:47.288 : ---1-->  12003.png | 29.02dB
22-01-12 12:05:47.594 : ---2-->  12074.png | 31.44dB
22-01-12 12:05:47.902 : ---3-->  15004.png | 24.85dB
22-01-12 12:05:48.199 : ---4-->  15088.png | 25.40dB
22-01-12 12:05:48.511 : ---5-->  16052.png | 33.83dB
22-01-12 12:05:48.828 : ---6-->   2092.png | 29.36dB
22-01-12 12:05:49.103 : ---7-->   8049.png | 28.05dB
22-01-12 12:05:49.394 : ---8-->   8143.png | 20.46dB
22-01-12 12:05:49.426 : <epoch:1077, iter: 305,000, Average PSNR : 27.80dB

22-01-12 12:06:16.066 : <epoch:1078, iter: 305,200, lr:1.000e-04> G_loss: 5.175e-02 
22-01-12 12:06:42.645 : <epoch:1079, iter: 305,400, lr:1.000e-04> G_loss: 8.841e-03 
22-01-12 12:07:08.849 : <epoch:1079, iter: 305,600, lr:1.000e-04> G_loss: 4.477e-02 
22-01-12 12:07:35.656 : <epoch:1080, iter: 305,800, lr:1.000e-04> G_loss: 6.669e-03 
22-01-12 12:08:02.292 : <epoch:1081, iter: 306,000, lr:1.000e-04> G_loss: 2.708e-02 
22-01-12 12:08:28.361 : <epoch:1081, iter: 306,200, lr:1.000e-04> G_loss: 1.103e-02 
22-01-12 12:08:55.030 : <epoch:1082, iter: 306,400, lr:1.000e-04> G_loss: 1.820e-02 
22-01-12 12:09:21.673 : <epoch:1083, iter: 306,600, lr:1.000e-04> G_loss: 6.265e-02 
22-01-12 12:09:48.400 : <epoch:1084, iter: 306,800, lr:1.000e-04> G_loss: 3.174e-02 
22-01-12 12:10:14.542 : <epoch:1084, iter: 307,000, lr:1.000e-04> G_loss: 4.341e-02 
22-01-12 12:10:41.242 : <epoch:1085, iter: 307,200, lr:1.000e-04> G_loss: 1.975e-02 
22-01-12 12:11:08.031 : <epoch:1086, iter: 307,400, lr:1.000e-04> G_loss: 6.191e-02 
22-01-12 12:11:34.223 : <epoch:1086, iter: 307,600, lr:1.000e-04> G_loss: 5.003e-02 
22-01-12 12:12:00.967 : <epoch:1087, iter: 307,800, lr:1.000e-04> G_loss: 1.497e-02 
22-01-12 12:12:27.702 : <epoch:1088, iter: 308,000, lr:1.000e-04> G_loss: 2.563e-02 
22-01-12 12:12:54.312 : <epoch:1089, iter: 308,200, lr:1.000e-04> G_loss: 1.832e-02 
22-01-12 12:13:20.429 : <epoch:1089, iter: 308,400, lr:1.000e-04> G_loss: 6.442e-03 
22-01-12 12:13:47.048 : <epoch:1090, iter: 308,600, lr:1.000e-04> G_loss: 2.410e-02 
22-01-12 12:14:13.685 : <epoch:1091, iter: 308,800, lr:1.000e-04> G_loss: 1.140e-02 
22-01-12 12:14:39.770 : <epoch:1091, iter: 309,000, lr:1.000e-04> G_loss: 9.563e-03 
22-01-12 12:15:06.436 : <epoch:1092, iter: 309,200, lr:1.000e-04> G_loss: 5.014e-02 
22-01-12 12:15:33.083 : <epoch:1093, iter: 309,400, lr:1.000e-04> G_loss: 9.052e-03 
22-01-12 12:15:59.128 : <epoch:1093, iter: 309,600, lr:1.000e-04> G_loss: 4.024e-02 
22-01-12 12:16:25.797 : <epoch:1094, iter: 309,800, lr:1.000e-04> G_loss: 2.876e-02 
22-01-12 12:16:52.436 : <epoch:1095, iter: 310,000, lr:1.000e-04> G_loss: 4.012e-02 
22-01-12 12:16:52.437 : Saving the model.
22-01-12 12:16:53.065 : ---1-->  12003.png | 28.91dB
22-01-12 12:16:53.376 : ---2-->  12074.png | 31.46dB
22-01-12 12:16:53.688 : ---3-->  15004.png | 24.85dB
22-01-12 12:16:54.011 : ---4-->  15088.png | 25.35dB
22-01-12 12:16:54.283 : ---5-->  16052.png | 33.68dB
22-01-12 12:16:54.611 : ---6-->   2092.png | 29.34dB
22-01-12 12:16:54.890 : ---7-->   8049.png | 28.04dB
22-01-12 12:16:55.179 : ---8-->   8143.png | 20.47dB
22-01-12 12:16:55.211 : <epoch:1095, iter: 310,000, Average PSNR : 27.76dB

22-01-12 12:17:21.813 : <epoch:1096, iter: 310,200, lr:1.000e-04> G_loss: 1.166e-02 
22-01-12 12:17:47.876 : <epoch:1096, iter: 310,400, lr:1.000e-04> G_loss: 1.790e-02 
22-01-12 12:18:14.518 : <epoch:1097, iter: 310,600, lr:1.000e-04> G_loss: 1.138e-02 
22-01-12 12:18:41.072 : <epoch:1098, iter: 310,800, lr:1.000e-04> G_loss: 5.165e-03 
22-01-12 12:19:07.167 : <epoch:1098, iter: 311,000, lr:1.000e-04> G_loss: 1.488e-02 
22-01-12 12:19:33.805 : <epoch:1099, iter: 311,200, lr:1.000e-04> G_loss: 3.216e-02 
22-01-12 12:20:00.419 : <epoch:1100, iter: 311,400, lr:1.000e-04> G_loss: 3.343e-02 
22-01-12 12:20:27.106 : <epoch:1101, iter: 311,600, lr:1.000e-04> G_loss: 3.735e-02 
22-01-12 12:20:53.182 : <epoch:1101, iter: 311,800, lr:1.000e-04> G_loss: 1.854e-02 
22-01-12 12:21:19.813 : <epoch:1102, iter: 312,000, lr:1.000e-04> G_loss: 3.545e-02 
22-01-12 12:21:46.370 : <epoch:1103, iter: 312,200, lr:1.000e-04> G_loss: 3.830e-02 
22-01-12 12:22:12.526 : <epoch:1103, iter: 312,400, lr:1.000e-04> G_loss: 1.903e-02 
22-01-12 12:22:39.127 : <epoch:1104, iter: 312,600, lr:1.000e-04> G_loss: 5.225e-03 
22-01-12 12:23:05.813 : <epoch:1105, iter: 312,800, lr:1.000e-04> G_loss: 1.994e-02 
22-01-12 12:23:32.415 : <epoch:1106, iter: 313,000, lr:1.000e-04> G_loss: 3.052e-02 
22-01-12 12:23:58.587 : <epoch:1106, iter: 313,200, lr:1.000e-04> G_loss: 3.083e-02 
22-01-12 12:24:25.219 : <epoch:1107, iter: 313,400, lr:1.000e-04> G_loss: 2.508e-02 
22-01-12 12:24:51.859 : <epoch:1108, iter: 313,600, lr:1.000e-04> G_loss: 1.945e-02 
22-01-12 12:25:17.994 : <epoch:1108, iter: 313,800, lr:1.000e-04> G_loss: 1.372e-02 
22-01-12 12:25:44.736 : <epoch:1109, iter: 314,000, lr:1.000e-04> G_loss: 2.670e-02 
22-01-12 12:26:11.365 : <epoch:1110, iter: 314,200, lr:1.000e-04> G_loss: 2.519e-02 
22-01-12 12:26:37.455 : <epoch:1110, iter: 314,400, lr:1.000e-04> G_loss: 1.777e-02 
22-01-12 12:27:04.104 : <epoch:1111, iter: 314,600, lr:1.000e-04> G_loss: 2.563e-02 
22-01-12 12:27:30.671 : <epoch:1112, iter: 314,800, lr:1.000e-04> G_loss: 1.283e-02 
22-01-12 12:27:57.301 : <epoch:1113, iter: 315,000, lr:1.000e-04> G_loss: 1.348e-02 
22-01-12 12:27:57.302 : Saving the model.
22-01-12 12:27:57.949 : ---1-->  12003.png | 29.01dB
22-01-12 12:27:58.283 : ---2-->  12074.png | 31.53dB
22-01-12 12:27:58.628 : ---3-->  15004.png | 24.91dB
22-01-12 12:27:58.964 : ---4-->  15088.png | 25.46dB
22-01-12 12:27:59.269 : ---5-->  16052.png | 33.90dB
22-01-12 12:27:59.606 : ---6-->   2092.png | 29.37dB
22-01-12 12:27:59.894 : ---7-->   8049.png | 28.06dB
22-01-12 12:28:00.167 : ---8-->   8143.png | 20.41dB
22-01-12 12:28:00.199 : <epoch:1113, iter: 315,000, Average PSNR : 27.83dB

22-01-12 12:28:26.347 : <epoch:1113, iter: 315,200, lr:1.000e-04> G_loss: 1.988e-02 
22-01-12 12:28:53.123 : <epoch:1114, iter: 315,400, lr:1.000e-04> G_loss: 8.760e-03 
22-01-12 12:29:20.004 : <epoch:1115, iter: 315,600, lr:1.000e-04> G_loss: 8.394e-03 
22-01-12 12:29:57.551 : <epoch:1115, iter: 315,800, lr:1.000e-04> G_loss: 2.689e-02 
22-01-12 12:30:39.529 : <epoch:1116, iter: 316,000, lr:1.000e-04> G_loss: 4.514e-02 
22-01-12 12:31:06.181 : <epoch:1117, iter: 316,200, lr:1.000e-04> G_loss: 1.500e-02 
22-01-12 12:31:32.825 : <epoch:1118, iter: 316,400, lr:1.000e-04> G_loss: 3.443e-02 
22-01-12 12:31:58.989 : <epoch:1118, iter: 316,600, lr:1.000e-04> G_loss: 2.552e-02 
22-01-12 12:32:25.652 : <epoch:1119, iter: 316,800, lr:1.000e-04> G_loss: 3.105e-02 
22-01-12 12:33:03.299 : <epoch:1120, iter: 317,000, lr:1.000e-04> G_loss: 1.775e-02 
22-01-12 12:33:55.045 : <epoch:1120, iter: 317,200, lr:1.000e-04> G_loss: 4.284e-02 
22-01-12 12:34:51.031 : <epoch:1121, iter: 317,400, lr:1.000e-04> G_loss: 3.739e-02 
22-01-12 12:35:18.108 : <epoch:1122, iter: 317,600, lr:1.000e-04> G_loss: 1.611e-02 
22-01-12 12:35:44.320 : <epoch:1122, iter: 317,800, lr:1.000e-04> G_loss: 9.684e-03 
22-01-12 12:36:11.022 : <epoch:1123, iter: 318,000, lr:1.000e-04> G_loss: 5.272e-02 
22-01-12 12:36:37.686 : <epoch:1124, iter: 318,200, lr:1.000e-04> G_loss: 5.009e-02 
22-01-12 12:37:04.373 : <epoch:1125, iter: 318,400, lr:1.000e-04> G_loss: 1.508e-02 
22-01-12 12:37:30.435 : <epoch:1125, iter: 318,600, lr:1.000e-04> G_loss: 2.587e-02 
22-01-12 12:37:57.090 : <epoch:1126, iter: 318,800, lr:1.000e-04> G_loss: 2.068e-02 
22-01-12 12:38:23.768 : <epoch:1127, iter: 319,000, lr:1.000e-04> G_loss: 4.202e-02 
22-01-12 12:38:49.819 : <epoch:1127, iter: 319,200, lr:1.000e-04> G_loss: 4.554e-02 
22-01-12 12:39:16.479 : <epoch:1128, iter: 319,400, lr:1.000e-04> G_loss: 9.770e-03 
22-01-12 12:39:43.116 : <epoch:1129, iter: 319,600, lr:1.000e-04> G_loss: 5.936e-02 
22-01-12 12:40:09.756 : <epoch:1130, iter: 319,800, lr:1.000e-04> G_loss: 1.382e-02 
22-01-12 12:40:35.885 : <epoch:1130, iter: 320,000, lr:1.000e-04> G_loss: 7.628e-02 
22-01-12 12:40:35.885 : Saving the model.
22-01-12 12:40:36.522 : ---1-->  12003.png | 29.01dB
22-01-12 12:40:36.832 : ---2-->  12074.png | 31.49dB
22-01-12 12:40:37.176 : ---3-->  15004.png | 24.90dB
22-01-12 12:40:37.496 : ---4-->  15088.png | 25.42dB
22-01-12 12:40:37.832 : ---5-->  16052.png | 33.78dB
22-01-12 12:40:38.187 : ---6-->   2092.png | 29.31dB
22-01-12 12:40:38.554 : ---7-->   8049.png | 28.01dB
22-01-12 12:40:38.977 : ---8-->   8143.png | 20.49dB
22-01-12 12:40:39.013 : <epoch:1130, iter: 320,000, Average PSNR : 27.80dB

22-01-12 12:41:05.780 : <epoch:1131, iter: 320,200, lr:1.000e-04> G_loss: 6.173e-02 
22-01-12 12:41:19.537 :   task: swinir_sr_classical_patch48_x3
  model: plain
  gpu_ids: [0]
  dist: False
  scale: 3
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution/swinir_sr_classical_patch48_x3/models/320000_G.pth
    pretrained_netE: superresolution/swinir_sr_classical_patch48_x3/models/320000_E.pth
    task: superresolution/swinir_sr_classical_patch48_x3
    log: superresolution/swinir_sr_classical_patch48_x3
    options: superresolution/swinir_sr_classical_patch48_x3/options
    models: superresolution/swinir_sr_classical_patch48_x3/models
    images: superresolution/swinir_sr_classical_patch48_x3/images
    pretrained_optimizerG: superresolution/swinir_sr_classical_patch48_x3/models/320000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: dataset/hr_144
      dataroot_L: None
      H_size: 144
      dataloader_shuffle: True
      dataloader_num_workers: 16
      dataloader_batch_size: 1
      phase: train
      scale: 3
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: dataset/val_hr_images
      dataroot_L: None
      phase: test
      scale: 3
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 3
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
    init_type: default
    scale: 3
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
  ]
  opt_path: options/swinir/train_swinir_sr_classical.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  num_gpu: 1
  rank: 0
  world_size: 1

22-01-12 12:41:19.544 : Number of train images: 2,855, iters: 2,855
22-01-12 12:41:37.691 : <epoch:1132, iter: 320,400, lr:1.000e-04> G_loss: 2.667e-02 
22-01-12 12:42:04.290 : <epoch:1132, iter: 320,600, lr:1.000e-04> G_loss: 1.779e-02 
22-01-12 12:42:30.955 : <epoch:1133, iter: 320,800, lr:1.000e-04> G_loss: 7.673e-03 
22-01-12 12:42:57.669 : <epoch:1134, iter: 321,000, lr:1.000e-04> G_loss: 4.860e-02 
22-01-12 12:43:23.739 : <epoch:1134, iter: 321,200, lr:1.000e-04> G_loss: 1.952e-02 
22-01-12 12:43:50.410 : <epoch:1135, iter: 321,400, lr:1.000e-04> G_loss: 3.537e-02 
22-01-12 12:44:17.046 : <epoch:1136, iter: 321,600, lr:1.000e-04> G_loss: 1.440e-02 
22-01-12 12:44:43.879 : <epoch:1137, iter: 321,800, lr:1.000e-04> G_loss: 2.142e-02 
22-01-12 12:45:09.920 : <epoch:1137, iter: 322,000, lr:1.000e-04> G_loss: 5.642e-02 
22-01-12 12:45:36.630 : <epoch:1138, iter: 322,200, lr:1.000e-04> G_loss: 2.662e-02 
22-01-12 12:46:03.277 : <epoch:1139, iter: 322,400, lr:1.000e-04> G_loss: 1.375e-02 
22-01-12 12:46:29.486 : <epoch:1139, iter: 322,600, lr:1.000e-04> G_loss: 1.855e-02 
22-01-12 12:46:56.242 : <epoch:1140, iter: 322,800, lr:1.000e-04> G_loss: 2.258e-02 
22-01-12 12:47:22.891 : <epoch:1141, iter: 323,000, lr:1.000e-04> G_loss: 1.326e-02 
22-01-12 12:47:49.558 : <epoch:1142, iter: 323,200, lr:1.000e-04> G_loss: 2.964e-02 
22-01-12 12:48:15.663 : <epoch:1142, iter: 323,400, lr:1.000e-04> G_loss: 1.605e-02 
22-01-12 12:49:04.931 : <epoch:1143, iter: 323,600, lr:1.000e-04> G_loss: 1.856e-02 
22-01-12 12:49:43.098 : <epoch:1144, iter: 323,800, lr:1.000e-04> G_loss: 3.625e-02 
22-01-12 12:50:09.203 : <epoch:1144, iter: 324,000, lr:1.000e-04> G_loss: 3.118e-02 
22-01-12 12:50:36.036 : <epoch:1145, iter: 324,200, lr:1.000e-04> G_loss: 6.498e-02 
22-01-12 12:51:02.713 : <epoch:1146, iter: 324,400, lr:1.000e-04> G_loss: 5.381e-02 
22-01-12 12:51:28.777 : <epoch:1146, iter: 324,600, lr:1.000e-04> G_loss: 2.778e-02 
22-01-12 12:51:55.462 : <epoch:1147, iter: 324,800, lr:1.000e-04> G_loss: 4.189e-02 
22-01-12 12:52:22.140 : <epoch:1148, iter: 325,000, lr:1.000e-04> G_loss: 1.529e-02 
22-01-12 12:52:22.140 : Saving the model.
22-01-12 12:52:22.811 : ---1-->  12003.png | 29.00dB
22-01-12 12:52:23.122 : ---2-->  12074.png | 31.43dB
22-01-12 12:52:23.435 : ---3-->  15004.png | 24.87dB
22-01-12 12:52:23.731 : ---4-->  15088.png | 25.47dB
22-01-12 12:52:24.042 : ---5-->  16052.png | 33.88dB
22-01-12 12:52:24.351 : ---6-->   2092.png | 29.38dB
22-01-12 12:52:24.645 : ---7-->   8049.png | 28.01dB
22-01-12 12:52:24.974 : ---8-->   8143.png | 20.46dB
22-01-12 12:52:25.006 : <epoch:1148, iter: 325,000, Average PSNR : 27.81dB

22-01-12 12:52:51.611 : <epoch:1149, iter: 325,200, lr:1.000e-04> G_loss: 5.202e-02 
22-01-12 12:53:18.131 : <epoch:1149, iter: 325,400, lr:1.000e-04> G_loss: 1.001e-02 
22-01-12 12:53:44.954 : <epoch:1150, iter: 325,600, lr:1.000e-04> G_loss: 2.458e-02 
22-01-12 12:54:11.643 : <epoch:1151, iter: 325,800, lr:1.000e-04> G_loss: 9.090e-03 
22-01-12 12:54:37.707 : <epoch:1151, iter: 326,000, lr:1.000e-04> G_loss: 1.255e-02 
22-01-12 12:55:04.494 : <epoch:1152, iter: 326,200, lr:1.000e-04> G_loss: 3.475e-02 
22-01-12 12:55:31.184 : <epoch:1153, iter: 326,400, lr:1.000e-04> G_loss: 1.848e-02 
22-01-12 12:55:57.951 : <epoch:1154, iter: 326,600, lr:1.000e-04> G_loss: 5.587e-02 
22-01-12 12:56:24.256 : <epoch:1154, iter: 326,800, lr:1.000e-04> G_loss: 6.752e-02 
22-01-12 12:56:51.091 : <epoch:1155, iter: 327,000, lr:1.000e-04> G_loss: 5.242e-03 
22-01-12 12:57:17.729 : <epoch:1156, iter: 327,200, lr:1.000e-04> G_loss: 1.787e-02 
22-01-12 12:57:43.813 : <epoch:1156, iter: 327,400, lr:1.000e-04> G_loss: 1.790e-02 
22-01-12 12:58:10.567 : <epoch:1157, iter: 327,600, lr:1.000e-04> G_loss: 3.784e-02 
22-01-12 12:58:37.333 : <epoch:1158, iter: 327,800, lr:1.000e-04> G_loss: 3.159e-02 
22-01-12 12:59:04.232 : <epoch:1159, iter: 328,000, lr:1.000e-04> G_loss: 8.173e-03 
22-01-12 12:59:30.305 : <epoch:1159, iter: 328,200, lr:1.000e-04> G_loss: 3.310e-02 
22-01-12 12:59:56.958 : <epoch:1160, iter: 328,400, lr:1.000e-04> G_loss: 2.339e-02 
22-01-12 13:00:23.778 : <epoch:1161, iter: 328,600, lr:1.000e-04> G_loss: 1.137e-02 
22-01-12 13:00:49.833 : <epoch:1161, iter: 328,800, lr:1.000e-04> G_loss: 2.438e-02 
22-01-12 13:01:16.536 : <epoch:1162, iter: 329,000, lr:1.000e-04> G_loss: 5.084e-02 
22-01-12 13:01:43.164 : <epoch:1163, iter: 329,200, lr:1.000e-04> G_loss: 3.150e-02 
22-01-12 13:02:19.484 : <epoch:1163, iter: 329,400, lr:1.000e-04> G_loss: 2.908e-02 
22-01-12 13:03:14.476 : <epoch:1164, iter: 329,600, lr:1.000e-04> G_loss: 2.100e-02 
22-01-12 13:03:41.159 : <epoch:1165, iter: 329,800, lr:1.000e-04> G_loss: 1.032e-02 
22-01-12 13:04:07.924 : <epoch:1166, iter: 330,000, lr:1.000e-04> G_loss: 4.180e-02 
22-01-12 13:04:07.924 : Saving the model.
22-01-12 13:04:08.566 : ---1-->  12003.png | 29.01dB
22-01-12 13:04:08.860 : ---2-->  12074.png | 31.50dB
22-01-12 13:04:09.165 : ---3-->  15004.png | 24.85dB
22-01-12 13:04:09.464 : ---4-->  15088.png | 25.40dB
22-01-12 13:04:09.758 : ---5-->  16052.png | 33.73dB
22-01-12 13:04:10.066 : ---6-->   2092.png | 29.34dB
22-01-12 13:04:10.323 : ---7-->   8049.png | 27.99dB
22-01-12 13:04:10.587 : ---8-->   8143.png | 20.42dB
22-01-12 13:04:10.619 : <epoch:1166, iter: 330,000, Average PSNR : 27.78dB

22-01-12 13:04:36.589 : <epoch:1166, iter: 330,200, lr:1.000e-04> G_loss: 1.116e-02 
22-01-12 13:05:03.181 : <epoch:1167, iter: 330,400, lr:1.000e-04> G_loss: 2.687e-02 
22-01-12 13:05:49.944 : <epoch:1168, iter: 330,600, lr:1.000e-04> G_loss: 9.698e-03 
22-01-12 13:06:44.066 : <epoch:1168, iter: 330,800, lr:1.000e-04> G_loss: 3.647e-02 
22-01-12 13:07:29.130 : <epoch:1169, iter: 331,000, lr:1.000e-04> G_loss: 3.758e-02 
22-01-12 13:07:55.747 : <epoch:1170, iter: 331,200, lr:1.000e-04> G_loss: 1.748e-02 
22-01-12 13:08:22.641 : <epoch:1171, iter: 331,400, lr:1.000e-04> G_loss: 5.261e-02 
22-01-12 13:08:49.005 : <epoch:1171, iter: 331,600, lr:1.000e-04> G_loss: 4.087e-02 
22-01-12 13:09:15.777 : <epoch:1172, iter: 331,800, lr:1.000e-04> G_loss: 6.717e-03 
22-01-12 13:09:42.581 : <epoch:1173, iter: 332,000, lr:1.000e-04> G_loss: 3.706e-02 
22-01-12 13:10:08.626 : <epoch:1173, iter: 332,200, lr:1.000e-04> G_loss: 1.165e-02 
22-01-12 13:10:35.407 : <epoch:1174, iter: 332,400, lr:1.000e-04> G_loss: 1.656e-02 
22-01-12 13:11:02.174 : <epoch:1175, iter: 332,600, lr:1.000e-04> G_loss: 2.711e-02 
22-01-12 13:11:28.223 : <epoch:1175, iter: 332,800, lr:1.000e-04> G_loss: 1.589e-02 
22-01-12 13:11:54.873 : <epoch:1176, iter: 333,000, lr:1.000e-04> G_loss: 4.642e-02 
22-01-12 13:12:21.937 : <epoch:1177, iter: 333,200, lr:1.000e-04> G_loss: 7.685e-03 
22-01-12 13:12:48.666 : <epoch:1178, iter: 333,400, lr:1.000e-04> G_loss: 1.201e-02 
22-01-12 13:13:14.675 : <epoch:1178, iter: 333,600, lr:1.000e-04> G_loss: 3.581e-02 
22-01-12 13:13:41.488 : <epoch:1179, iter: 333,800, lr:1.000e-04> G_loss: 1.541e-02 
22-01-12 13:14:08.131 : <epoch:1180, iter: 334,000, lr:1.000e-04> G_loss: 4.833e-02 
22-01-12 13:14:34.160 : <epoch:1180, iter: 334,200, lr:1.000e-04> G_loss: 7.690e-03 
22-01-12 13:15:00.766 : <epoch:1181, iter: 334,400, lr:1.000e-04> G_loss: 1.143e-02 
22-01-12 13:15:27.450 : <epoch:1182, iter: 334,600, lr:1.000e-04> G_loss: 5.153e-02 
22-01-12 13:15:54.163 : <epoch:1183, iter: 334,800, lr:1.000e-04> G_loss: 5.048e-02 
22-01-12 13:16:20.240 : <epoch:1183, iter: 335,000, lr:1.000e-04> G_loss: 4.883e-02 
22-01-12 13:16:20.240 : Saving the model.
22-01-12 13:16:20.856 : ---1-->  12003.png | 29.00dB
22-01-12 13:16:21.169 : ---2-->  12074.png | 31.34dB
22-01-12 13:16:21.500 : ---3-->  15004.png | 24.75dB
22-01-12 13:16:21.824 : ---4-->  15088.png | 25.42dB
22-01-12 13:16:22.138 : ---5-->  16052.png | 33.71dB
22-01-12 13:16:22.463 : ---6-->   2092.png | 29.34dB
22-01-12 13:16:22.743 : ---7-->   8049.png | 27.96dB
22-01-12 13:16:23.026 : ---8-->   8143.png | 20.43dB
22-01-12 13:16:23.059 : <epoch:1183, iter: 335,000, Average PSNR : 27.74dB

22-01-12 13:16:49.714 : <epoch:1184, iter: 335,200, lr:1.000e-04> G_loss: 4.104e-02 
22-01-12 13:17:16.367 : <epoch:1185, iter: 335,400, lr:1.000e-04> G_loss: 1.495e-02 
22-01-12 13:17:42.562 : <epoch:1185, iter: 335,600, lr:1.000e-04> G_loss: 3.671e-02 
22-01-12 13:18:09.283 : <epoch:1186, iter: 335,800, lr:1.000e-04> G_loss: 8.839e-03 
22-01-12 13:18:35.950 : <epoch:1187, iter: 336,000, lr:1.000e-04> G_loss: 2.519e-02 
22-01-12 13:19:02.175 : <epoch:1187, iter: 336,200, lr:1.000e-04> G_loss: 2.458e-02 
22-01-12 13:19:28.979 : <epoch:1188, iter: 336,400, lr:1.000e-04> G_loss: 3.615e-02 
22-01-12 13:19:55.631 : <epoch:1189, iter: 336,600, lr:1.000e-04> G_loss: 2.207e-02 
22-01-12 13:20:22.439 : <epoch:1190, iter: 336,800, lr:1.000e-04> G_loss: 4.757e-02 
22-01-12 13:20:48.460 : <epoch:1190, iter: 337,000, lr:1.000e-04> G_loss: 2.678e-02 
22-01-12 13:21:15.102 : <epoch:1191, iter: 337,200, lr:1.000e-04> G_loss: 3.895e-02 
22-01-12 13:21:41.756 : <epoch:1192, iter: 337,400, lr:1.000e-04> G_loss: 1.704e-02 
22-01-12 13:22:07.990 : <epoch:1192, iter: 337,600, lr:1.000e-04> G_loss: 8.221e-02 
22-01-12 13:22:55.590 : <epoch:1193, iter: 337,800, lr:1.000e-04> G_loss: 8.309e-03 
22-01-12 13:23:28.327 : <epoch:1194, iter: 338,000, lr:1.000e-04> G_loss: 3.112e-02 
22-01-12 13:23:55.037 : <epoch:1195, iter: 338,200, lr:1.000e-04> G_loss: 3.424e-02 
